{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_byball.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOANe4TmpDwma2WkPfgw4kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UtkarshAIITB/IPL-Data-Analysis/blob/main/DL_byball.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zdjsnmC9Vc4w"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-LNG4BrVi0y",
        "outputId": "409f8798-0c28-40d2-834e-0268e8e0d968"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IPL Score_Analysis/CSV/new.csv')\n",
        "# new.head()"
      ],
      "metadata": {
        "id": "Nel_GZwLXGV8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IPL Score_Analysis/CSV/t.csv')\n",
        "# t.head()"
      ],
      "metadata": {
        "id": "7Ms7gszeXGZ5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.drop(columns = ['Unnamed: 0'], inplace = True)\n",
        "t.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "5FtDH4IqXGdP",
        "outputId": "3a23e533-4f6d-4715-86ee-abbbf031b7a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1baaa331-cba1-4c99-b6a4-75ff991f136b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>year</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>total_runs_y</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1175356</td>\n",
              "      <td>2019-03-23</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1175356</td>\n",
              "      <td>2019-03-23</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1175356</td>\n",
              "      <td>2019-03-23</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1175356</td>\n",
              "      <td>2019-03-23</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1175356</td>\n",
              "      <td>2019-03-23</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1baaa331-cba1-4c99-b6a4-75ff991f136b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1baaa331-cba1-4c99-b6a4-75ff991f136b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1baaa331-cba1-4c99-b6a4-75ff991f136b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id        date  team1  ...  total_runs_y  cum_total  cum_wicket\n",
              "0  1175356  2019-03-23     12  ...            70          1           0\n",
              "1  1175356  2019-03-23     12  ...            70          1           0\n",
              "2  1175356  2019-03-23     12  ...            70          1           0\n",
              "3  1175356  2019-03-23     12  ...            70          1           0\n",
              "4  1175356  2019-03-23     12  ...            70          5           0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new.drop(columns = ['Unnamed: 0'], inplace = True)"
      ],
      "metadata": {
        "id": "JUu59SerXGgR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "EwMUU3KuXGjO",
        "outputId": "a46aba5d-6ff2-4580-dfe5-a8c3ef72b9da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f4f26c23-fd93-477d-a67c-828b743ea612\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>year</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>total_runs_y</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>335982</td>\n",
              "      <td>2008-04-18</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>335982</td>\n",
              "      <td>2008-04-18</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>335982</td>\n",
              "      <td>2008-04-18</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>335982</td>\n",
              "      <td>2008-04-18</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>335982</td>\n",
              "      <td>2008-04-18</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f26c23-fd93-477d-a67c-828b743ea612')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4f26c23-fd93-477d-a67c-828b743ea612 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4f26c23-fd93-477d-a67c-828b743ea612');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       id        date  team1  ...  total_runs_y  cum_total  cum_wicket\n",
              "0  335982  2008-04-18      5  ...           222          1           0\n",
              "1  335982  2008-04-18      5  ...           222          1           0\n",
              "2  335982  2008-04-18      5  ...           222          2           0\n",
              "3  335982  2008-04-18      5  ...           222          2           0\n",
              "4  335982  2008-04-18      5  ...           222          2           0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new is the training set and t is the test set"
      ],
      "metadata": {
        "id": "nMX6FC7UAF67"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tnew = t.drop(t[(t.over < 15.5) | (t.over >=15.6)].index)\n",
        "tnew.reset_index(drop = True)\n",
        "y1test = tnew['total_runs_y']\n",
        "y2test = tnew['winner']\n",
        "id_test = tnew['id'].reset_index(drop = True)\n",
        "id_test = id_test.to_frame().reset_index(drop=True)\n",
        "tnew.drop(columns = ['id', 'date', 'year', 'total_runs_y', 'winner'], inplace = True)\n",
        "tnew.reset_index(drop=True).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NmPNdAArAVjw",
        "outputId": "dbcf6449-0799-4b5e-a5ea-558db5d89d05"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2483cb14-4edc-4dc7-a995-7e2d653ff061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2483cb14-4edc-4dc7-a995-7e2d653ff061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2483cb14-4edc-4dc7-a995-7e2d653ff061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2483cb14-4edc-4dc7-a995-7e2d653ff061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   team1  team2  toss_winner  inning  ...  D/L  eliminator?  cum_total  cum_wicket\n",
              "0     12      5           12       1  ...    0            0         68           8\n",
              "1     12      5           12       2  ...    0            0         67           3\n",
              "2      9      7            9       1  ...    0            0        144           1\n",
              "3      9      7            9       2  ...    0            0        119           4\n",
              "4     13      6           13       1  ...    0            0        139           4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xnew = new.drop(new[(new.over < 15.5) | (new.over >=15.6)].index)\n",
        "xnew.reset_index(drop = True)\n",
        "y1train = xnew['total_runs_y']\n",
        "y2train = xnew['winner']\n",
        "xnew.drop(columns = ['id', 'date', 'year', 'total_runs_y', 'winner'], inplace = True)\n",
        "xnew.reset_index(drop=True).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZKOFlIZcAkqn",
        "outputId": "7375b3b3-4e63-489e-92f0-eded0eb57b86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88a67d30-ff76-4bef-9d07-07d57f540eb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88a67d30-ff76-4bef-9d07-07d57f540eb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88a67d30-ff76-4bef-9d07-07d57f540eb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88a67d30-ff76-4bef-9d07-07d57f540eb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   team1  team2  toss_winner  inning  ...  D/L  eliminator?  cum_total  cum_wicket\n",
              "0      5      9            5       1  ...    0            0        158           2\n",
              "1      8     12           12       1  ...    0            0        168           5\n",
              "2      8     12           12       2  ...    0            0        174           3\n",
              "3      6     11           11       1  ...    0            0        104           7\n",
              "4     13      5           13       1  ...    0            0        110           4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "metadata": {
        "id": "HNeUSEPzA15r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xnewt = sc.fit_transform(xnew)    #2019 data\n",
        "tnewt = sc.fit_transform(tnew)    #2008-2020 data"
      ],
      "metadata": {
        "id": "whb3bwTyAz5r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xnew.shape)\n",
        "print(tnew.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHeWUdBD9nGI",
        "outputId": "e0453cc3-bf42-4ae4-9abb-25a8379153d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1403, 12)\n",
            "(116, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Score Prediction"
      ],
      "metadata": {
        "id": "NReUqkv1JXge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout"
      ],
      "metadata": {
        "id": "r7Gh43hlVkfJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "nBr0HeiyJcYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# # model.add(Dense(88, activation = 'relu'))\n",
        "# # model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(50, activation = 'relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(25, activation = 'relu'))\n",
        "# # model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(12, activation = 'relu'))\n",
        "# # model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(1))\n",
        "# model.compile(optimizer='adam', loss='mse')\n",
        "model = Sequential()\n",
        "# model.add(Dense(88, activation = 'relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "GlZacOaVWTTs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history= model.fit(x=xnewt, y=y1train, epochs=2000, \n",
        "          validation_data=(tnewt,y1test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ysELYFBIlV",
        "outputId": "74fc0437-a0b9-4554-e589-0b93969171ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "44/44 [==============================] - 3s 8ms/step - loss: 18018.4453 - val_loss: 3173.2986\n",
            "Epoch 2/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 4831.2437 - val_loss: 3669.4819\n",
            "Epoch 3/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 3814.2410 - val_loss: 3178.8938\n",
            "Epoch 4/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 3411.3987 - val_loss: 2874.8604\n",
            "Epoch 5/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 3124.0759 - val_loss: 1571.9567\n",
            "Epoch 6/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2816.3281 - val_loss: 1965.2710\n",
            "Epoch 7/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2564.7998 - val_loss: 3053.4834\n",
            "Epoch 8/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2560.0981 - val_loss: 1786.8796\n",
            "Epoch 9/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2236.3411 - val_loss: 2581.0137\n",
            "Epoch 10/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2282.7913 - val_loss: 2790.3176\n",
            "Epoch 11/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2044.6454 - val_loss: 3336.8826\n",
            "Epoch 12/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1983.7739 - val_loss: 2428.4692\n",
            "Epoch 13/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1990.6028 - val_loss: 1984.2434\n",
            "Epoch 14/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1922.3735 - val_loss: 1960.2108\n",
            "Epoch 15/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1757.3230 - val_loss: 2117.9133\n",
            "Epoch 16/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1831.8457 - val_loss: 1934.1385\n",
            "Epoch 17/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1773.9736 - val_loss: 1628.4471\n",
            "Epoch 18/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1795.7926 - val_loss: 1972.2223\n",
            "Epoch 19/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1823.6775 - val_loss: 1657.0192\n",
            "Epoch 20/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1645.3871 - val_loss: 2017.3584\n",
            "Epoch 21/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1622.3448 - val_loss: 1795.1501\n",
            "Epoch 22/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1564.4606 - val_loss: 1751.9561\n",
            "Epoch 23/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1637.1914 - val_loss: 2825.6147\n",
            "Epoch 24/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1625.3716 - val_loss: 2700.2380\n",
            "Epoch 25/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1525.1317 - val_loss: 1798.0105\n",
            "Epoch 26/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1611.0427 - val_loss: 1707.3893\n",
            "Epoch 27/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1569.4039 - val_loss: 1260.0781\n",
            "Epoch 28/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1436.1919 - val_loss: 1687.1576\n",
            "Epoch 29/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1483.2726 - val_loss: 1966.4189\n",
            "Epoch 30/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1562.3143 - val_loss: 1326.7123\n",
            "Epoch 31/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1520.6976 - val_loss: 1439.6552\n",
            "Epoch 32/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1490.6978 - val_loss: 1217.9282\n",
            "Epoch 33/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1514.1174 - val_loss: 926.4697\n",
            "Epoch 34/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1522.6509 - val_loss: 1166.5536\n",
            "Epoch 35/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1454.5255 - val_loss: 971.2965\n",
            "Epoch 36/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1423.5457 - val_loss: 1407.9709\n",
            "Epoch 37/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1557.4915 - val_loss: 1226.4196\n",
            "Epoch 38/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1400.4493 - val_loss: 1213.7610\n",
            "Epoch 39/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1418.3567 - val_loss: 924.1935\n",
            "Epoch 40/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1538.1631 - val_loss: 794.5605\n",
            "Epoch 41/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1510.9373 - val_loss: 1017.2177\n",
            "Epoch 42/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1402.7186 - val_loss: 1054.9585\n",
            "Epoch 43/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1378.3455 - val_loss: 615.6109\n",
            "Epoch 44/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1409.7303 - val_loss: 1317.0217\n",
            "Epoch 45/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1455.9210 - val_loss: 1061.9946\n",
            "Epoch 46/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1418.5253 - val_loss: 1269.0891\n",
            "Epoch 47/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1315.8633 - val_loss: 1108.1460\n",
            "Epoch 48/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1315.9730 - val_loss: 862.1497\n",
            "Epoch 49/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1393.3323 - val_loss: 688.8785\n",
            "Epoch 50/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1430.9608 - val_loss: 901.5897\n",
            "Epoch 51/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1380.2241 - val_loss: 828.2911\n",
            "Epoch 52/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1392.1632 - val_loss: 854.8705\n",
            "Epoch 53/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1319.2130 - val_loss: 872.3442\n",
            "Epoch 54/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1389.8329 - val_loss: 996.3256\n",
            "Epoch 55/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1287.3041 - val_loss: 639.1327\n",
            "Epoch 56/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1297.7192 - val_loss: 815.9906\n",
            "Epoch 57/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1405.9709 - val_loss: 679.3469\n",
            "Epoch 58/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1387.4686 - val_loss: 841.1799\n",
            "Epoch 59/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1347.3595 - val_loss: 812.8542\n",
            "Epoch 60/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1466.3695 - val_loss: 546.9383\n",
            "Epoch 61/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1387.7437 - val_loss: 907.0172\n",
            "Epoch 62/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1296.2115 - val_loss: 605.7154\n",
            "Epoch 63/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1291.3660 - val_loss: 774.5623\n",
            "Epoch 64/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1301.9309 - val_loss: 1018.7353\n",
            "Epoch 65/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1307.0840 - val_loss: 760.7487\n",
            "Epoch 66/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1301.8209 - val_loss: 879.9711\n",
            "Epoch 67/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1301.9226 - val_loss: 499.5140\n",
            "Epoch 68/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1356.1699 - val_loss: 715.3904\n",
            "Epoch 69/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1311.5563 - val_loss: 1121.8905\n",
            "Epoch 70/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1279.7906 - val_loss: 622.7812\n",
            "Epoch 71/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1369.2737 - val_loss: 580.7279\n",
            "Epoch 72/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1300.8857 - val_loss: 701.7885\n",
            "Epoch 73/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1320.9517 - val_loss: 787.4691\n",
            "Epoch 74/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1279.0090 - val_loss: 618.8630\n",
            "Epoch 75/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1365.4429 - val_loss: 717.2162\n",
            "Epoch 76/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1400.3400 - val_loss: 566.0519\n",
            "Epoch 77/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1322.3669 - val_loss: 396.9467\n",
            "Epoch 78/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1211.8462 - val_loss: 599.7387\n",
            "Epoch 79/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1310.9530 - val_loss: 399.1126\n",
            "Epoch 80/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1297.8835 - val_loss: 853.3124\n",
            "Epoch 81/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1289.9923 - val_loss: 752.5012\n",
            "Epoch 82/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1360.9698 - val_loss: 602.4956\n",
            "Epoch 83/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1179.3341 - val_loss: 354.1902\n",
            "Epoch 84/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1287.3129 - val_loss: 633.9663\n",
            "Epoch 85/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1323.1656 - val_loss: 570.8411\n",
            "Epoch 86/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1221.3304 - val_loss: 704.0331\n",
            "Epoch 87/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1303.2985 - val_loss: 644.0966\n",
            "Epoch 88/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1240.6710 - val_loss: 576.1219\n",
            "Epoch 89/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1315.9144 - val_loss: 637.5580\n",
            "Epoch 90/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1300.7072 - val_loss: 679.8216\n",
            "Epoch 91/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1252.1084 - val_loss: 599.6282\n",
            "Epoch 92/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1209.8319 - val_loss: 673.5805\n",
            "Epoch 93/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1201.0559 - val_loss: 602.6886\n",
            "Epoch 94/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1357.7843 - val_loss: 616.0287\n",
            "Epoch 95/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1281.9462 - val_loss: 487.2326\n",
            "Epoch 96/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1288.4762 - val_loss: 644.5380\n",
            "Epoch 97/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1199.9628 - val_loss: 514.7330\n",
            "Epoch 98/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1306.3810 - val_loss: 644.7592\n",
            "Epoch 99/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1291.2186 - val_loss: 494.0549\n",
            "Epoch 100/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1188.6455 - val_loss: 704.1451\n",
            "Epoch 101/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1354.7495 - val_loss: 448.8168\n",
            "Epoch 102/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1234.7788 - val_loss: 483.0112\n",
            "Epoch 103/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1264.7175 - val_loss: 590.1213\n",
            "Epoch 104/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1252.5466 - val_loss: 589.0449\n",
            "Epoch 105/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1190.0100 - val_loss: 706.1934\n",
            "Epoch 106/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1253.6188 - val_loss: 417.9949\n",
            "Epoch 107/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1305.4148 - val_loss: 552.4561\n",
            "Epoch 108/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1220.3979 - val_loss: 687.0676\n",
            "Epoch 109/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1269.6510 - val_loss: 756.7674\n",
            "Epoch 110/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1104.9148 - val_loss: 448.8984\n",
            "Epoch 111/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1198.8979 - val_loss: 571.5327\n",
            "Epoch 112/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1236.2266 - val_loss: 789.9957\n",
            "Epoch 113/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1247.7214 - val_loss: 687.3801\n",
            "Epoch 114/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1234.4783 - val_loss: 847.7296\n",
            "Epoch 115/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1284.5116 - val_loss: 596.2422\n",
            "Epoch 116/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1254.7018 - val_loss: 445.9464\n",
            "Epoch 117/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1191.5229 - val_loss: 357.8754\n",
            "Epoch 118/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1256.1426 - val_loss: 498.3299\n",
            "Epoch 119/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1224.6105 - val_loss: 724.0333\n",
            "Epoch 120/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1250.0190 - val_loss: 487.3759\n",
            "Epoch 121/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1175.1479 - val_loss: 644.6210\n",
            "Epoch 122/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1262.5491 - val_loss: 560.6478\n",
            "Epoch 123/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1304.4266 - val_loss: 674.5659\n",
            "Epoch 124/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1232.4969 - val_loss: 414.5224\n",
            "Epoch 125/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1192.0110 - val_loss: 375.1898\n",
            "Epoch 126/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1284.9594 - val_loss: 499.7908\n",
            "Epoch 127/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1166.1033 - val_loss: 733.3486\n",
            "Epoch 128/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1220.2007 - val_loss: 540.8262\n",
            "Epoch 129/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1285.6571 - val_loss: 826.8010\n",
            "Epoch 130/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1258.8792 - val_loss: 385.5912\n",
            "Epoch 131/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1302.1495 - val_loss: 412.9195\n",
            "Epoch 132/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1228.8538 - val_loss: 501.9436\n",
            "Epoch 133/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1233.5203 - val_loss: 617.9332\n",
            "Epoch 134/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1125.8528 - val_loss: 488.3623\n",
            "Epoch 135/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1252.3240 - val_loss: 619.6556\n",
            "Epoch 136/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1235.2670 - val_loss: 489.7054\n",
            "Epoch 137/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1197.1390 - val_loss: 529.3182\n",
            "Epoch 138/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1208.9629 - val_loss: 740.5696\n",
            "Epoch 139/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1188.8567 - val_loss: 917.1285\n",
            "Epoch 140/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1075.0662 - val_loss: 550.9866\n",
            "Epoch 141/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1266.2380 - val_loss: 626.5215\n",
            "Epoch 142/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1229.1104 - val_loss: 730.3505\n",
            "Epoch 143/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1287.8417 - val_loss: 567.4725\n",
            "Epoch 144/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1179.0378 - val_loss: 567.6916\n",
            "Epoch 145/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1182.9607 - val_loss: 468.1335\n",
            "Epoch 146/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1224.1832 - val_loss: 487.1537\n",
            "Epoch 147/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1146.0549 - val_loss: 431.2194\n",
            "Epoch 148/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1134.0845 - val_loss: 717.9153\n",
            "Epoch 149/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1273.4154 - val_loss: 650.7726\n",
            "Epoch 150/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1203.9319 - val_loss: 587.9158\n",
            "Epoch 151/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1238.0692 - val_loss: 432.6718\n",
            "Epoch 152/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1250.3461 - val_loss: 539.6337\n",
            "Epoch 153/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1224.9755 - val_loss: 530.1577\n",
            "Epoch 154/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1104.9464 - val_loss: 547.4788\n",
            "Epoch 155/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1268.3099 - val_loss: 444.5175\n",
            "Epoch 156/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1173.2087 - val_loss: 417.3987\n",
            "Epoch 157/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1224.2130 - val_loss: 546.1641\n",
            "Epoch 158/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1165.3013 - val_loss: 442.5275\n",
            "Epoch 159/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1218.0198 - val_loss: 342.6917\n",
            "Epoch 160/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1226.8849 - val_loss: 531.2390\n",
            "Epoch 161/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1203.6420 - val_loss: 377.6938\n",
            "Epoch 162/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1162.2361 - val_loss: 428.0149\n",
            "Epoch 163/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1125.2843 - val_loss: 320.7898\n",
            "Epoch 164/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1202.2362 - val_loss: 794.7992\n",
            "Epoch 165/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1202.6982 - val_loss: 343.2881\n",
            "Epoch 166/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1287.0131 - val_loss: 336.6360\n",
            "Epoch 167/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1142.1327 - val_loss: 374.1512\n",
            "Epoch 168/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1145.5979 - val_loss: 325.7352\n",
            "Epoch 169/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1216.8654 - val_loss: 575.2623\n",
            "Epoch 170/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1187.3672 - val_loss: 385.9283\n",
            "Epoch 171/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1167.5494 - val_loss: 528.6236\n",
            "Epoch 172/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1200.7885 - val_loss: 425.1686\n",
            "Epoch 173/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1140.1315 - val_loss: 275.7899\n",
            "Epoch 174/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1190.5474 - val_loss: 458.7125\n",
            "Epoch 175/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1128.3577 - val_loss: 389.9019\n",
            "Epoch 176/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1124.3340 - val_loss: 331.9043\n",
            "Epoch 177/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1115.3988 - val_loss: 491.5208\n",
            "Epoch 178/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1133.2966 - val_loss: 573.5980\n",
            "Epoch 179/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1067.9274 - val_loss: 517.0065\n",
            "Epoch 180/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1195.8090 - val_loss: 576.1711\n",
            "Epoch 181/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1181.7460 - val_loss: 305.3293\n",
            "Epoch 182/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1160.7639 - val_loss: 534.2038\n",
            "Epoch 183/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1122.5275 - val_loss: 558.5529\n",
            "Epoch 184/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1148.2250 - val_loss: 432.7837\n",
            "Epoch 185/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1129.4589 - val_loss: 518.1212\n",
            "Epoch 186/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1168.0391 - val_loss: 543.4413\n",
            "Epoch 187/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1054.3656 - val_loss: 342.3564\n",
            "Epoch 188/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1155.9562 - val_loss: 622.4708\n",
            "Epoch 189/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1158.0553 - val_loss: 419.1406\n",
            "Epoch 190/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1029.1433 - val_loss: 559.7254\n",
            "Epoch 191/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1089.5365 - val_loss: 280.8480\n",
            "Epoch 192/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1072.7120 - val_loss: 337.3439\n",
            "Epoch 193/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1098.7377 - val_loss: 467.6994\n",
            "Epoch 194/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1093.4731 - val_loss: 377.7891\n",
            "Epoch 195/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1128.0387 - val_loss: 576.3596\n",
            "Epoch 196/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1193.1218 - val_loss: 405.9293\n",
            "Epoch 197/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1137.4270 - val_loss: 598.2661\n",
            "Epoch 198/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1134.9895 - val_loss: 452.3476\n",
            "Epoch 199/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1152.6746 - val_loss: 396.6096\n",
            "Epoch 200/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1069.0278 - val_loss: 560.9711\n",
            "Epoch 201/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1152.9331 - val_loss: 514.5976\n",
            "Epoch 202/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1120.6674 - val_loss: 620.8364\n",
            "Epoch 203/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1113.2078 - val_loss: 359.1264\n",
            "Epoch 204/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1050.8679 - val_loss: 402.5922\n",
            "Epoch 205/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1130.9579 - val_loss: 356.3452\n",
            "Epoch 206/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1174.6794 - val_loss: 503.1194\n",
            "Epoch 207/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1119.8099 - val_loss: 422.9769\n",
            "Epoch 208/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1236.6996 - val_loss: 285.3735\n",
            "Epoch 209/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1193.7018 - val_loss: 456.7786\n",
            "Epoch 210/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1028.7997 - val_loss: 256.0133\n",
            "Epoch 211/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1204.5035 - val_loss: 571.5356\n",
            "Epoch 212/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1057.2335 - val_loss: 408.1505\n",
            "Epoch 213/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1064.3779 - val_loss: 365.9421\n",
            "Epoch 214/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1120.9321 - val_loss: 539.6527\n",
            "Epoch 215/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1082.0492 - val_loss: 468.2100\n",
            "Epoch 216/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1121.7795 - val_loss: 413.0413\n",
            "Epoch 217/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1128.5239 - val_loss: 485.9365\n",
            "Epoch 218/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1067.2786 - val_loss: 469.6366\n",
            "Epoch 219/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1105.2721 - val_loss: 448.5130\n",
            "Epoch 220/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1041.9841 - val_loss: 499.6855\n",
            "Epoch 221/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1053.8817 - val_loss: 374.4564\n",
            "Epoch 222/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1138.2328 - val_loss: 545.0330\n",
            "Epoch 223/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1144.0565 - val_loss: 338.8225\n",
            "Epoch 224/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1049.4868 - val_loss: 331.0978\n",
            "Epoch 225/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1057.3132 - val_loss: 454.0440\n",
            "Epoch 226/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1124.0310 - val_loss: 262.9915\n",
            "Epoch 227/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1063.0663 - val_loss: 449.1903\n",
            "Epoch 228/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1007.8520 - val_loss: 393.1915\n",
            "Epoch 229/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1123.6104 - val_loss: 489.8593\n",
            "Epoch 230/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1025.8512 - val_loss: 542.9568\n",
            "Epoch 231/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1070.6921 - val_loss: 465.3144\n",
            "Epoch 232/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1061.1964 - val_loss: 293.8442\n",
            "Epoch 233/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1073.4363 - val_loss: 294.7256\n",
            "Epoch 234/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1063.6479 - val_loss: 316.7659\n",
            "Epoch 235/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1032.8899 - val_loss: 341.3395\n",
            "Epoch 236/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1003.5681 - val_loss: 489.9039\n",
            "Epoch 237/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1120.4603 - val_loss: 411.1510\n",
            "Epoch 238/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1080.5054 - val_loss: 346.3604\n",
            "Epoch 239/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1014.2880 - val_loss: 391.8825\n",
            "Epoch 240/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1140.7393 - val_loss: 386.8011\n",
            "Epoch 241/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1024.5612 - val_loss: 361.7313\n",
            "Epoch 242/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1052.2722 - val_loss: 416.0056\n",
            "Epoch 243/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1057.7808 - val_loss: 364.9364\n",
            "Epoch 244/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1106.3378 - val_loss: 614.4874\n",
            "Epoch 245/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1022.3708 - val_loss: 333.9812\n",
            "Epoch 246/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1115.3430 - val_loss: 285.6241\n",
            "Epoch 247/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1078.6880 - val_loss: 415.4439\n",
            "Epoch 248/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1081.7769 - val_loss: 283.7008\n",
            "Epoch 249/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1003.6917 - val_loss: 362.5200\n",
            "Epoch 250/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1073.4852 - val_loss: 422.0251\n",
            "Epoch 251/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 974.5095 - val_loss: 591.8345\n",
            "Epoch 252/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1115.6047 - val_loss: 448.1645\n",
            "Epoch 253/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1083.0865 - val_loss: 520.0121\n",
            "Epoch 254/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1058.3777 - val_loss: 262.2971\n",
            "Epoch 255/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1075.0912 - val_loss: 350.4916\n",
            "Epoch 256/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1050.7036 - val_loss: 342.7321\n",
            "Epoch 257/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 994.4823 - val_loss: 309.9937\n",
            "Epoch 258/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1116.1764 - val_loss: 350.5353\n",
            "Epoch 259/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1045.2168 - val_loss: 339.7191\n",
            "Epoch 260/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1040.2247 - val_loss: 356.4691\n",
            "Epoch 261/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1083.6860 - val_loss: 332.1674\n",
            "Epoch 262/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1016.5256 - val_loss: 455.8938\n",
            "Epoch 263/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 986.7798 - val_loss: 398.1857\n",
            "Epoch 264/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1020.6340 - val_loss: 322.1093\n",
            "Epoch 265/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1062.9922 - val_loss: 430.6342\n",
            "Epoch 266/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1015.3550 - val_loss: 350.0413\n",
            "Epoch 267/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1058.0709 - val_loss: 418.2511\n",
            "Epoch 268/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1034.3983 - val_loss: 378.4779\n",
            "Epoch 269/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1060.4065 - val_loss: 269.0518\n",
            "Epoch 270/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1092.1293 - val_loss: 645.4174\n",
            "Epoch 271/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1028.9747 - val_loss: 356.3812\n",
            "Epoch 272/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1065.4611 - val_loss: 316.5318\n",
            "Epoch 273/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1075.0411 - val_loss: 473.6160\n",
            "Epoch 274/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1017.8343 - val_loss: 304.7267\n",
            "Epoch 275/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 968.8998 - val_loss: 434.7757\n",
            "Epoch 276/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 949.4398 - val_loss: 497.3395\n",
            "Epoch 277/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1115.0553 - val_loss: 418.1381\n",
            "Epoch 278/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1085.3412 - val_loss: 310.0466\n",
            "Epoch 279/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1031.4070 - val_loss: 457.2831\n",
            "Epoch 280/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 991.0706 - val_loss: 454.3535\n",
            "Epoch 281/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 988.3151 - val_loss: 553.4861\n",
            "Epoch 282/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1024.2456 - val_loss: 354.2912\n",
            "Epoch 283/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1031.3241 - val_loss: 306.4832\n",
            "Epoch 284/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1050.3495 - val_loss: 546.0246\n",
            "Epoch 285/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1020.4706 - val_loss: 383.6984\n",
            "Epoch 286/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1007.5513 - val_loss: 422.3567\n",
            "Epoch 287/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1038.0668 - val_loss: 303.2727\n",
            "Epoch 288/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 964.2567 - val_loss: 532.2086\n",
            "Epoch 289/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1036.5647 - val_loss: 387.5958\n",
            "Epoch 290/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 998.1085 - val_loss: 282.7447\n",
            "Epoch 291/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1056.6440 - val_loss: 306.4536\n",
            "Epoch 292/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1064.5863 - val_loss: 410.5580\n",
            "Epoch 293/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 973.5194 - val_loss: 386.1742\n",
            "Epoch 294/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1009.0175 - val_loss: 456.6243\n",
            "Epoch 295/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1032.4054 - val_loss: 435.6865\n",
            "Epoch 296/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1116.7772 - val_loss: 378.3741\n",
            "Epoch 297/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1013.3251 - val_loss: 459.7982\n",
            "Epoch 298/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1011.3451 - val_loss: 390.9169\n",
            "Epoch 299/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1053.9762 - val_loss: 529.9218\n",
            "Epoch 300/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 952.7144 - val_loss: 364.2318\n",
            "Epoch 301/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1000.5530 - val_loss: 447.8167\n",
            "Epoch 302/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 994.6991 - val_loss: 341.2234\n",
            "Epoch 303/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1036.3247 - val_loss: 430.1980\n",
            "Epoch 304/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1064.0232 - val_loss: 373.0052\n",
            "Epoch 305/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1014.5294 - val_loss: 413.1028\n",
            "Epoch 306/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 986.4711 - val_loss: 383.9686\n",
            "Epoch 307/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1049.9054 - val_loss: 428.9323\n",
            "Epoch 308/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1082.3206 - val_loss: 383.2347\n",
            "Epoch 309/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 995.7016 - val_loss: 379.7005\n",
            "Epoch 310/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1068.1354 - val_loss: 444.9504\n",
            "Epoch 311/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1062.3204 - val_loss: 443.4701\n",
            "Epoch 312/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1038.1361 - val_loss: 441.1553\n",
            "Epoch 313/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1030.9039 - val_loss: 510.7802\n",
            "Epoch 314/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1008.6066 - val_loss: 284.6653\n",
            "Epoch 315/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 991.1417 - val_loss: 412.5671\n",
            "Epoch 316/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1038.4384 - val_loss: 353.3155\n",
            "Epoch 317/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1019.4087 - val_loss: 321.8050\n",
            "Epoch 318/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1061.0052 - val_loss: 438.5709\n",
            "Epoch 319/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 956.8569 - val_loss: 371.0598\n",
            "Epoch 320/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1022.3198 - val_loss: 386.0755\n",
            "Epoch 321/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 942.2996 - val_loss: 308.4066\n",
            "Epoch 322/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 966.0905 - val_loss: 259.7155\n",
            "Epoch 323/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 984.1846 - val_loss: 401.9102\n",
            "Epoch 324/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 997.7686 - val_loss: 420.5768\n",
            "Epoch 325/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 971.3779 - val_loss: 381.7347\n",
            "Epoch 326/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 970.6852 - val_loss: 407.5517\n",
            "Epoch 327/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 981.4254 - val_loss: 369.4637\n",
            "Epoch 328/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1043.0746 - val_loss: 262.1074\n",
            "Epoch 329/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1070.7673 - val_loss: 445.0369\n",
            "Epoch 330/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 923.2568 - val_loss: 348.3679\n",
            "Epoch 331/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 962.2025 - val_loss: 439.1277\n",
            "Epoch 332/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1005.4447 - val_loss: 374.9938\n",
            "Epoch 333/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 972.7325 - val_loss: 433.1359\n",
            "Epoch 334/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 951.4728 - val_loss: 349.4241\n",
            "Epoch 335/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 951.7971 - val_loss: 371.7601\n",
            "Epoch 336/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 936.0919 - val_loss: 372.6999\n",
            "Epoch 337/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 967.1691 - val_loss: 419.7807\n",
            "Epoch 338/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 985.6693 - val_loss: 277.3545\n",
            "Epoch 339/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 975.7849 - val_loss: 382.7104\n",
            "Epoch 340/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1001.9760 - val_loss: 304.7336\n",
            "Epoch 341/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 997.7829 - val_loss: 360.9345\n",
            "Epoch 342/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 911.3109 - val_loss: 403.4378\n",
            "Epoch 343/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 976.2574 - val_loss: 386.2630\n",
            "Epoch 344/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 961.3630 - val_loss: 356.2709\n",
            "Epoch 345/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 958.6481 - val_loss: 335.8191\n",
            "Epoch 346/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 878.0275 - val_loss: 407.8705\n",
            "Epoch 347/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 964.4463 - val_loss: 463.4650\n",
            "Epoch 348/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1036.3223 - val_loss: 340.0416\n",
            "Epoch 349/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 960.9500 - val_loss: 361.4602\n",
            "Epoch 350/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 985.6102 - val_loss: 366.2571\n",
            "Epoch 351/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1022.1843 - val_loss: 437.8403\n",
            "Epoch 352/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1061.5631 - val_loss: 334.0818\n",
            "Epoch 353/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 985.3088 - val_loss: 378.8422\n",
            "Epoch 354/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 944.7020 - val_loss: 359.8277\n",
            "Epoch 355/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 944.7768 - val_loss: 440.6709\n",
            "Epoch 356/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 984.0292 - val_loss: 333.7490\n",
            "Epoch 357/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1007.7130 - val_loss: 378.0132\n",
            "Epoch 358/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1056.0764 - val_loss: 454.3132\n",
            "Epoch 359/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1006.0323 - val_loss: 363.7112\n",
            "Epoch 360/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 974.9417 - val_loss: 368.1251\n",
            "Epoch 361/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 966.3994 - val_loss: 379.0873\n",
            "Epoch 362/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 961.3904 - val_loss: 380.3677\n",
            "Epoch 363/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 958.6406 - val_loss: 339.8617\n",
            "Epoch 364/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 944.6096 - val_loss: 347.5026\n",
            "Epoch 365/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 938.7839 - val_loss: 326.2704\n",
            "Epoch 366/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 995.6967 - val_loss: 315.3391\n",
            "Epoch 367/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 968.9980 - val_loss: 315.4312\n",
            "Epoch 368/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 933.5250 - val_loss: 297.7787\n",
            "Epoch 369/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 996.8624 - val_loss: 322.9600\n",
            "Epoch 370/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1002.5578 - val_loss: 335.9304\n",
            "Epoch 371/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 955.0169 - val_loss: 415.2722\n",
            "Epoch 372/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 912.8152 - val_loss: 352.6773\n",
            "Epoch 373/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 988.7132 - val_loss: 330.9927\n",
            "Epoch 374/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 964.3766 - val_loss: 240.6344\n",
            "Epoch 375/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 958.5739 - val_loss: 308.8800\n",
            "Epoch 376/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 965.1981 - val_loss: 371.9405\n",
            "Epoch 377/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 980.4324 - val_loss: 360.9833\n",
            "Epoch 378/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 891.1744 - val_loss: 381.3850\n",
            "Epoch 379/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 967.0612 - val_loss: 372.4912\n",
            "Epoch 380/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 954.8812 - val_loss: 358.3571\n",
            "Epoch 381/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 994.1752 - val_loss: 335.1284\n",
            "Epoch 382/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 915.6448 - val_loss: 407.4287\n",
            "Epoch 383/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 953.7499 - val_loss: 323.8552\n",
            "Epoch 384/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 980.4365 - val_loss: 460.3385\n",
            "Epoch 385/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 937.8502 - val_loss: 316.2281\n",
            "Epoch 386/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 928.3580 - val_loss: 372.6647\n",
            "Epoch 387/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 952.8140 - val_loss: 335.2868\n",
            "Epoch 388/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 932.2093 - val_loss: 390.5916\n",
            "Epoch 389/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 956.0715 - val_loss: 283.9917\n",
            "Epoch 390/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 889.6252 - val_loss: 308.6379\n",
            "Epoch 391/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 988.1178 - val_loss: 351.4183\n",
            "Epoch 392/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 939.0533 - val_loss: 355.7978\n",
            "Epoch 393/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 978.9387 - val_loss: 392.3000\n",
            "Epoch 394/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 962.9254 - val_loss: 363.2800\n",
            "Epoch 395/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 925.2587 - val_loss: 443.9068\n",
            "Epoch 396/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 931.8382 - val_loss: 362.6272\n",
            "Epoch 397/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1000.9846 - val_loss: 323.2749\n",
            "Epoch 398/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 888.7424 - val_loss: 360.8398\n",
            "Epoch 399/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 940.6731 - val_loss: 343.7255\n",
            "Epoch 400/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 876.9198 - val_loss: 424.0237\n",
            "Epoch 401/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 916.1475 - val_loss: 373.8488\n",
            "Epoch 402/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 928.1730 - val_loss: 333.4027\n",
            "Epoch 403/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 900.8236 - val_loss: 365.2050\n",
            "Epoch 404/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 946.0232 - val_loss: 347.4838\n",
            "Epoch 405/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 916.3868 - val_loss: 348.9203\n",
            "Epoch 406/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 932.5874 - val_loss: 402.8546\n",
            "Epoch 407/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 942.6329 - val_loss: 312.7920\n",
            "Epoch 408/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 947.0291 - val_loss: 270.3164\n",
            "Epoch 409/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 921.0921 - val_loss: 314.4217\n",
            "Epoch 410/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 880.7206 - val_loss: 336.3027\n",
            "Epoch 411/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 869.1510 - val_loss: 337.6983\n",
            "Epoch 412/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 867.6504 - val_loss: 416.6017\n",
            "Epoch 413/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 955.6588 - val_loss: 323.3063\n",
            "Epoch 414/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 934.1084 - val_loss: 376.5985\n",
            "Epoch 415/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 925.6318 - val_loss: 365.2650\n",
            "Epoch 416/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 887.8878 - val_loss: 355.2938\n",
            "Epoch 417/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 907.0321 - val_loss: 341.0161\n",
            "Epoch 418/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 902.8958 - val_loss: 313.3302\n",
            "Epoch 419/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 909.4936 - val_loss: 326.3387\n",
            "Epoch 420/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 872.5892 - val_loss: 360.2921\n",
            "Epoch 421/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 932.1990 - val_loss: 270.8738\n",
            "Epoch 422/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 947.5197 - val_loss: 296.2660\n",
            "Epoch 423/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 900.1682 - val_loss: 389.1306\n",
            "Epoch 424/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 823.3558 - val_loss: 289.4687\n",
            "Epoch 425/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 909.2133 - val_loss: 321.4231\n",
            "Epoch 426/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 897.2539 - val_loss: 387.4837\n",
            "Epoch 427/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 960.3045 - val_loss: 416.1109\n",
            "Epoch 428/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 884.2527 - val_loss: 345.7325\n",
            "Epoch 429/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 930.7122 - val_loss: 385.1127\n",
            "Epoch 430/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 921.8302 - val_loss: 428.1819\n",
            "Epoch 431/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 864.2006 - val_loss: 272.7082\n",
            "Epoch 432/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 919.4878 - val_loss: 314.1616\n",
            "Epoch 433/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 877.9455 - val_loss: 325.3349\n",
            "Epoch 434/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 945.7548 - val_loss: 299.2564\n",
            "Epoch 435/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 945.1155 - val_loss: 377.2314\n",
            "Epoch 436/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 898.8856 - val_loss: 310.2746\n",
            "Epoch 437/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 881.1165 - val_loss: 357.6511\n",
            "Epoch 438/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 883.3193 - val_loss: 298.3535\n",
            "Epoch 439/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 873.4171 - val_loss: 310.0097\n",
            "Epoch 440/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 923.8228 - val_loss: 327.0485\n",
            "Epoch 441/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 868.8360 - val_loss: 372.9299\n",
            "Epoch 442/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 907.8807 - val_loss: 369.1299\n",
            "Epoch 443/2000\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 873.2714 - val_loss: 414.8388\n",
            "Epoch 444/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 899.0900 - val_loss: 320.3142\n",
            "Epoch 445/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 919.8680 - val_loss: 270.0185\n",
            "Epoch 446/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 890.5663 - val_loss: 401.9633\n",
            "Epoch 447/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 828.0847 - val_loss: 406.3676\n",
            "Epoch 448/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 910.3093 - val_loss: 335.3875\n",
            "Epoch 449/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 910.3729 - val_loss: 394.8296\n",
            "Epoch 450/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 940.5547 - val_loss: 315.2059\n",
            "Epoch 451/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 853.7156 - val_loss: 327.5125\n",
            "Epoch 452/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 924.0632 - val_loss: 317.4949\n",
            "Epoch 453/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 858.8202 - val_loss: 340.6306\n",
            "Epoch 454/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 900.3148 - val_loss: 356.2229\n",
            "Epoch 455/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 898.5887 - val_loss: 290.8373\n",
            "Epoch 456/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 886.6749 - val_loss: 401.1740\n",
            "Epoch 457/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 907.3438 - val_loss: 337.4977\n",
            "Epoch 458/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 904.2874 - val_loss: 398.1306\n",
            "Epoch 459/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 912.3593 - val_loss: 312.8966\n",
            "Epoch 460/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 896.1509 - val_loss: 301.7455\n",
            "Epoch 461/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 882.1761 - val_loss: 334.5876\n",
            "Epoch 462/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 876.7951 - val_loss: 378.2362\n",
            "Epoch 463/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 868.6678 - val_loss: 336.8088\n",
            "Epoch 464/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 883.8618 - val_loss: 350.2232\n",
            "Epoch 465/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 831.0565 - val_loss: 293.0997\n",
            "Epoch 466/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 927.4052 - val_loss: 352.2324\n",
            "Epoch 467/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 859.9330 - val_loss: 282.4216\n",
            "Epoch 468/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 821.5046 - val_loss: 383.2539\n",
            "Epoch 469/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 919.7963 - val_loss: 348.0809\n",
            "Epoch 470/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 863.5764 - val_loss: 345.5377\n",
            "Epoch 471/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 887.1481 - val_loss: 382.2807\n",
            "Epoch 472/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 923.0867 - val_loss: 450.0067\n",
            "Epoch 473/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 860.4763 - val_loss: 337.9032\n",
            "Epoch 474/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 892.9734 - val_loss: 279.1776\n",
            "Epoch 475/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 776.9758 - val_loss: 318.5933\n",
            "Epoch 476/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 901.2074 - val_loss: 322.1358\n",
            "Epoch 477/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 897.4841 - val_loss: 381.0240\n",
            "Epoch 478/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 909.9257 - val_loss: 327.2746\n",
            "Epoch 479/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 898.1230 - val_loss: 272.3848\n",
            "Epoch 480/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 851.0575 - val_loss: 336.7879\n",
            "Epoch 481/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 854.8946 - val_loss: 326.2772\n",
            "Epoch 482/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 872.5787 - val_loss: 314.6876\n",
            "Epoch 483/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 925.3032 - val_loss: 330.7935\n",
            "Epoch 484/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 898.6226 - val_loss: 347.5215\n",
            "Epoch 485/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 891.2270 - val_loss: 278.2466\n",
            "Epoch 486/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 834.8702 - val_loss: 339.5195\n",
            "Epoch 487/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 941.4380 - val_loss: 380.2631\n",
            "Epoch 488/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 858.2105 - val_loss: 425.3177\n",
            "Epoch 489/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 882.4080 - val_loss: 357.0382\n",
            "Epoch 490/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 889.3124 - val_loss: 379.3874\n",
            "Epoch 491/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 870.2419 - val_loss: 313.5699\n",
            "Epoch 492/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 904.3135 - val_loss: 360.0703\n",
            "Epoch 493/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 889.7618 - val_loss: 320.8582\n",
            "Epoch 494/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 913.8582 - val_loss: 342.0818\n",
            "Epoch 495/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 918.3572 - val_loss: 415.8925\n",
            "Epoch 496/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 835.1418 - val_loss: 307.2581\n",
            "Epoch 497/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 902.2198 - val_loss: 298.3012\n",
            "Epoch 498/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 873.9445 - val_loss: 286.4130\n",
            "Epoch 499/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 813.5814 - val_loss: 336.5295\n",
            "Epoch 500/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 834.0562 - val_loss: 328.6434\n",
            "Epoch 501/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 853.9849 - val_loss: 322.5094\n",
            "Epoch 502/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 885.3982 - val_loss: 351.5961\n",
            "Epoch 503/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 873.3763 - val_loss: 340.2311\n",
            "Epoch 504/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 838.7886 - val_loss: 269.5455\n",
            "Epoch 505/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 864.6057 - val_loss: 368.7253\n",
            "Epoch 506/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 860.5295 - val_loss: 369.8359\n",
            "Epoch 507/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 828.9443 - val_loss: 324.1588\n",
            "Epoch 508/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 812.4308 - val_loss: 282.0823\n",
            "Epoch 509/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 812.3260 - val_loss: 268.6884\n",
            "Epoch 510/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 813.8199 - val_loss: 317.1481\n",
            "Epoch 511/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 880.0572 - val_loss: 265.4264\n",
            "Epoch 512/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 846.4991 - val_loss: 327.4996\n",
            "Epoch 513/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 788.4989 - val_loss: 295.1185\n",
            "Epoch 514/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 890.1068 - val_loss: 429.2623\n",
            "Epoch 515/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 887.9669 - val_loss: 350.4035\n",
            "Epoch 516/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 854.6093 - val_loss: 317.2717\n",
            "Epoch 517/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 825.0583 - val_loss: 273.8542\n",
            "Epoch 518/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 851.2927 - val_loss: 306.1367\n",
            "Epoch 519/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 887.4686 - val_loss: 296.8762\n",
            "Epoch 520/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 882.8983 - val_loss: 304.7627\n",
            "Epoch 521/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 873.5131 - val_loss: 312.7286\n",
            "Epoch 522/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 885.3851 - val_loss: 302.2609\n",
            "Epoch 523/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 878.2335 - val_loss: 364.0276\n",
            "Epoch 524/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 862.8266 - val_loss: 366.5394\n",
            "Epoch 525/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 837.2405 - val_loss: 337.6220\n",
            "Epoch 526/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 837.5466 - val_loss: 298.9208\n",
            "Epoch 527/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 807.6434 - val_loss: 307.4953\n",
            "Epoch 528/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 819.8794 - val_loss: 311.8658\n",
            "Epoch 529/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 847.7989 - val_loss: 320.7418\n",
            "Epoch 530/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 843.5426 - val_loss: 372.3539\n",
            "Epoch 531/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 801.2523 - val_loss: 329.3561\n",
            "Epoch 532/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 876.8520 - val_loss: 333.1469\n",
            "Epoch 533/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 804.7103 - val_loss: 353.5940\n",
            "Epoch 534/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 830.4787 - val_loss: 259.0291\n",
            "Epoch 535/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 844.4314 - val_loss: 330.6326\n",
            "Epoch 536/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 862.6929 - val_loss: 301.8216\n",
            "Epoch 537/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 845.6592 - val_loss: 283.5143\n",
            "Epoch 538/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 807.5420 - val_loss: 273.8088\n",
            "Epoch 539/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 815.6229 - val_loss: 322.6357\n",
            "Epoch 540/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 889.9030 - val_loss: 282.7820\n",
            "Epoch 541/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 873.5908 - val_loss: 314.7072\n",
            "Epoch 542/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 851.5017 - val_loss: 314.6723\n",
            "Epoch 543/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 834.4347 - val_loss: 367.9456\n",
            "Epoch 544/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 813.1145 - val_loss: 334.5611\n",
            "Epoch 545/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 865.1749 - val_loss: 447.4204\n",
            "Epoch 546/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 828.7111 - val_loss: 270.4011\n",
            "Epoch 547/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 890.5984 - val_loss: 315.6604\n",
            "Epoch 548/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 877.4073 - val_loss: 333.9130\n",
            "Epoch 549/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 849.7892 - val_loss: 303.7730\n",
            "Epoch 550/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 815.1385 - val_loss: 304.3709\n",
            "Epoch 551/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 842.5822 - val_loss: 412.1863\n",
            "Epoch 552/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 844.7128 - val_loss: 298.5102\n",
            "Epoch 553/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 920.6439 - val_loss: 378.6180\n",
            "Epoch 554/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 892.7444 - val_loss: 317.5476\n",
            "Epoch 555/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 777.8848 - val_loss: 288.9846\n",
            "Epoch 556/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 831.0889 - val_loss: 300.8697\n",
            "Epoch 557/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 857.5109 - val_loss: 282.5034\n",
            "Epoch 558/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 877.0850 - val_loss: 302.1315\n",
            "Epoch 559/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 916.0802 - val_loss: 342.7682\n",
            "Epoch 560/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 841.9396 - val_loss: 357.4122\n",
            "Epoch 561/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 861.8651 - val_loss: 367.9957\n",
            "Epoch 562/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 775.9201 - val_loss: 305.5212\n",
            "Epoch 563/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 876.4753 - val_loss: 251.6151\n",
            "Epoch 564/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 826.6683 - val_loss: 415.3721\n",
            "Epoch 565/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 846.4221 - val_loss: 300.7605\n",
            "Epoch 566/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 796.6637 - val_loss: 297.6158\n",
            "Epoch 567/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 822.5010 - val_loss: 323.3187\n",
            "Epoch 568/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 841.1050 - val_loss: 315.6349\n",
            "Epoch 569/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 827.2951 - val_loss: 356.7458\n",
            "Epoch 570/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 765.2622 - val_loss: 414.8120\n",
            "Epoch 571/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 830.3231 - val_loss: 368.0788\n",
            "Epoch 572/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 862.9921 - val_loss: 266.7385\n",
            "Epoch 573/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 814.1562 - val_loss: 401.6650\n",
            "Epoch 574/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 840.8754 - val_loss: 291.3563\n",
            "Epoch 575/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 767.8449 - val_loss: 361.7439\n",
            "Epoch 576/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 868.4740 - val_loss: 308.6531\n",
            "Epoch 577/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 830.2085 - val_loss: 331.6863\n",
            "Epoch 578/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 807.2004 - val_loss: 371.5045\n",
            "Epoch 579/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 797.3401 - val_loss: 339.1995\n",
            "Epoch 580/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 814.3456 - val_loss: 314.4045\n",
            "Epoch 581/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 802.4351 - val_loss: 296.6913\n",
            "Epoch 582/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 835.3259 - val_loss: 335.6875\n",
            "Epoch 583/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 806.5186 - val_loss: 299.0545\n",
            "Epoch 584/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 818.2001 - val_loss: 308.0934\n",
            "Epoch 585/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 786.8291 - val_loss: 383.6512\n",
            "Epoch 586/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 842.7687 - val_loss: 335.4299\n",
            "Epoch 587/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 779.1599 - val_loss: 329.5042\n",
            "Epoch 588/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 829.2505 - val_loss: 334.2346\n",
            "Epoch 589/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 811.2727 - val_loss: 295.6259\n",
            "Epoch 590/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 744.8452 - val_loss: 325.1967\n",
            "Epoch 591/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 785.2999 - val_loss: 333.2460\n",
            "Epoch 592/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 815.8647 - val_loss: 359.5536\n",
            "Epoch 593/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 815.1800 - val_loss: 339.0319\n",
            "Epoch 594/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 803.4913 - val_loss: 345.4040\n",
            "Epoch 595/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 849.7311 - val_loss: 315.3972\n",
            "Epoch 596/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 759.2916 - val_loss: 334.8132\n",
            "Epoch 597/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 823.7562 - val_loss: 362.5280\n",
            "Epoch 598/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 810.3295 - val_loss: 366.2041\n",
            "Epoch 599/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 805.3555 - val_loss: 306.7512\n",
            "Epoch 600/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 797.8576 - val_loss: 321.7832\n",
            "Epoch 601/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 804.1218 - val_loss: 292.2546\n",
            "Epoch 602/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 776.6274 - val_loss: 348.9700\n",
            "Epoch 603/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 746.0500 - val_loss: 324.9188\n",
            "Epoch 604/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 817.3391 - val_loss: 310.0093\n",
            "Epoch 605/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 794.4523 - val_loss: 342.7838\n",
            "Epoch 606/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 814.1494 - val_loss: 390.0116\n",
            "Epoch 607/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 825.3517 - val_loss: 351.9296\n",
            "Epoch 608/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 817.0738 - val_loss: 297.6069\n",
            "Epoch 609/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 798.0052 - val_loss: 262.1563\n",
            "Epoch 610/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 755.3698 - val_loss: 321.1514\n",
            "Epoch 611/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 765.7606 - val_loss: 309.0707\n",
            "Epoch 612/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 790.1464 - val_loss: 364.2171\n",
            "Epoch 613/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 804.3488 - val_loss: 406.2169\n",
            "Epoch 614/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 736.2397 - val_loss: 286.7520\n",
            "Epoch 615/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 736.3407 - val_loss: 340.2772\n",
            "Epoch 616/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 761.4044 - val_loss: 299.3810\n",
            "Epoch 617/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 813.1731 - val_loss: 306.5962\n",
            "Epoch 618/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 786.8549 - val_loss: 258.8869\n",
            "Epoch 619/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 807.6865 - val_loss: 326.2043\n",
            "Epoch 620/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 781.6141 - val_loss: 281.8525\n",
            "Epoch 621/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 761.2146 - val_loss: 287.8759\n",
            "Epoch 622/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 800.7810 - val_loss: 280.1037\n",
            "Epoch 623/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 788.0089 - val_loss: 268.5061\n",
            "Epoch 624/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 772.1888 - val_loss: 349.9221\n",
            "Epoch 625/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 819.0259 - val_loss: 313.9584\n",
            "Epoch 626/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 821.2855 - val_loss: 288.2940\n",
            "Epoch 627/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 803.9448 - val_loss: 324.0015\n",
            "Epoch 628/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 774.4085 - val_loss: 320.0564\n",
            "Epoch 629/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 768.3672 - val_loss: 431.4581\n",
            "Epoch 630/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 792.7415 - val_loss: 323.5464\n",
            "Epoch 631/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 850.8088 - val_loss: 307.0790\n",
            "Epoch 632/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 761.5219 - val_loss: 267.7690\n",
            "Epoch 633/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 773.1290 - val_loss: 302.5516\n",
            "Epoch 634/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 778.0508 - val_loss: 373.3494\n",
            "Epoch 635/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 795.6363 - val_loss: 335.4592\n",
            "Epoch 636/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 793.8384 - val_loss: 306.1174\n",
            "Epoch 637/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 778.8243 - val_loss: 429.9716\n",
            "Epoch 638/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 801.1329 - val_loss: 375.9098\n",
            "Epoch 639/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 739.1594 - val_loss: 312.0037\n",
            "Epoch 640/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 737.9299 - val_loss: 300.9127\n",
            "Epoch 641/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 774.7159 - val_loss: 275.9590\n",
            "Epoch 642/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 761.7474 - val_loss: 302.9095\n",
            "Epoch 643/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 814.1913 - val_loss: 293.5646\n",
            "Epoch 644/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 772.7979 - val_loss: 249.0422\n",
            "Epoch 645/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 797.6587 - val_loss: 345.3900\n",
            "Epoch 646/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 725.4511 - val_loss: 329.6511\n",
            "Epoch 647/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 799.5468 - val_loss: 302.6440\n",
            "Epoch 648/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 719.4745 - val_loss: 261.1753\n",
            "Epoch 649/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 792.1821 - val_loss: 350.0562\n",
            "Epoch 650/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 746.6022 - val_loss: 320.7551\n",
            "Epoch 651/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 771.4540 - val_loss: 313.8632\n",
            "Epoch 652/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 778.0189 - val_loss: 292.9274\n",
            "Epoch 653/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 820.4692 - val_loss: 349.2882\n",
            "Epoch 654/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 758.4967 - val_loss: 448.6225\n",
            "Epoch 655/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 784.8455 - val_loss: 325.8404\n",
            "Epoch 656/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 739.5649 - val_loss: 290.9088\n",
            "Epoch 657/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 749.6133 - val_loss: 273.9451\n",
            "Epoch 658/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 799.0751 - val_loss: 304.6535\n",
            "Epoch 659/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 771.8361 - val_loss: 349.2788\n",
            "Epoch 660/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 786.8466 - val_loss: 317.0885\n",
            "Epoch 661/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 800.0475 - val_loss: 260.9860\n",
            "Epoch 662/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 801.2526 - val_loss: 364.1093\n",
            "Epoch 663/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 803.0128 - val_loss: 336.3932\n",
            "Epoch 664/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 765.9879 - val_loss: 367.0094\n",
            "Epoch 665/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 744.2531 - val_loss: 267.8561\n",
            "Epoch 666/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 812.9825 - val_loss: 345.2229\n",
            "Epoch 667/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 736.3019 - val_loss: 322.4153\n",
            "Epoch 668/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 767.6660 - val_loss: 386.9877\n",
            "Epoch 669/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 781.5652 - val_loss: 331.8182\n",
            "Epoch 670/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 775.5940 - val_loss: 282.5060\n",
            "Epoch 671/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 725.1330 - val_loss: 302.8550\n",
            "Epoch 672/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 770.6158 - val_loss: 293.6476\n",
            "Epoch 673/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 741.2095 - val_loss: 316.3557\n",
            "Epoch 674/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 691.7950 - val_loss: 310.4810\n",
            "Epoch 675/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 759.3118 - val_loss: 370.7313\n",
            "Epoch 676/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 736.9591 - val_loss: 399.7439\n",
            "Epoch 677/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 770.7717 - val_loss: 345.9245\n",
            "Epoch 678/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 794.2151 - val_loss: 320.7900\n",
            "Epoch 679/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 735.9784 - val_loss: 357.4491\n",
            "Epoch 680/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 771.7106 - val_loss: 337.2825\n",
            "Epoch 681/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 795.0473 - val_loss: 317.9601\n",
            "Epoch 682/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 790.1810 - val_loss: 368.3370\n",
            "Epoch 683/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 762.8046 - val_loss: 287.8209\n",
            "Epoch 684/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 727.4430 - val_loss: 387.7668\n",
            "Epoch 685/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 731.9814 - val_loss: 336.9990\n",
            "Epoch 686/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 773.9211 - val_loss: 293.2347\n",
            "Epoch 687/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 799.6216 - val_loss: 344.5348\n",
            "Epoch 688/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 759.7714 - val_loss: 370.3675\n",
            "Epoch 689/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 750.5798 - val_loss: 319.3375\n",
            "Epoch 690/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 754.0039 - val_loss: 361.3627\n",
            "Epoch 691/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 815.1986 - val_loss: 467.1832\n",
            "Epoch 692/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 732.7990 - val_loss: 404.1580\n",
            "Epoch 693/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 750.7308 - val_loss: 331.6827\n",
            "Epoch 694/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 757.6961 - val_loss: 311.6386\n",
            "Epoch 695/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 714.9904 - val_loss: 313.0667\n",
            "Epoch 696/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 775.5796 - val_loss: 347.0270\n",
            "Epoch 697/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 728.8516 - val_loss: 316.7054\n",
            "Epoch 698/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 766.7204 - val_loss: 341.0708\n",
            "Epoch 699/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 799.5823 - val_loss: 403.8705\n",
            "Epoch 700/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 763.6335 - val_loss: 343.7841\n",
            "Epoch 701/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 766.7034 - val_loss: 314.4451\n",
            "Epoch 702/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 734.7631 - val_loss: 311.8438\n",
            "Epoch 703/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 756.6808 - val_loss: 380.3038\n",
            "Epoch 704/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 730.7256 - val_loss: 315.4296\n",
            "Epoch 705/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 728.6884 - val_loss: 358.7763\n",
            "Epoch 706/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 753.0363 - val_loss: 377.9493\n",
            "Epoch 707/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 814.7997 - val_loss: 387.3129\n",
            "Epoch 708/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 730.2143 - val_loss: 298.4156\n",
            "Epoch 709/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 731.5235 - val_loss: 333.3994\n",
            "Epoch 710/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 791.4285 - val_loss: 360.4909\n",
            "Epoch 711/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 731.3335 - val_loss: 339.4210\n",
            "Epoch 712/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 787.3155 - val_loss: 338.6778\n",
            "Epoch 713/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 756.9581 - val_loss: 310.1022\n",
            "Epoch 714/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 773.4403 - val_loss: 406.4034\n",
            "Epoch 715/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 731.8120 - val_loss: 312.4586\n",
            "Epoch 716/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 762.8969 - val_loss: 304.0954\n",
            "Epoch 717/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 703.0682 - val_loss: 294.2673\n",
            "Epoch 718/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 791.5777 - val_loss: 309.3663\n",
            "Epoch 719/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 762.3090 - val_loss: 313.8247\n",
            "Epoch 720/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 730.8787 - val_loss: 372.1358\n",
            "Epoch 721/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 685.7363 - val_loss: 341.6109\n",
            "Epoch 722/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 743.0049 - val_loss: 357.3594\n",
            "Epoch 723/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 698.2632 - val_loss: 322.6657\n",
            "Epoch 724/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 770.9380 - val_loss: 389.8562\n",
            "Epoch 725/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 712.0997 - val_loss: 349.1158\n",
            "Epoch 726/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 755.3512 - val_loss: 374.4393\n",
            "Epoch 727/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 758.2347 - val_loss: 384.1765\n",
            "Epoch 728/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 711.9477 - val_loss: 323.8901\n",
            "Epoch 729/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 742.4304 - val_loss: 349.3600\n",
            "Epoch 730/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 734.3718 - val_loss: 330.2061\n",
            "Epoch 731/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 687.7883 - val_loss: 266.2105\n",
            "Epoch 732/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 711.8666 - val_loss: 343.4210\n",
            "Epoch 733/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 782.5779 - val_loss: 353.0720\n",
            "Epoch 734/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 738.9438 - val_loss: 347.2424\n",
            "Epoch 735/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 749.8881 - val_loss: 352.9785\n",
            "Epoch 736/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 676.9632 - val_loss: 344.5804\n",
            "Epoch 737/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 724.7642 - val_loss: 341.3038\n",
            "Epoch 738/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 721.9020 - val_loss: 370.5942\n",
            "Epoch 739/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 714.2834 - val_loss: 341.6294\n",
            "Epoch 740/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 796.8832 - val_loss: 345.7750\n",
            "Epoch 741/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 765.8752 - val_loss: 369.5801\n",
            "Epoch 742/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 749.6341 - val_loss: 345.4376\n",
            "Epoch 743/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 706.2103 - val_loss: 393.6552\n",
            "Epoch 744/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 726.7479 - val_loss: 336.6273\n",
            "Epoch 745/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 768.6144 - val_loss: 343.2326\n",
            "Epoch 746/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 799.9291 - val_loss: 375.6416\n",
            "Epoch 747/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 684.7470 - val_loss: 363.4188\n",
            "Epoch 748/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 730.8077 - val_loss: 351.8052\n",
            "Epoch 749/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 718.3452 - val_loss: 359.6396\n",
            "Epoch 750/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 763.1605 - val_loss: 304.9871\n",
            "Epoch 751/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 728.6176 - val_loss: 316.4415\n",
            "Epoch 752/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 726.0532 - val_loss: 319.0350\n",
            "Epoch 753/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 732.5225 - val_loss: 366.6866\n",
            "Epoch 754/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 677.1976 - val_loss: 289.0876\n",
            "Epoch 755/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 762.0180 - val_loss: 305.2559\n",
            "Epoch 756/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 729.3242 - val_loss: 313.0794\n",
            "Epoch 757/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 720.5908 - val_loss: 341.0025\n",
            "Epoch 758/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 746.2281 - val_loss: 327.6003\n",
            "Epoch 759/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 700.8233 - val_loss: 276.2645\n",
            "Epoch 760/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 754.4444 - val_loss: 345.1872\n",
            "Epoch 761/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 746.7286 - val_loss: 325.6859\n",
            "Epoch 762/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 747.5420 - val_loss: 383.8129\n",
            "Epoch 763/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 719.8151 - val_loss: 295.4107\n",
            "Epoch 764/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 738.0563 - val_loss: 333.7224\n",
            "Epoch 765/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 707.7300 - val_loss: 345.5989\n",
            "Epoch 766/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 674.4141 - val_loss: 328.6927\n",
            "Epoch 767/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 721.8896 - val_loss: 339.3471\n",
            "Epoch 768/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 708.8701 - val_loss: 298.4983\n",
            "Epoch 769/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 742.1076 - val_loss: 346.0233\n",
            "Epoch 770/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 741.5858 - val_loss: 378.5671\n",
            "Epoch 771/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 680.2814 - val_loss: 347.1497\n",
            "Epoch 772/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 684.6566 - val_loss: 328.3889\n",
            "Epoch 773/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 711.6804 - val_loss: 271.5080\n",
            "Epoch 774/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 741.2159 - val_loss: 394.9622\n",
            "Epoch 775/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 712.3632 - val_loss: 349.9834\n",
            "Epoch 776/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 753.7501 - val_loss: 331.6596\n",
            "Epoch 777/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 732.2710 - val_loss: 377.4498\n",
            "Epoch 778/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 732.9353 - val_loss: 351.5878\n",
            "Epoch 779/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 724.6309 - val_loss: 356.7424\n",
            "Epoch 780/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 676.7980 - val_loss: 352.9606\n",
            "Epoch 781/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 727.0274 - val_loss: 314.5436\n",
            "Epoch 782/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 718.9318 - val_loss: 281.3209\n",
            "Epoch 783/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 765.0797 - val_loss: 388.7274\n",
            "Epoch 784/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 711.9749 - val_loss: 324.5076\n",
            "Epoch 785/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 718.6262 - val_loss: 319.0716\n",
            "Epoch 786/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 758.4837 - val_loss: 305.3083\n",
            "Epoch 787/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 726.3490 - val_loss: 343.9309\n",
            "Epoch 788/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 732.6708 - val_loss: 316.7550\n",
            "Epoch 789/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 677.8033 - val_loss: 345.7462\n",
            "Epoch 790/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 750.5312 - val_loss: 427.8570\n",
            "Epoch 791/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 703.4956 - val_loss: 327.9806\n",
            "Epoch 792/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 795.6567 - val_loss: 322.7450\n",
            "Epoch 793/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 724.5598 - val_loss: 327.5191\n",
            "Epoch 794/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 690.3901 - val_loss: 342.0244\n",
            "Epoch 795/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 680.0207 - val_loss: 347.7704\n",
            "Epoch 796/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 714.6970 - val_loss: 291.5517\n",
            "Epoch 797/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 757.1310 - val_loss: 267.3799\n",
            "Epoch 798/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 700.6251 - val_loss: 296.0921\n",
            "Epoch 799/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 711.6880 - val_loss: 311.7719\n",
            "Epoch 800/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 713.6210 - val_loss: 314.1695\n",
            "Epoch 801/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 691.8345 - val_loss: 342.6143\n",
            "Epoch 802/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 727.5594 - val_loss: 305.1390\n",
            "Epoch 803/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 733.2567 - val_loss: 324.4494\n",
            "Epoch 804/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 704.9763 - val_loss: 298.7298\n",
            "Epoch 805/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 768.8381 - val_loss: 352.8932\n",
            "Epoch 806/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 725.8472 - val_loss: 343.6054\n",
            "Epoch 807/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 710.7731 - val_loss: 322.4464\n",
            "Epoch 808/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 668.9456 - val_loss: 313.4129\n",
            "Epoch 809/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 709.8983 - val_loss: 382.4609\n",
            "Epoch 810/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 728.8367 - val_loss: 319.3011\n",
            "Epoch 811/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 679.7025 - val_loss: 350.2730\n",
            "Epoch 812/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 738.9589 - val_loss: 328.0209\n",
            "Epoch 813/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 695.5557 - val_loss: 338.2613\n",
            "Epoch 814/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 741.7079 - val_loss: 333.9827\n",
            "Epoch 815/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 706.9418 - val_loss: 321.6532\n",
            "Epoch 816/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 679.1784 - val_loss: 325.0394\n",
            "Epoch 817/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 687.6345 - val_loss: 342.8959\n",
            "Epoch 818/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 727.5197 - val_loss: 402.4068\n",
            "Epoch 819/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 673.6186 - val_loss: 356.4138\n",
            "Epoch 820/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 761.8651 - val_loss: 326.7265\n",
            "Epoch 821/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 680.8480 - val_loss: 377.7083\n",
            "Epoch 822/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 729.5804 - val_loss: 277.3766\n",
            "Epoch 823/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 705.0553 - val_loss: 295.6287\n",
            "Epoch 824/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 691.7310 - val_loss: 334.8720\n",
            "Epoch 825/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 694.4835 - val_loss: 315.3383\n",
            "Epoch 826/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 690.7471 - val_loss: 346.1975\n",
            "Epoch 827/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 674.1118 - val_loss: 362.2095\n",
            "Epoch 828/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 727.7603 - val_loss: 317.3578\n",
            "Epoch 829/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 707.1483 - val_loss: 332.0205\n",
            "Epoch 830/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 729.8217 - val_loss: 337.7421\n",
            "Epoch 831/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 663.8319 - val_loss: 379.7501\n",
            "Epoch 832/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 687.4548 - val_loss: 334.8191\n",
            "Epoch 833/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 679.9362 - val_loss: 284.6223\n",
            "Epoch 834/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 719.1040 - val_loss: 325.9455\n",
            "Epoch 835/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 729.5085 - val_loss: 298.3877\n",
            "Epoch 836/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 720.2490 - val_loss: 317.2353\n",
            "Epoch 837/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 648.4672 - val_loss: 341.4349\n",
            "Epoch 838/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 699.2672 - val_loss: 283.0235\n",
            "Epoch 839/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 698.8107 - val_loss: 306.0709\n",
            "Epoch 840/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 726.4107 - val_loss: 390.1480\n",
            "Epoch 841/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 691.2951 - val_loss: 400.4734\n",
            "Epoch 842/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 730.6783 - val_loss: 342.7780\n",
            "Epoch 843/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 700.3023 - val_loss: 356.4219\n",
            "Epoch 844/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 723.8673 - val_loss: 332.3399\n",
            "Epoch 845/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 699.9860 - val_loss: 267.6273\n",
            "Epoch 846/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 730.1657 - val_loss: 272.3728\n",
            "Epoch 847/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 731.1825 - val_loss: 317.9726\n",
            "Epoch 848/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 674.3560 - val_loss: 283.2955\n",
            "Epoch 849/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 711.8271 - val_loss: 403.3612\n",
            "Epoch 850/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 711.7002 - val_loss: 345.0644\n",
            "Epoch 851/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 715.4079 - val_loss: 365.9728\n",
            "Epoch 852/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 682.8964 - val_loss: 314.3704\n",
            "Epoch 853/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 732.4245 - val_loss: 347.6315\n",
            "Epoch 854/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 708.1566 - val_loss: 365.8715\n",
            "Epoch 855/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 693.2953 - val_loss: 383.3914\n",
            "Epoch 856/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 693.7621 - val_loss: 377.4433\n",
            "Epoch 857/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 675.9276 - val_loss: 311.9346\n",
            "Epoch 858/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 645.8076 - val_loss: 293.6827\n",
            "Epoch 859/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 718.1838 - val_loss: 322.9406\n",
            "Epoch 860/2000\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 674.7666 - val_loss: 315.5784\n",
            "Epoch 861/2000\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 717.3396 - val_loss: 309.1744\n",
            "Epoch 862/2000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 673.0693 - val_loss: 402.0408\n",
            "Epoch 863/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 729.9796 - val_loss: 348.6251\n",
            "Epoch 864/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 661.6265 - val_loss: 338.2874\n",
            "Epoch 865/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 696.6113 - val_loss: 283.5784\n",
            "Epoch 866/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 697.0205 - val_loss: 338.4822\n",
            "Epoch 867/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 709.4415 - val_loss: 308.7094\n",
            "Epoch 868/2000\n",
            "44/44 [==============================] - 1s 11ms/step - loss: 723.6559 - val_loss: 287.0440\n",
            "Epoch 869/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 702.0039 - val_loss: 305.5641\n",
            "Epoch 870/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 632.8572 - val_loss: 313.2678\n",
            "Epoch 871/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 697.5042 - val_loss: 326.8082\n",
            "Epoch 872/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 649.0461 - val_loss: 313.5793\n",
            "Epoch 873/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 687.6156 - val_loss: 300.2113\n",
            "Epoch 874/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 716.9544 - val_loss: 333.5609\n",
            "Epoch 875/2000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 665.1089 - val_loss: 294.6578\n",
            "Epoch 876/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 663.5427 - val_loss: 381.4426\n",
            "Epoch 877/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 648.8198 - val_loss: 298.5596\n",
            "Epoch 878/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 653.9160 - val_loss: 316.8065\n",
            "Epoch 879/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 711.0601 - val_loss: 384.9142\n",
            "Epoch 880/2000\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 651.2953 - val_loss: 335.8231\n",
            "Epoch 881/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 707.9636 - val_loss: 323.3353\n",
            "Epoch 882/2000\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 680.2746 - val_loss: 309.3209\n",
            "Epoch 883/2000\n",
            "44/44 [==============================] - 1s 11ms/step - loss: 708.8802 - val_loss: 350.1726\n",
            "Epoch 884/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 648.6561 - val_loss: 293.3462\n",
            "Epoch 885/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 715.4735 - val_loss: 356.7471\n",
            "Epoch 886/2000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 689.8120 - val_loss: 369.7475\n",
            "Epoch 887/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 760.9501 - val_loss: 447.7704\n",
            "Epoch 888/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 706.1057 - val_loss: 381.8581\n",
            "Epoch 889/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 647.3761 - val_loss: 361.7613\n",
            "Epoch 890/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 672.2615 - val_loss: 334.8055\n",
            "Epoch 891/2000\n",
            "44/44 [==============================] - 1s 14ms/step - loss: 675.6966 - val_loss: 295.1867\n",
            "Epoch 892/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 662.8489 - val_loss: 373.1071\n",
            "Epoch 893/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 679.0311 - val_loss: 340.1213\n",
            "Epoch 894/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 692.5971 - val_loss: 355.5768\n",
            "Epoch 895/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 690.1089 - val_loss: 338.7271\n",
            "Epoch 896/2000\n",
            "44/44 [==============================] - 1s 12ms/step - loss: 714.6163 - val_loss: 329.0020\n",
            "Epoch 897/2000\n",
            "44/44 [==============================] - 1s 15ms/step - loss: 696.1218 - val_loss: 307.2753\n",
            "Epoch 898/2000\n",
            "44/44 [==============================] - 1s 16ms/step - loss: 698.0171 - val_loss: 287.4682\n",
            "Epoch 899/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 671.6852 - val_loss: 347.0855\n",
            "Epoch 900/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 732.9569 - val_loss: 335.5258\n",
            "Epoch 901/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 719.1427 - val_loss: 333.5593\n",
            "Epoch 902/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 702.0632 - val_loss: 326.3331\n",
            "Epoch 903/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 716.2194 - val_loss: 335.2475\n",
            "Epoch 904/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 711.7474 - val_loss: 356.5802\n",
            "Epoch 905/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 694.8489 - val_loss: 336.0822\n",
            "Epoch 906/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 698.4493 - val_loss: 367.5172\n",
            "Epoch 907/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 720.7213 - val_loss: 295.0090\n",
            "Epoch 908/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 722.6176 - val_loss: 287.1478\n",
            "Epoch 909/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 682.1519 - val_loss: 304.4673\n",
            "Epoch 910/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 685.8957 - val_loss: 304.2666\n",
            "Epoch 911/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 732.6601 - val_loss: 326.9419\n",
            "Epoch 912/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 744.4150 - val_loss: 334.5320\n",
            "Epoch 913/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 695.7430 - val_loss: 360.4932\n",
            "Epoch 914/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 684.5256 - val_loss: 344.4645\n",
            "Epoch 915/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 695.1782 - val_loss: 293.5276\n",
            "Epoch 916/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 735.7202 - val_loss: 317.8618\n",
            "Epoch 917/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 653.2278 - val_loss: 353.0634\n",
            "Epoch 918/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 664.5745 - val_loss: 343.9018\n",
            "Epoch 919/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 678.3726 - val_loss: 335.2296\n",
            "Epoch 920/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 643.9762 - val_loss: 312.3066\n",
            "Epoch 921/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 682.2968 - val_loss: 407.4844\n",
            "Epoch 922/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 682.2582 - val_loss: 319.1028\n",
            "Epoch 923/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 689.5459 - val_loss: 338.2679\n",
            "Epoch 924/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 691.4643 - val_loss: 384.3780\n",
            "Epoch 925/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 694.5832 - val_loss: 310.2090\n",
            "Epoch 926/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 710.9587 - val_loss: 331.6484\n",
            "Epoch 927/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 675.0484 - val_loss: 328.3455\n",
            "Epoch 928/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 676.5967 - val_loss: 288.5208\n",
            "Epoch 929/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.3442 - val_loss: 255.0209\n",
            "Epoch 930/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 706.3250 - val_loss: 338.1905\n",
            "Epoch 931/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 695.9579 - val_loss: 309.5710\n",
            "Epoch 932/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 691.9293 - val_loss: 274.2709\n",
            "Epoch 933/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 724.2486 - val_loss: 358.8523\n",
            "Epoch 934/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 692.8911 - val_loss: 351.8217\n",
            "Epoch 935/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 706.9950 - val_loss: 306.6252\n",
            "Epoch 936/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 650.3745 - val_loss: 355.1175\n",
            "Epoch 937/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 692.1559 - val_loss: 315.3629\n",
            "Epoch 938/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 709.1815 - val_loss: 326.6612\n",
            "Epoch 939/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 668.6581 - val_loss: 327.2542\n",
            "Epoch 940/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 679.4844 - val_loss: 343.8620\n",
            "Epoch 941/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 686.7307 - val_loss: 306.2310\n",
            "Epoch 942/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 646.9399 - val_loss: 337.4846\n",
            "Epoch 943/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 691.5178 - val_loss: 367.3737\n",
            "Epoch 944/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 698.7585 - val_loss: 269.6459\n",
            "Epoch 945/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 660.4208 - val_loss: 317.2274\n",
            "Epoch 946/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 713.1226 - val_loss: 364.0433\n",
            "Epoch 947/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 645.2371 - val_loss: 327.7076\n",
            "Epoch 948/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 686.9767 - val_loss: 334.3452\n",
            "Epoch 949/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 636.6659 - val_loss: 289.9383\n",
            "Epoch 950/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 684.9252 - val_loss: 329.4627\n",
            "Epoch 951/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 695.5974 - val_loss: 298.4558\n",
            "Epoch 952/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 675.7041 - val_loss: 313.3606\n",
            "Epoch 953/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 695.3436 - val_loss: 369.8470\n",
            "Epoch 954/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 669.8289 - val_loss: 293.9101\n",
            "Epoch 955/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 682.3035 - val_loss: 290.6592\n",
            "Epoch 956/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 669.2529 - val_loss: 376.0603\n",
            "Epoch 957/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 699.9521 - val_loss: 302.2607\n",
            "Epoch 958/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 662.8597 - val_loss: 297.9180\n",
            "Epoch 959/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 672.2732 - val_loss: 307.5015\n",
            "Epoch 960/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 677.1682 - val_loss: 294.1130\n",
            "Epoch 961/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 666.2281 - val_loss: 283.5487\n",
            "Epoch 962/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 701.6018 - val_loss: 287.5888\n",
            "Epoch 963/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 692.2187 - val_loss: 309.9130\n",
            "Epoch 964/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 669.2256 - val_loss: 310.3006\n",
            "Epoch 965/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 695.7417 - val_loss: 374.3137\n",
            "Epoch 966/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 663.1425 - val_loss: 344.4830\n",
            "Epoch 967/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 671.8108 - val_loss: 296.6064\n",
            "Epoch 968/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 673.3995 - val_loss: 322.2079\n",
            "Epoch 969/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 680.0608 - val_loss: 326.9919\n",
            "Epoch 970/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 674.9489 - val_loss: 314.9408\n",
            "Epoch 971/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 682.3861 - val_loss: 346.4897\n",
            "Epoch 972/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 629.9005 - val_loss: 348.4756\n",
            "Epoch 973/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 689.8494 - val_loss: 294.0444\n",
            "Epoch 974/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 696.9144 - val_loss: 274.3345\n",
            "Epoch 975/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 664.1752 - val_loss: 353.7470\n",
            "Epoch 976/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 666.3997 - val_loss: 317.2365\n",
            "Epoch 977/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 668.5186 - val_loss: 307.4692\n",
            "Epoch 978/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 678.3846 - val_loss: 301.0022\n",
            "Epoch 979/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 679.9725 - val_loss: 306.6445\n",
            "Epoch 980/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 668.6084 - val_loss: 368.0809\n",
            "Epoch 981/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 639.9727 - val_loss: 308.7843\n",
            "Epoch 982/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 647.8201 - val_loss: 344.7161\n",
            "Epoch 983/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 601.4974 - val_loss: 325.9814\n",
            "Epoch 984/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 668.2766 - val_loss: 299.6661\n",
            "Epoch 985/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 673.8597 - val_loss: 340.3931\n",
            "Epoch 986/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 635.5277 - val_loss: 348.8954\n",
            "Epoch 987/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 586.8047 - val_loss: 309.3501\n",
            "Epoch 988/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 675.9167 - val_loss: 323.7946\n",
            "Epoch 989/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 630.8149 - val_loss: 288.0647\n",
            "Epoch 990/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 642.9580 - val_loss: 325.9209\n",
            "Epoch 991/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 652.5332 - val_loss: 374.5276\n",
            "Epoch 992/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 667.0161 - val_loss: 326.2301\n",
            "Epoch 993/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 651.1968 - val_loss: 377.3015\n",
            "Epoch 994/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 652.5984 - val_loss: 315.8953\n",
            "Epoch 995/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 677.4206 - val_loss: 339.4562\n",
            "Epoch 996/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 670.1852 - val_loss: 261.3669\n",
            "Epoch 997/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 664.6938 - val_loss: 374.6999\n",
            "Epoch 998/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 637.8450 - val_loss: 318.3577\n",
            "Epoch 999/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 640.5999 - val_loss: 310.0193\n",
            "Epoch 1000/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.9940 - val_loss: 365.4279\n",
            "Epoch 1001/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 643.7141 - val_loss: 309.0856\n",
            "Epoch 1002/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 634.4883 - val_loss: 355.2973\n",
            "Epoch 1003/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 633.5788 - val_loss: 341.6529\n",
            "Epoch 1004/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 644.6389 - val_loss: 303.0728\n",
            "Epoch 1005/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 646.3749 - val_loss: 282.6194\n",
            "Epoch 1006/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.9633 - val_loss: 324.9332\n",
            "Epoch 1007/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 631.6543 - val_loss: 307.5548\n",
            "Epoch 1008/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 637.1091 - val_loss: 295.9978\n",
            "Epoch 1009/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 642.2922 - val_loss: 310.7489\n",
            "Epoch 1010/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 631.9453 - val_loss: 281.4164\n",
            "Epoch 1011/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 609.2537 - val_loss: 301.3741\n",
            "Epoch 1012/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 651.0598 - val_loss: 309.8774\n",
            "Epoch 1013/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 665.0722 - val_loss: 343.1316\n",
            "Epoch 1014/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 647.2538 - val_loss: 304.8498\n",
            "Epoch 1015/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 729.1185 - val_loss: 307.3566\n",
            "Epoch 1016/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 634.0102 - val_loss: 341.5075\n",
            "Epoch 1017/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 667.3068 - val_loss: 266.7274\n",
            "Epoch 1018/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 619.9277 - val_loss: 314.4229\n",
            "Epoch 1019/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 628.9820 - val_loss: 288.8669\n",
            "Epoch 1020/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 630.8306 - val_loss: 339.5667\n",
            "Epoch 1021/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.8712 - val_loss: 319.3966\n",
            "Epoch 1022/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 687.1619 - val_loss: 334.7525\n",
            "Epoch 1023/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 641.9534 - val_loss: 314.4545\n",
            "Epoch 1024/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 666.7396 - val_loss: 293.4915\n",
            "Epoch 1025/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 666.4477 - val_loss: 329.3022\n",
            "Epoch 1026/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 628.7460 - val_loss: 322.6382\n",
            "Epoch 1027/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 658.8508 - val_loss: 333.6286\n",
            "Epoch 1028/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 627.3535 - val_loss: 335.4355\n",
            "Epoch 1029/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 656.3982 - val_loss: 288.4064\n",
            "Epoch 1030/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 660.0518 - val_loss: 314.9895\n",
            "Epoch 1031/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 618.9474 - val_loss: 319.5750\n",
            "Epoch 1032/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 662.7476 - val_loss: 316.8304\n",
            "Epoch 1033/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 646.0767 - val_loss: 359.2291\n",
            "Epoch 1034/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 621.7947 - val_loss: 318.9614\n",
            "Epoch 1035/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 645.3589 - val_loss: 323.3894\n",
            "Epoch 1036/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 636.2230 - val_loss: 330.4258\n",
            "Epoch 1037/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 683.9045 - val_loss: 290.0494\n",
            "Epoch 1038/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 632.3222 - val_loss: 346.2625\n",
            "Epoch 1039/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 686.3996 - val_loss: 354.1969\n",
            "Epoch 1040/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 646.4211 - val_loss: 351.7737\n",
            "Epoch 1041/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 669.0957 - val_loss: 307.4976\n",
            "Epoch 1042/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 659.5048 - val_loss: 273.7686\n",
            "Epoch 1043/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 636.5438 - val_loss: 309.8661\n",
            "Epoch 1044/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 647.7958 - val_loss: 345.1407\n",
            "Epoch 1045/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 683.3593 - val_loss: 309.1148\n",
            "Epoch 1046/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 661.9325 - val_loss: 344.9279\n",
            "Epoch 1047/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 646.2027 - val_loss: 332.9401\n",
            "Epoch 1048/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 658.1541 - val_loss: 309.2746\n",
            "Epoch 1049/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 648.4491 - val_loss: 335.9405\n",
            "Epoch 1050/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.5060 - val_loss: 302.0504\n",
            "Epoch 1051/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 649.8256 - val_loss: 317.9209\n",
            "Epoch 1052/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 678.8699 - val_loss: 271.8864\n",
            "Epoch 1053/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 663.6777 - val_loss: 341.1096\n",
            "Epoch 1054/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 621.4115 - val_loss: 372.0328\n",
            "Epoch 1055/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 617.9532 - val_loss: 322.6746\n",
            "Epoch 1056/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 658.1047 - val_loss: 344.6472\n",
            "Epoch 1057/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 624.0644 - val_loss: 349.5338\n",
            "Epoch 1058/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 648.0788 - val_loss: 318.4603\n",
            "Epoch 1059/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.8044 - val_loss: 290.2245\n",
            "Epoch 1060/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 637.1885 - val_loss: 371.6765\n",
            "Epoch 1061/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 615.7278 - val_loss: 335.0483\n",
            "Epoch 1062/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 607.1423 - val_loss: 329.8074\n",
            "Epoch 1063/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 626.5790 - val_loss: 303.4154\n",
            "Epoch 1064/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 636.4380 - val_loss: 330.2513\n",
            "Epoch 1065/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 688.5745 - val_loss: 348.8810\n",
            "Epoch 1066/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 629.5328 - val_loss: 329.5267\n",
            "Epoch 1067/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 685.7159 - val_loss: 318.4180\n",
            "Epoch 1068/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 651.4263 - val_loss: 284.3761\n",
            "Epoch 1069/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 642.3093 - val_loss: 294.2416\n",
            "Epoch 1070/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 668.1213 - val_loss: 304.9492\n",
            "Epoch 1071/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 612.3597 - val_loss: 306.0643\n",
            "Epoch 1072/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 619.7072 - val_loss: 350.0910\n",
            "Epoch 1073/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 652.2798 - val_loss: 302.2014\n",
            "Epoch 1074/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 636.4429 - val_loss: 337.0234\n",
            "Epoch 1075/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 627.9340 - val_loss: 350.2592\n",
            "Epoch 1076/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 597.6694 - val_loss: 297.6354\n",
            "Epoch 1077/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 625.6645 - val_loss: 364.9488\n",
            "Epoch 1078/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 673.9802 - val_loss: 314.1608\n",
            "Epoch 1079/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 616.0903 - val_loss: 356.2660\n",
            "Epoch 1080/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 625.2018 - val_loss: 318.3127\n",
            "Epoch 1081/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 619.5432 - val_loss: 271.4309\n",
            "Epoch 1082/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 639.1007 - val_loss: 267.9777\n",
            "Epoch 1083/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 672.8390 - val_loss: 324.2709\n",
            "Epoch 1084/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 660.4295 - val_loss: 321.4177\n",
            "Epoch 1085/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 636.2677 - val_loss: 307.2086\n",
            "Epoch 1086/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 685.4104 - val_loss: 384.7904\n",
            "Epoch 1087/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 608.2220 - val_loss: 334.1918\n",
            "Epoch 1088/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 637.0496 - val_loss: 330.5609\n",
            "Epoch 1089/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 685.0447 - val_loss: 289.8598\n",
            "Epoch 1090/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 618.0123 - val_loss: 323.2011\n",
            "Epoch 1091/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 613.8114 - val_loss: 304.2379\n",
            "Epoch 1092/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 646.5366 - val_loss: 343.1010\n",
            "Epoch 1093/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 688.2238 - val_loss: 294.5292\n",
            "Epoch 1094/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 638.1619 - val_loss: 304.1343\n",
            "Epoch 1095/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 632.3063 - val_loss: 330.8014\n",
            "Epoch 1096/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 648.7302 - val_loss: 292.6277\n",
            "Epoch 1097/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 660.4102 - val_loss: 329.7554\n",
            "Epoch 1098/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 629.9329 - val_loss: 325.8418\n",
            "Epoch 1099/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 650.5686 - val_loss: 277.4606\n",
            "Epoch 1100/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 662.7015 - val_loss: 329.5723\n",
            "Epoch 1101/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 625.8685 - val_loss: 360.6145\n",
            "Epoch 1102/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 635.1236 - val_loss: 298.8712\n",
            "Epoch 1103/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 617.7655 - val_loss: 350.1758\n",
            "Epoch 1104/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 607.4527 - val_loss: 368.4278\n",
            "Epoch 1105/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 644.7150 - val_loss: 298.3620\n",
            "Epoch 1106/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 609.3773 - val_loss: 293.0918\n",
            "Epoch 1107/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 629.3248 - val_loss: 295.7738\n",
            "Epoch 1108/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 648.6592 - val_loss: 303.8545\n",
            "Epoch 1109/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 632.4597 - val_loss: 308.2327\n",
            "Epoch 1110/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 623.0360 - val_loss: 343.2228\n",
            "Epoch 1111/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 652.4551 - val_loss: 330.5107\n",
            "Epoch 1112/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 671.2602 - val_loss: 330.9484\n",
            "Epoch 1113/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 623.0956 - val_loss: 321.8282\n",
            "Epoch 1114/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 624.3116 - val_loss: 291.3949\n",
            "Epoch 1115/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 643.3710 - val_loss: 303.7997\n",
            "Epoch 1116/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 654.4544 - val_loss: 299.9754\n",
            "Epoch 1117/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 667.1678 - val_loss: 312.7367\n",
            "Epoch 1118/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 628.6497 - val_loss: 305.1606\n",
            "Epoch 1119/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 671.2008 - val_loss: 369.4060\n",
            "Epoch 1120/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 631.5010 - val_loss: 312.2676\n",
            "Epoch 1121/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 623.9246 - val_loss: 311.0467\n",
            "Epoch 1122/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 611.0370 - val_loss: 283.6202\n",
            "Epoch 1123/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 645.9905 - val_loss: 313.1283\n",
            "Epoch 1124/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 622.9234 - val_loss: 307.6093\n",
            "Epoch 1125/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 616.3494 - val_loss: 293.5966\n",
            "Epoch 1126/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 622.8939 - val_loss: 306.3484\n",
            "Epoch 1127/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 614.8594 - val_loss: 339.8719\n",
            "Epoch 1128/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 641.7954 - val_loss: 332.8371\n",
            "Epoch 1129/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 615.2610 - val_loss: 332.5829\n",
            "Epoch 1130/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 636.4897 - val_loss: 309.1827\n",
            "Epoch 1131/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 617.3452 - val_loss: 305.7829\n",
            "Epoch 1132/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 641.3729 - val_loss: 325.2989\n",
            "Epoch 1133/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 618.8533 - val_loss: 342.7929\n",
            "Epoch 1134/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 639.6231 - val_loss: 304.6840\n",
            "Epoch 1135/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 613.0081 - val_loss: 332.5951\n",
            "Epoch 1136/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 643.6419 - val_loss: 308.2268\n",
            "Epoch 1137/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 615.0084 - val_loss: 340.4613\n",
            "Epoch 1138/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 603.7316 - val_loss: 332.0787\n",
            "Epoch 1139/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 597.3315 - val_loss: 304.3955\n",
            "Epoch 1140/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 639.3524 - val_loss: 345.1542\n",
            "Epoch 1141/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 619.8422 - val_loss: 281.9478\n",
            "Epoch 1142/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 607.7776 - val_loss: 318.9242\n",
            "Epoch 1143/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 632.5233 - val_loss: 319.7141\n",
            "Epoch 1144/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 648.6737 - val_loss: 280.7161\n",
            "Epoch 1145/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 636.4860 - val_loss: 314.0804\n",
            "Epoch 1146/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 639.3901 - val_loss: 301.8127\n",
            "Epoch 1147/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 642.3581 - val_loss: 323.9348\n",
            "Epoch 1148/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 597.7779 - val_loss: 307.0615\n",
            "Epoch 1149/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 598.4435 - val_loss: 353.4437\n",
            "Epoch 1150/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 625.8127 - val_loss: 330.4577\n",
            "Epoch 1151/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 639.2999 - val_loss: 292.8184\n",
            "Epoch 1152/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 618.7769 - val_loss: 332.3922\n",
            "Epoch 1153/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 566.8936 - val_loss: 288.4376\n",
            "Epoch 1154/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 592.7613 - val_loss: 354.7046\n",
            "Epoch 1155/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 631.4143 - val_loss: 320.5763\n",
            "Epoch 1156/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 647.9980 - val_loss: 327.2071\n",
            "Epoch 1157/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 617.9789 - val_loss: 291.5859\n",
            "Epoch 1158/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 634.8177 - val_loss: 343.9127\n",
            "Epoch 1159/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 653.9231 - val_loss: 341.8430\n",
            "Epoch 1160/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 628.3611 - val_loss: 314.4090\n",
            "Epoch 1161/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 650.0723 - val_loss: 301.4651\n",
            "Epoch 1162/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 607.6446 - val_loss: 285.8817\n",
            "Epoch 1163/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 606.3223 - val_loss: 331.9301\n",
            "Epoch 1164/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 638.6628 - val_loss: 330.8632\n",
            "Epoch 1165/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 629.7339 - val_loss: 346.0983\n",
            "Epoch 1166/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 617.4724 - val_loss: 347.0760\n",
            "Epoch 1167/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 673.0560 - val_loss: 317.1754\n",
            "Epoch 1168/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 622.0587 - val_loss: 301.6478\n",
            "Epoch 1169/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 594.5815 - val_loss: 334.9413\n",
            "Epoch 1170/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 609.1518 - val_loss: 333.8484\n",
            "Epoch 1171/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 645.9510 - val_loss: 279.2699\n",
            "Epoch 1172/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 626.6295 - val_loss: 295.1840\n",
            "Epoch 1173/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 608.3652 - val_loss: 278.5870\n",
            "Epoch 1174/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 638.4302 - val_loss: 302.8672\n",
            "Epoch 1175/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 635.4525 - val_loss: 255.4575\n",
            "Epoch 1176/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 673.7156 - val_loss: 306.8444\n",
            "Epoch 1177/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 613.1340 - val_loss: 321.1032\n",
            "Epoch 1178/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 597.4352 - val_loss: 312.1142\n",
            "Epoch 1179/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 615.9664 - val_loss: 331.8611\n",
            "Epoch 1180/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 593.1078 - val_loss: 329.7594\n",
            "Epoch 1181/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 627.7886 - val_loss: 284.1858\n",
            "Epoch 1182/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 587.3994 - val_loss: 328.5681\n",
            "Epoch 1183/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 584.0645 - val_loss: 275.0632\n",
            "Epoch 1184/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 632.0445 - val_loss: 263.4128\n",
            "Epoch 1185/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 601.0827 - val_loss: 321.5943\n",
            "Epoch 1186/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 641.4386 - val_loss: 314.7610\n",
            "Epoch 1187/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 615.7573 - val_loss: 296.1059\n",
            "Epoch 1188/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 591.8776 - val_loss: 342.7930\n",
            "Epoch 1189/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 637.5964 - val_loss: 313.2149\n",
            "Epoch 1190/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 577.1534 - val_loss: 374.2321\n",
            "Epoch 1191/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 594.4107 - val_loss: 293.1221\n",
            "Epoch 1192/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 602.1334 - val_loss: 268.5505\n",
            "Epoch 1193/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 627.1160 - val_loss: 369.8921\n",
            "Epoch 1194/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 579.2491 - val_loss: 320.7549\n",
            "Epoch 1195/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 580.2004 - val_loss: 286.0603\n",
            "Epoch 1196/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 596.7900 - val_loss: 304.2494\n",
            "Epoch 1197/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 587.3176 - val_loss: 329.6600\n",
            "Epoch 1198/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 602.4333 - val_loss: 311.0891\n",
            "Epoch 1199/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 627.7346 - val_loss: 321.4026\n",
            "Epoch 1200/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 587.2509 - val_loss: 283.4241\n",
            "Epoch 1201/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 619.9840 - val_loss: 382.6398\n",
            "Epoch 1202/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.1545 - val_loss: 295.6760\n",
            "Epoch 1203/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 627.6813 - val_loss: 318.3594\n",
            "Epoch 1204/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 622.1877 - val_loss: 294.9661\n",
            "Epoch 1205/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 658.0623 - val_loss: 323.8991\n",
            "Epoch 1206/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.3512 - val_loss: 304.3801\n",
            "Epoch 1207/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 631.5842 - val_loss: 355.5607\n",
            "Epoch 1208/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 614.1672 - val_loss: 331.0695\n",
            "Epoch 1209/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.3453 - val_loss: 333.9384\n",
            "Epoch 1210/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 627.2274 - val_loss: 347.3175\n",
            "Epoch 1211/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 657.3093 - val_loss: 335.2774\n",
            "Epoch 1212/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 577.1172 - val_loss: 318.8516\n",
            "Epoch 1213/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 652.4345 - val_loss: 370.4922\n",
            "Epoch 1214/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 592.4434 - val_loss: 271.6912\n",
            "Epoch 1215/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 610.0538 - val_loss: 364.8399\n",
            "Epoch 1216/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 604.0858 - val_loss: 319.7361\n",
            "Epoch 1217/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 591.3531 - val_loss: 346.8062\n",
            "Epoch 1218/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 611.5363 - val_loss: 275.5537\n",
            "Epoch 1219/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.4128 - val_loss: 264.0561\n",
            "Epoch 1220/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 650.4676 - val_loss: 294.0828\n",
            "Epoch 1221/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 615.4662 - val_loss: 324.3672\n",
            "Epoch 1222/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 616.8312 - val_loss: 307.3834\n",
            "Epoch 1223/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 622.7186 - val_loss: 271.2907\n",
            "Epoch 1224/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 647.5765 - val_loss: 282.0020\n",
            "Epoch 1225/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 577.4266 - val_loss: 363.2400\n",
            "Epoch 1226/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 614.3276 - val_loss: 260.4075\n",
            "Epoch 1227/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 586.7785 - val_loss: 281.1058\n",
            "Epoch 1228/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 631.4532 - val_loss: 276.2402\n",
            "Epoch 1229/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 611.4539 - val_loss: 310.0913\n",
            "Epoch 1230/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 611.0416 - val_loss: 284.5019\n",
            "Epoch 1231/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 584.3901 - val_loss: 338.2578\n",
            "Epoch 1232/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 606.0378 - val_loss: 290.0345\n",
            "Epoch 1233/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 621.4659 - val_loss: 296.7063\n",
            "Epoch 1234/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 639.8738 - val_loss: 304.5900\n",
            "Epoch 1235/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 656.7734 - val_loss: 274.2234\n",
            "Epoch 1236/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 578.2791 - val_loss: 271.4709\n",
            "Epoch 1237/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 622.7659 - val_loss: 252.6446\n",
            "Epoch 1238/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 607.3926 - val_loss: 313.2444\n",
            "Epoch 1239/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.1089 - val_loss: 327.4412\n",
            "Epoch 1240/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 591.7612 - val_loss: 289.6710\n",
            "Epoch 1241/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.2579 - val_loss: 317.9996\n",
            "Epoch 1242/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 650.4664 - val_loss: 334.5013\n",
            "Epoch 1243/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 600.9072 - val_loss: 290.8627\n",
            "Epoch 1244/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 592.7233 - val_loss: 304.9185\n",
            "Epoch 1245/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 600.4346 - val_loss: 308.1761\n",
            "Epoch 1246/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 598.4814 - val_loss: 330.2629\n",
            "Epoch 1247/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.2384 - val_loss: 343.4142\n",
            "Epoch 1248/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.9949 - val_loss: 296.4681\n",
            "Epoch 1249/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 601.9557 - val_loss: 343.5203\n",
            "Epoch 1250/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 617.5430 - val_loss: 311.8177\n",
            "Epoch 1251/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 591.1473 - val_loss: 340.0013\n",
            "Epoch 1252/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 598.0101 - val_loss: 349.9569\n",
            "Epoch 1253/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 616.7119 - val_loss: 296.3578\n",
            "Epoch 1254/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 604.5824 - val_loss: 290.5043\n",
            "Epoch 1255/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 590.5530 - val_loss: 290.1324\n",
            "Epoch 1256/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 614.5271 - val_loss: 318.6960\n",
            "Epoch 1257/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 604.6566 - val_loss: 313.5942\n",
            "Epoch 1258/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 627.5611 - val_loss: 285.4283\n",
            "Epoch 1259/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 632.8492 - val_loss: 308.0068\n",
            "Epoch 1260/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 592.2646 - val_loss: 312.4760\n",
            "Epoch 1261/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 663.9023 - val_loss: 313.2247\n",
            "Epoch 1262/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 640.1790 - val_loss: 310.3890\n",
            "Epoch 1263/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 589.0618 - val_loss: 311.2229\n",
            "Epoch 1264/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 638.2505 - val_loss: 296.1288\n",
            "Epoch 1265/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 607.3446 - val_loss: 326.3144\n",
            "Epoch 1266/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.6848 - val_loss: 310.6659\n",
            "Epoch 1267/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 594.4536 - val_loss: 269.8829\n",
            "Epoch 1268/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 595.8079 - val_loss: 298.2549\n",
            "Epoch 1269/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 581.7607 - val_loss: 322.2432\n",
            "Epoch 1270/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 589.5569 - val_loss: 292.2712\n",
            "Epoch 1271/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 579.0416 - val_loss: 304.5754\n",
            "Epoch 1272/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 604.2185 - val_loss: 292.6918\n",
            "Epoch 1273/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 573.6741 - val_loss: 279.8167\n",
            "Epoch 1274/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 600.8592 - val_loss: 294.0634\n",
            "Epoch 1275/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 592.6961 - val_loss: 262.3666\n",
            "Epoch 1276/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 594.7158 - val_loss: 318.9750\n",
            "Epoch 1277/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 600.2052 - val_loss: 298.3489\n",
            "Epoch 1278/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 628.1342 - val_loss: 268.7073\n",
            "Epoch 1279/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 629.8108 - val_loss: 330.8489\n",
            "Epoch 1280/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 605.3868 - val_loss: 337.6380\n",
            "Epoch 1281/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 574.8739 - val_loss: 308.9457\n",
            "Epoch 1282/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 574.4684 - val_loss: 326.8802\n",
            "Epoch 1283/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 559.0345 - val_loss: 313.0347\n",
            "Epoch 1284/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 605.0097 - val_loss: 309.6488\n",
            "Epoch 1285/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 616.1215 - val_loss: 329.1799\n",
            "Epoch 1286/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 619.0695 - val_loss: 317.6045\n",
            "Epoch 1287/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 610.4956 - val_loss: 277.0714\n",
            "Epoch 1288/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 605.4922 - val_loss: 284.5905\n",
            "Epoch 1289/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 554.5252 - val_loss: 311.7524\n",
            "Epoch 1290/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 576.9868 - val_loss: 290.6595\n",
            "Epoch 1291/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 637.5388 - val_loss: 301.4619\n",
            "Epoch 1292/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 590.5449 - val_loss: 293.6613\n",
            "Epoch 1293/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 606.9679 - val_loss: 288.2950\n",
            "Epoch 1294/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 608.5450 - val_loss: 317.6964\n",
            "Epoch 1295/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 594.3398 - val_loss: 298.7263\n",
            "Epoch 1296/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 630.3548 - val_loss: 326.3141\n",
            "Epoch 1297/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 641.4279 - val_loss: 306.0237\n",
            "Epoch 1298/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 615.2572 - val_loss: 297.7502\n",
            "Epoch 1299/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 613.1440 - val_loss: 363.3688\n",
            "Epoch 1300/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 555.4865 - val_loss: 290.8676\n",
            "Epoch 1301/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 620.9592 - val_loss: 311.4301\n",
            "Epoch 1302/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 573.6617 - val_loss: 320.6819\n",
            "Epoch 1303/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 629.6547 - val_loss: 312.8086\n",
            "Epoch 1304/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 588.8163 - val_loss: 325.3358\n",
            "Epoch 1305/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 596.7075 - val_loss: 318.6511\n",
            "Epoch 1306/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 603.8688 - val_loss: 298.3607\n",
            "Epoch 1307/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 571.1216 - val_loss: 334.7272\n",
            "Epoch 1308/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 581.8579 - val_loss: 310.2595\n",
            "Epoch 1309/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 574.0878 - val_loss: 365.5179\n",
            "Epoch 1310/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 595.6125 - val_loss: 330.3728\n",
            "Epoch 1311/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 591.8581 - val_loss: 339.9500\n",
            "Epoch 1312/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 571.4583 - val_loss: 299.1402\n",
            "Epoch 1313/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 596.1381 - val_loss: 312.3117\n",
            "Epoch 1314/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 566.1393 - val_loss: 289.6839\n",
            "Epoch 1315/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 609.1074 - val_loss: 351.0353\n",
            "Epoch 1316/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 573.6683 - val_loss: 398.7032\n",
            "Epoch 1317/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 563.2070 - val_loss: 344.8092\n",
            "Epoch 1318/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 585.1765 - val_loss: 285.4478\n",
            "Epoch 1319/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 603.3152 - val_loss: 315.1565\n",
            "Epoch 1320/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 655.5348 - val_loss: 331.5085\n",
            "Epoch 1321/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 621.4307 - val_loss: 353.5120\n",
            "Epoch 1322/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 613.4618 - val_loss: 379.1562\n",
            "Epoch 1323/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 601.8126 - val_loss: 344.3539\n",
            "Epoch 1324/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 640.6984 - val_loss: 303.4831\n",
            "Epoch 1325/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.0190 - val_loss: 281.4066\n",
            "Epoch 1326/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.6155 - val_loss: 326.1384\n",
            "Epoch 1327/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 557.3223 - val_loss: 256.2143\n",
            "Epoch 1328/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 614.2728 - val_loss: 271.4424\n",
            "Epoch 1329/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 571.7189 - val_loss: 266.4923\n",
            "Epoch 1330/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 587.0199 - val_loss: 272.1136\n",
            "Epoch 1331/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 596.7552 - val_loss: 290.0565\n",
            "Epoch 1332/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 597.1043 - val_loss: 296.0898\n",
            "Epoch 1333/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 602.9856 - val_loss: 309.1673\n",
            "Epoch 1334/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 643.1865 - val_loss: 259.7295\n",
            "Epoch 1335/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 609.7441 - val_loss: 289.4720\n",
            "Epoch 1336/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 566.7867 - val_loss: 308.6750\n",
            "Epoch 1337/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 577.5725 - val_loss: 294.5310\n",
            "Epoch 1338/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 609.6455 - val_loss: 286.3890\n",
            "Epoch 1339/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 601.7248 - val_loss: 283.9251\n",
            "Epoch 1340/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 600.1534 - val_loss: 310.4229\n",
            "Epoch 1341/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 561.7243 - val_loss: 267.4320\n",
            "Epoch 1342/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 566.7145 - val_loss: 292.5985\n",
            "Epoch 1343/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 605.3405 - val_loss: 331.9606\n",
            "Epoch 1344/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 607.7580 - val_loss: 341.3791\n",
            "Epoch 1345/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 585.3076 - val_loss: 281.3124\n",
            "Epoch 1346/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 570.9552 - val_loss: 346.1742\n",
            "Epoch 1347/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 620.9549 - val_loss: 306.0381\n",
            "Epoch 1348/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 603.3967 - val_loss: 288.3064\n",
            "Epoch 1349/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 557.6580 - val_loss: 320.4555\n",
            "Epoch 1350/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 603.9628 - val_loss: 294.7006\n",
            "Epoch 1351/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 617.7743 - val_loss: 309.2166\n",
            "Epoch 1352/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 635.7011 - val_loss: 316.2103\n",
            "Epoch 1353/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 584.2186 - val_loss: 267.3218\n",
            "Epoch 1354/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 571.8748 - val_loss: 320.8652\n",
            "Epoch 1355/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 533.7761 - val_loss: 273.1993\n",
            "Epoch 1356/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 610.4914 - val_loss: 340.0833\n",
            "Epoch 1357/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 618.9380 - val_loss: 301.7428\n",
            "Epoch 1358/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.8546 - val_loss: 312.1214\n",
            "Epoch 1359/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 559.5957 - val_loss: 302.2914\n",
            "Epoch 1360/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 597.9829 - val_loss: 305.1576\n",
            "Epoch 1361/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 613.1060 - val_loss: 322.2126\n",
            "Epoch 1362/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 610.4147 - val_loss: 321.6062\n",
            "Epoch 1363/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 589.3933 - val_loss: 284.6302\n",
            "Epoch 1364/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 610.4261 - val_loss: 324.5748\n",
            "Epoch 1365/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 600.4711 - val_loss: 325.4213\n",
            "Epoch 1366/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 617.6339 - val_loss: 345.5892\n",
            "Epoch 1367/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 563.8327 - val_loss: 343.3335\n",
            "Epoch 1368/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 608.6359 - val_loss: 302.7085\n",
            "Epoch 1369/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 601.2748 - val_loss: 286.8259\n",
            "Epoch 1370/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 586.8005 - val_loss: 308.0821\n",
            "Epoch 1371/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 578.1465 - val_loss: 271.9445\n",
            "Epoch 1372/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 595.0037 - val_loss: 315.8280\n",
            "Epoch 1373/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 562.8751 - val_loss: 307.0216\n",
            "Epoch 1374/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 606.6236 - val_loss: 294.2555\n",
            "Epoch 1375/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 555.5019 - val_loss: 305.1430\n",
            "Epoch 1376/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 579.6868 - val_loss: 278.0824\n",
            "Epoch 1377/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 623.0232 - val_loss: 269.9594\n",
            "Epoch 1378/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 598.7827 - val_loss: 323.7753\n",
            "Epoch 1379/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 580.6271 - val_loss: 320.3308\n",
            "Epoch 1380/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 574.0480 - val_loss: 323.5875\n",
            "Epoch 1381/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 577.4265 - val_loss: 314.9925\n",
            "Epoch 1382/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 627.4626 - val_loss: 291.9036\n",
            "Epoch 1383/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 639.9483 - val_loss: 327.4110\n",
            "Epoch 1384/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 569.2091 - val_loss: 286.6463\n",
            "Epoch 1385/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 570.1666 - val_loss: 304.4258\n",
            "Epoch 1386/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 570.9582 - val_loss: 302.6325\n",
            "Epoch 1387/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 570.0182 - val_loss: 323.1718\n",
            "Epoch 1388/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 564.1017 - val_loss: 324.9312\n",
            "Epoch 1389/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 594.4042 - val_loss: 316.6733\n",
            "Epoch 1390/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 570.4777 - val_loss: 295.2820\n",
            "Epoch 1391/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 534.4304 - val_loss: 346.8037\n",
            "Epoch 1392/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 573.8779 - val_loss: 273.3054\n",
            "Epoch 1393/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 584.0022 - val_loss: 285.9825\n",
            "Epoch 1394/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 545.3864 - val_loss: 275.7404\n",
            "Epoch 1395/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.6559 - val_loss: 321.5549\n",
            "Epoch 1396/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 617.1797 - val_loss: 303.5556\n",
            "Epoch 1397/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 586.9651 - val_loss: 342.2678\n",
            "Epoch 1398/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 528.9698 - val_loss: 329.3626\n",
            "Epoch 1399/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 587.4412 - val_loss: 336.3482\n",
            "Epoch 1400/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 584.9760 - val_loss: 343.8042\n",
            "Epoch 1401/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 584.6937 - val_loss: 296.9924\n",
            "Epoch 1402/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.9353 - val_loss: 293.5596\n",
            "Epoch 1403/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.3299 - val_loss: 322.0319\n",
            "Epoch 1404/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 571.7408 - val_loss: 281.2474\n",
            "Epoch 1405/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 581.5264 - val_loss: 314.0312\n",
            "Epoch 1406/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 605.6046 - val_loss: 306.7638\n",
            "Epoch 1407/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 578.7576 - val_loss: 286.8549\n",
            "Epoch 1408/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 561.7465 - val_loss: 279.6907\n",
            "Epoch 1409/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 572.4825 - val_loss: 256.2377\n",
            "Epoch 1410/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 561.7429 - val_loss: 279.4295\n",
            "Epoch 1411/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 573.6147 - val_loss: 314.8356\n",
            "Epoch 1412/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 565.7880 - val_loss: 303.9380\n",
            "Epoch 1413/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 615.7662 - val_loss: 290.3346\n",
            "Epoch 1414/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.7846 - val_loss: 295.8729\n",
            "Epoch 1415/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 552.6981 - val_loss: 295.7887\n",
            "Epoch 1416/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 580.3691 - val_loss: 292.1946\n",
            "Epoch 1417/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 586.4597 - val_loss: 296.4996\n",
            "Epoch 1418/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 547.8038 - val_loss: 321.0777\n",
            "Epoch 1419/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 598.4250 - val_loss: 334.2953\n",
            "Epoch 1420/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 565.1193 - val_loss: 306.2485\n",
            "Epoch 1421/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 606.6390 - val_loss: 292.7889\n",
            "Epoch 1422/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 569.8969 - val_loss: 333.8713\n",
            "Epoch 1423/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 605.2960 - val_loss: 309.7181\n",
            "Epoch 1424/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 559.4991 - val_loss: 322.1529\n",
            "Epoch 1425/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 580.4697 - val_loss: 302.4032\n",
            "Epoch 1426/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 532.2020 - val_loss: 314.4455\n",
            "Epoch 1427/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 579.3174 - val_loss: 307.9029\n",
            "Epoch 1428/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 549.5748 - val_loss: 297.4349\n",
            "Epoch 1429/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 581.1433 - val_loss: 297.5453\n",
            "Epoch 1430/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 548.0980 - val_loss: 311.3289\n",
            "Epoch 1431/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 563.8882 - val_loss: 301.7689\n",
            "Epoch 1432/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 592.1219 - val_loss: 303.4648\n",
            "Epoch 1433/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 570.0137 - val_loss: 292.4121\n",
            "Epoch 1434/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 546.6304 - val_loss: 276.6218\n",
            "Epoch 1435/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 583.7227 - val_loss: 309.5481\n",
            "Epoch 1436/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 610.2468 - val_loss: 320.6543\n",
            "Epoch 1437/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 554.4081 - val_loss: 287.1029\n",
            "Epoch 1438/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 565.2253 - val_loss: 304.7195\n",
            "Epoch 1439/2000\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 555.6223 - val_loss: 297.7704\n",
            "Epoch 1440/2000\n",
            "44/44 [==============================] - 1s 13ms/step - loss: 543.2039 - val_loss: 332.8246\n",
            "Epoch 1441/2000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 568.4865 - val_loss: 343.7466\n",
            "Epoch 1442/2000\n",
            "44/44 [==============================] - 0s 11ms/step - loss: 568.8677 - val_loss: 294.9329\n",
            "Epoch 1443/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 576.4742 - val_loss: 311.3034\n",
            "Epoch 1444/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.4843 - val_loss: 295.1230\n",
            "Epoch 1445/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 562.9993 - val_loss: 316.0557\n",
            "Epoch 1446/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 549.4772 - val_loss: 287.0331\n",
            "Epoch 1447/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 584.8589 - val_loss: 292.8669\n",
            "Epoch 1448/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 545.4951 - val_loss: 351.8157\n",
            "Epoch 1449/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 581.2943 - val_loss: 350.0358\n",
            "Epoch 1450/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 578.5782 - val_loss: 312.0399\n",
            "Epoch 1451/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 569.6497 - val_loss: 310.7030\n",
            "Epoch 1452/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 564.5101 - val_loss: 301.2037\n",
            "Epoch 1453/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 585.6196 - val_loss: 291.0496\n",
            "Epoch 1454/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 556.8821 - val_loss: 297.6737\n",
            "Epoch 1455/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 564.7963 - val_loss: 318.7011\n",
            "Epoch 1456/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 576.4859 - val_loss: 284.4006\n",
            "Epoch 1457/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.6457 - val_loss: 309.8534\n",
            "Epoch 1458/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.6165 - val_loss: 318.0562\n",
            "Epoch 1459/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 582.1526 - val_loss: 307.3835\n",
            "Epoch 1460/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 581.0095 - val_loss: 344.0244\n",
            "Epoch 1461/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.8604 - val_loss: 331.0198\n",
            "Epoch 1462/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 557.9717 - val_loss: 296.2087\n",
            "Epoch 1463/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 545.0123 - val_loss: 358.6299\n",
            "Epoch 1464/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 569.2677 - val_loss: 302.0031\n",
            "Epoch 1465/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.8429 - val_loss: 321.4398\n",
            "Epoch 1466/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.4444 - val_loss: 303.0738\n",
            "Epoch 1467/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 554.9934 - val_loss: 337.2515\n",
            "Epoch 1468/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 547.6136 - val_loss: 343.5756\n",
            "Epoch 1469/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 611.2836 - val_loss: 277.3026\n",
            "Epoch 1470/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 559.7204 - val_loss: 295.7924\n",
            "Epoch 1471/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 568.5605 - val_loss: 302.5609\n",
            "Epoch 1472/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 540.6079 - val_loss: 315.5580\n",
            "Epoch 1473/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 529.1553 - val_loss: 349.6511\n",
            "Epoch 1474/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 576.4340 - val_loss: 356.4760\n",
            "Epoch 1475/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 584.8536 - val_loss: 300.8677\n",
            "Epoch 1476/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 544.4579 - val_loss: 334.6495\n",
            "Epoch 1477/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 581.4054 - val_loss: 336.7283\n",
            "Epoch 1478/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 552.5016 - val_loss: 325.8925\n",
            "Epoch 1479/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 565.8109 - val_loss: 281.2608\n",
            "Epoch 1480/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 588.8436 - val_loss: 303.2143\n",
            "Epoch 1481/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 557.1157 - val_loss: 321.5803\n",
            "Epoch 1482/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 575.8463 - val_loss: 307.4552\n",
            "Epoch 1483/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 569.0794 - val_loss: 293.9457\n",
            "Epoch 1484/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 596.5097 - val_loss: 333.1107\n",
            "Epoch 1485/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 575.0166 - val_loss: 332.5378\n",
            "Epoch 1486/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 597.2841 - val_loss: 305.2422\n",
            "Epoch 1487/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 547.1950 - val_loss: 287.6070\n",
            "Epoch 1488/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 562.7374 - val_loss: 262.4462\n",
            "Epoch 1489/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 601.0755 - val_loss: 300.8016\n",
            "Epoch 1490/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 577.4946 - val_loss: 282.1480\n",
            "Epoch 1491/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 561.3233 - val_loss: 265.5532\n",
            "Epoch 1492/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 574.3372 - val_loss: 305.8297\n",
            "Epoch 1493/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 573.8484 - val_loss: 308.3858\n",
            "Epoch 1494/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 576.8629 - val_loss: 285.8003\n",
            "Epoch 1495/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.3499 - val_loss: 284.6840\n",
            "Epoch 1496/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 561.4468 - val_loss: 356.0655\n",
            "Epoch 1497/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 501.2600 - val_loss: 329.4675\n",
            "Epoch 1498/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 581.4252 - val_loss: 292.1597\n",
            "Epoch 1499/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 585.8420 - val_loss: 297.3385\n",
            "Epoch 1500/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 556.8318 - val_loss: 316.9799\n",
            "Epoch 1501/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 574.0156 - val_loss: 280.6139\n",
            "Epoch 1502/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 593.1392 - val_loss: 336.2194\n",
            "Epoch 1503/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 539.3311 - val_loss: 267.5055\n",
            "Epoch 1504/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 550.4703 - val_loss: 283.6696\n",
            "Epoch 1505/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 602.0768 - val_loss: 316.9600\n",
            "Epoch 1506/2000\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 559.0991 - val_loss: 288.0673\n",
            "Epoch 1507/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.0669 - val_loss: 342.0683\n",
            "Epoch 1508/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 546.7437 - val_loss: 281.8032\n",
            "Epoch 1509/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 584.4219 - val_loss: 296.5234\n",
            "Epoch 1510/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 591.0651 - val_loss: 331.3910\n",
            "Epoch 1511/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 540.3644 - val_loss: 286.6986\n",
            "Epoch 1512/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.2959 - val_loss: 290.8326\n",
            "Epoch 1513/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 592.1732 - val_loss: 307.1599\n",
            "Epoch 1514/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 587.1109 - val_loss: 352.9753\n",
            "Epoch 1515/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 597.7699 - val_loss: 277.6751\n",
            "Epoch 1516/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 561.0802 - val_loss: 302.9098\n",
            "Epoch 1517/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 598.9200 - val_loss: 290.3942\n",
            "Epoch 1518/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 598.6599 - val_loss: 295.1306\n",
            "Epoch 1519/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 554.5616 - val_loss: 312.3183\n",
            "Epoch 1520/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 566.9360 - val_loss: 267.2989\n",
            "Epoch 1521/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 544.5522 - val_loss: 353.9743\n",
            "Epoch 1522/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 579.7468 - val_loss: 325.9633\n",
            "Epoch 1523/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 522.2219 - val_loss: 272.1741\n",
            "Epoch 1524/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 555.5613 - val_loss: 321.1196\n",
            "Epoch 1525/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 579.4009 - val_loss: 271.1400\n",
            "Epoch 1526/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 522.2056 - val_loss: 316.8996\n",
            "Epoch 1527/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 572.6290 - val_loss: 299.4593\n",
            "Epoch 1528/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 524.5334 - val_loss: 335.1476\n",
            "Epoch 1529/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 585.4296 - val_loss: 263.3341\n",
            "Epoch 1530/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 541.4736 - val_loss: 325.1757\n",
            "Epoch 1531/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 547.0572 - val_loss: 281.5683\n",
            "Epoch 1532/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 563.0848 - val_loss: 382.4631\n",
            "Epoch 1533/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 528.2448 - val_loss: 317.6109\n",
            "Epoch 1534/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 568.3181 - val_loss: 326.8471\n",
            "Epoch 1535/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 539.3323 - val_loss: 337.4244\n",
            "Epoch 1536/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 527.0171 - val_loss: 305.1684\n",
            "Epoch 1537/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 540.5161 - val_loss: 306.8906\n",
            "Epoch 1538/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 561.1252 - val_loss: 313.9976\n",
            "Epoch 1539/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 528.5032 - val_loss: 303.2839\n",
            "Epoch 1540/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 545.3580 - val_loss: 308.8055\n",
            "Epoch 1541/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 563.6635 - val_loss: 311.5887\n",
            "Epoch 1542/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 553.8263 - val_loss: 340.9717\n",
            "Epoch 1543/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 556.8107 - val_loss: 298.8433\n",
            "Epoch 1544/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 556.4279 - val_loss: 319.8365\n",
            "Epoch 1545/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 568.9785 - val_loss: 322.9218\n",
            "Epoch 1546/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 554.9788 - val_loss: 307.7170\n",
            "Epoch 1547/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 562.9947 - val_loss: 344.6377\n",
            "Epoch 1548/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 546.2156 - val_loss: 280.3920\n",
            "Epoch 1549/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 551.3221 - val_loss: 299.4698\n",
            "Epoch 1550/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 543.2844 - val_loss: 272.6802\n",
            "Epoch 1551/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 573.4506 - val_loss: 303.0131\n",
            "Epoch 1552/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 526.3285 - val_loss: 272.2620\n",
            "Epoch 1553/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 547.4645 - val_loss: 304.3131\n",
            "Epoch 1554/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 580.5618 - val_loss: 299.4700\n",
            "Epoch 1555/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 519.7892 - val_loss: 305.3320\n",
            "Epoch 1556/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 544.8113 - val_loss: 260.5978\n",
            "Epoch 1557/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 592.0542 - val_loss: 315.7064\n",
            "Epoch 1558/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 522.4277 - val_loss: 258.8213\n",
            "Epoch 1559/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 551.5561 - val_loss: 342.4374\n",
            "Epoch 1560/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 541.0938 - val_loss: 332.1172\n",
            "Epoch 1561/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 544.1407 - val_loss: 347.7982\n",
            "Epoch 1562/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 554.6189 - val_loss: 351.9580\n",
            "Epoch 1563/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 513.6373 - val_loss: 312.3831\n",
            "Epoch 1564/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 552.8917 - val_loss: 305.1897\n",
            "Epoch 1565/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 582.4019 - val_loss: 321.4562\n",
            "Epoch 1566/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 524.4620 - val_loss: 304.2455\n",
            "Epoch 1567/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 566.3995 - val_loss: 326.9517\n",
            "Epoch 1568/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 555.1934 - val_loss: 331.2190\n",
            "Epoch 1569/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 571.6465 - val_loss: 302.3180\n",
            "Epoch 1570/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.3998 - val_loss: 297.4334\n",
            "Epoch 1571/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 557.6965 - val_loss: 362.3237\n",
            "Epoch 1572/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 531.1992 - val_loss: 282.1166\n",
            "Epoch 1573/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.5724 - val_loss: 294.1234\n",
            "Epoch 1574/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 586.1765 - val_loss: 311.2986\n",
            "Epoch 1575/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 578.5504 - val_loss: 296.4475\n",
            "Epoch 1576/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 523.8312 - val_loss: 340.4506\n",
            "Epoch 1577/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 547.2316 - val_loss: 308.5400\n",
            "Epoch 1578/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 543.5764 - val_loss: 345.2365\n",
            "Epoch 1579/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 512.5319 - val_loss: 311.1474\n",
            "Epoch 1580/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 530.0676 - val_loss: 291.8690\n",
            "Epoch 1581/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 561.0187 - val_loss: 285.5751\n",
            "Epoch 1582/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 522.1483 - val_loss: 305.2801\n",
            "Epoch 1583/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 557.6846 - val_loss: 359.6326\n",
            "Epoch 1584/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 534.0305 - val_loss: 300.1298\n",
            "Epoch 1585/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 505.0023 - val_loss: 281.6393\n",
            "Epoch 1586/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 568.8252 - val_loss: 310.9304\n",
            "Epoch 1587/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 568.7910 - val_loss: 278.9612\n",
            "Epoch 1588/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 515.6112 - val_loss: 311.9390\n",
            "Epoch 1589/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 528.3413 - val_loss: 315.3095\n",
            "Epoch 1590/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 540.6104 - val_loss: 307.2025\n",
            "Epoch 1591/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 534.6930 - val_loss: 290.1642\n",
            "Epoch 1592/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 543.0507 - val_loss: 300.0667\n",
            "Epoch 1593/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 551.7981 - val_loss: 304.5953\n",
            "Epoch 1594/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 499.0135 - val_loss: 269.5182\n",
            "Epoch 1595/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.7888 - val_loss: 280.9896\n",
            "Epoch 1596/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 548.6045 - val_loss: 320.3127\n",
            "Epoch 1597/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 528.1260 - val_loss: 301.6978\n",
            "Epoch 1598/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 529.6378 - val_loss: 288.1925\n",
            "Epoch 1599/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 529.0298 - val_loss: 289.9182\n",
            "Epoch 1600/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 597.8574 - val_loss: 311.0725\n",
            "Epoch 1601/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 538.5007 - val_loss: 332.0903\n",
            "Epoch 1602/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 576.5060 - val_loss: 328.0123\n",
            "Epoch 1603/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 554.2841 - val_loss: 276.8998\n",
            "Epoch 1604/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 535.5927 - val_loss: 280.4375\n",
            "Epoch 1605/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 516.1699 - val_loss: 329.0869\n",
            "Epoch 1606/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 526.5256 - val_loss: 331.3234\n",
            "Epoch 1607/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 501.0232 - val_loss: 280.0442\n",
            "Epoch 1608/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 548.2216 - val_loss: 310.1953\n",
            "Epoch 1609/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 499.0134 - val_loss: 345.1820\n",
            "Epoch 1610/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 556.4485 - val_loss: 277.5409\n",
            "Epoch 1611/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 545.5344 - val_loss: 318.3982\n",
            "Epoch 1612/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 561.0244 - val_loss: 318.5350\n",
            "Epoch 1613/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 542.9234 - val_loss: 312.6951\n",
            "Epoch 1614/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 544.9663 - val_loss: 262.0115\n",
            "Epoch 1615/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 542.4860 - val_loss: 279.9631\n",
            "Epoch 1616/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 573.6987 - val_loss: 285.5508\n",
            "Epoch 1617/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 548.2094 - val_loss: 322.6756\n",
            "Epoch 1618/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 558.6505 - val_loss: 296.9792\n",
            "Epoch 1619/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.2712 - val_loss: 303.1857\n",
            "Epoch 1620/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 525.5599 - val_loss: 276.8804\n",
            "Epoch 1621/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 520.7973 - val_loss: 293.5674\n",
            "Epoch 1622/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 524.9391 - val_loss: 303.0850\n",
            "Epoch 1623/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 562.8703 - val_loss: 316.4493\n",
            "Epoch 1624/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 576.6049 - val_loss: 285.0254\n",
            "Epoch 1625/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 543.7955 - val_loss: 306.8232\n",
            "Epoch 1626/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.6110 - val_loss: 295.4942\n",
            "Epoch 1627/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 555.3616 - val_loss: 339.7112\n",
            "Epoch 1628/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 557.5195 - val_loss: 299.7181\n",
            "Epoch 1629/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.9427 - val_loss: 278.4516\n",
            "Epoch 1630/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 503.7561 - val_loss: 390.5995\n",
            "Epoch 1631/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 557.8454 - val_loss: 315.5569\n",
            "Epoch 1632/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 551.9340 - val_loss: 308.3909\n",
            "Epoch 1633/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 552.4493 - val_loss: 299.9260\n",
            "Epoch 1634/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 540.4971 - val_loss: 327.4057\n",
            "Epoch 1635/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 565.2391 - val_loss: 310.5519\n",
            "Epoch 1636/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 567.3764 - val_loss: 292.2047\n",
            "Epoch 1637/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 543.9551 - val_loss: 266.7009\n",
            "Epoch 1638/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 539.6221 - val_loss: 275.7163\n",
            "Epoch 1639/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 574.6017 - val_loss: 281.1294\n",
            "Epoch 1640/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 535.3163 - val_loss: 259.6781\n",
            "Epoch 1641/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 495.0126 - val_loss: 295.1902\n",
            "Epoch 1642/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 558.1990 - val_loss: 315.6834\n",
            "Epoch 1643/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 560.4540 - val_loss: 300.6145\n",
            "Epoch 1644/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.1730 - val_loss: 291.8232\n",
            "Epoch 1645/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 506.9819 - val_loss: 341.8904\n",
            "Epoch 1646/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 507.9983 - val_loss: 293.6969\n",
            "Epoch 1647/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 528.0362 - val_loss: 325.9561\n",
            "Epoch 1648/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 569.3723 - val_loss: 270.7851\n",
            "Epoch 1649/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 573.0350 - val_loss: 295.7722\n",
            "Epoch 1650/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 540.8629 - val_loss: 336.2379\n",
            "Epoch 1651/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 556.9655 - val_loss: 327.6441\n",
            "Epoch 1652/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 531.2166 - val_loss: 284.1189\n",
            "Epoch 1653/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 547.2692 - val_loss: 313.5973\n",
            "Epoch 1654/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 533.9323 - val_loss: 288.4391\n",
            "Epoch 1655/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 549.6951 - val_loss: 290.2664\n",
            "Epoch 1656/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 591.7783 - val_loss: 325.2506\n",
            "Epoch 1657/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 543.7929 - val_loss: 314.0345\n",
            "Epoch 1658/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 525.7293 - val_loss: 293.9590\n",
            "Epoch 1659/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 557.5720 - val_loss: 304.5902\n",
            "Epoch 1660/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 546.8944 - val_loss: 327.2505\n",
            "Epoch 1661/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.1201 - val_loss: 332.4974\n",
            "Epoch 1662/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 520.7635 - val_loss: 281.6303\n",
            "Epoch 1663/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 523.9773 - val_loss: 286.0377\n",
            "Epoch 1664/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 543.6076 - val_loss: 291.6059\n",
            "Epoch 1665/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 516.1342 - val_loss: 289.0501\n",
            "Epoch 1666/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 537.9826 - val_loss: 284.3660\n",
            "Epoch 1667/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 568.5095 - val_loss: 346.5230\n",
            "Epoch 1668/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 559.6752 - val_loss: 302.2647\n",
            "Epoch 1669/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 536.6863 - val_loss: 317.2660\n",
            "Epoch 1670/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 540.0980 - val_loss: 371.6986\n",
            "Epoch 1671/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 537.7251 - val_loss: 317.2554\n",
            "Epoch 1672/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 555.4814 - val_loss: 320.5754\n",
            "Epoch 1673/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 535.9944 - val_loss: 294.5321\n",
            "Epoch 1674/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 476.6475 - val_loss: 340.0621\n",
            "Epoch 1675/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 494.6621 - val_loss: 301.6396\n",
            "Epoch 1676/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 547.8802 - val_loss: 294.4797\n",
            "Epoch 1677/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 526.4640 - val_loss: 320.1839\n",
            "Epoch 1678/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 523.3461 - val_loss: 293.5818\n",
            "Epoch 1679/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 549.4537 - val_loss: 337.5410\n",
            "Epoch 1680/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 536.2678 - val_loss: 316.3675\n",
            "Epoch 1681/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 537.7204 - val_loss: 284.7728\n",
            "Epoch 1682/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 533.5574 - val_loss: 289.5047\n",
            "Epoch 1683/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 581.3635 - val_loss: 302.9331\n",
            "Epoch 1684/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 528.0054 - val_loss: 335.4603\n",
            "Epoch 1685/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 551.0908 - val_loss: 300.8254\n",
            "Epoch 1686/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 523.1002 - val_loss: 280.6412\n",
            "Epoch 1687/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 512.9648 - val_loss: 342.7792\n",
            "Epoch 1688/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 538.7479 - val_loss: 287.6052\n",
            "Epoch 1689/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 568.6047 - val_loss: 308.6386\n",
            "Epoch 1690/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 542.6035 - val_loss: 330.2100\n",
            "Epoch 1691/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 530.8810 - val_loss: 307.5182\n",
            "Epoch 1692/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 530.1235 - val_loss: 307.5641\n",
            "Epoch 1693/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 559.3352 - val_loss: 342.9025\n",
            "Epoch 1694/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 512.2638 - val_loss: 309.9150\n",
            "Epoch 1695/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 541.8336 - val_loss: 290.8503\n",
            "Epoch 1696/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 517.2416 - val_loss: 293.6982\n",
            "Epoch 1697/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 530.5005 - val_loss: 283.6923\n",
            "Epoch 1698/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 495.8152 - val_loss: 313.8288\n",
            "Epoch 1699/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 480.9543 - val_loss: 266.4576\n",
            "Epoch 1700/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 531.9620 - val_loss: 273.5986\n",
            "Epoch 1701/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 505.9429 - val_loss: 301.2479\n",
            "Epoch 1702/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 534.0024 - val_loss: 298.9980\n",
            "Epoch 1703/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 505.0672 - val_loss: 292.1505\n",
            "Epoch 1704/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 545.6224 - val_loss: 287.5603\n",
            "Epoch 1705/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 520.1646 - val_loss: 312.6216\n",
            "Epoch 1706/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 556.9478 - val_loss: 312.4889\n",
            "Epoch 1707/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 522.0743 - val_loss: 312.0965\n",
            "Epoch 1708/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 521.1978 - val_loss: 333.1746\n",
            "Epoch 1709/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 518.9193 - val_loss: 284.4862\n",
            "Epoch 1710/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 540.6577 - val_loss: 298.4653\n",
            "Epoch 1711/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 518.9432 - val_loss: 300.4349\n",
            "Epoch 1712/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 539.0159 - val_loss: 330.1270\n",
            "Epoch 1713/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 536.9368 - val_loss: 261.7203\n",
            "Epoch 1714/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 540.3983 - val_loss: 266.0270\n",
            "Epoch 1715/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 557.1478 - val_loss: 320.2286\n",
            "Epoch 1716/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 512.2902 - val_loss: 296.8380\n",
            "Epoch 1717/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.2245 - val_loss: 295.7844\n",
            "Epoch 1718/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 557.1551 - val_loss: 321.0055\n",
            "Epoch 1719/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 537.2660 - val_loss: 307.3621\n",
            "Epoch 1720/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 490.3143 - val_loss: 284.5998\n",
            "Epoch 1721/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 539.3973 - val_loss: 307.9919\n",
            "Epoch 1722/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 537.3752 - val_loss: 297.3738\n",
            "Epoch 1723/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 563.9490 - val_loss: 300.1946\n",
            "Epoch 1724/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 519.4855 - val_loss: 292.3203\n",
            "Epoch 1725/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 520.4061 - val_loss: 295.6909\n",
            "Epoch 1726/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 488.9820 - val_loss: 297.9512\n",
            "Epoch 1727/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 495.5497 - val_loss: 283.5638\n",
            "Epoch 1728/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 525.8402 - val_loss: 280.3709\n",
            "Epoch 1729/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.8922 - val_loss: 321.8999\n",
            "Epoch 1730/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 555.1246 - val_loss: 337.5914\n",
            "Epoch 1731/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 524.1553 - val_loss: 306.1374\n",
            "Epoch 1732/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 485.6128 - val_loss: 301.8742\n",
            "Epoch 1733/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 524.6866 - val_loss: 316.7689\n",
            "Epoch 1734/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.0314 - val_loss: 275.7728\n",
            "Epoch 1735/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 535.0869 - val_loss: 323.7731\n",
            "Epoch 1736/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 521.1516 - val_loss: 284.5518\n",
            "Epoch 1737/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 501.8116 - val_loss: 285.0200\n",
            "Epoch 1738/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 506.8676 - val_loss: 306.7312\n",
            "Epoch 1739/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 509.9805 - val_loss: 270.4680\n",
            "Epoch 1740/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 532.8239 - val_loss: 268.5113\n",
            "Epoch 1741/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 498.5675 - val_loss: 318.3190\n",
            "Epoch 1742/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 542.0822 - val_loss: 333.1915\n",
            "Epoch 1743/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 538.7126 - val_loss: 335.9805\n",
            "Epoch 1744/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 498.5656 - val_loss: 282.0981\n",
            "Epoch 1745/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 530.1102 - val_loss: 292.0421\n",
            "Epoch 1746/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 513.9973 - val_loss: 280.4971\n",
            "Epoch 1747/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 538.8897 - val_loss: 330.0073\n",
            "Epoch 1748/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.7098 - val_loss: 285.0189\n",
            "Epoch 1749/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 523.5758 - val_loss: 317.5554\n",
            "Epoch 1750/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 524.6968 - val_loss: 339.3743\n",
            "Epoch 1751/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 523.0479 - val_loss: 299.4813\n",
            "Epoch 1752/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 514.1490 - val_loss: 342.0037\n",
            "Epoch 1753/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 520.8323 - val_loss: 314.6708\n",
            "Epoch 1754/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 478.4553 - val_loss: 302.6406\n",
            "Epoch 1755/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 510.9955 - val_loss: 302.5150\n",
            "Epoch 1756/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 566.4732 - val_loss: 316.5408\n",
            "Epoch 1757/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 549.5045 - val_loss: 342.5443\n",
            "Epoch 1758/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 531.5821 - val_loss: 301.1944\n",
            "Epoch 1759/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 553.2045 - val_loss: 371.6345\n",
            "Epoch 1760/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 525.8567 - val_loss: 278.5645\n",
            "Epoch 1761/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 501.1660 - val_loss: 290.0320\n",
            "Epoch 1762/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 523.0292 - val_loss: 324.4873\n",
            "Epoch 1763/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 505.2783 - val_loss: 283.5267\n",
            "Epoch 1764/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 497.0060 - val_loss: 296.7159\n",
            "Epoch 1765/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 487.8193 - val_loss: 286.4992\n",
            "Epoch 1766/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 495.8129 - val_loss: 276.0295\n",
            "Epoch 1767/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 502.9142 - val_loss: 324.2090\n",
            "Epoch 1768/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 518.6703 - val_loss: 275.9557\n",
            "Epoch 1769/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 565.0789 - val_loss: 280.9830\n",
            "Epoch 1770/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 518.0001 - val_loss: 292.2141\n",
            "Epoch 1771/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 549.4201 - val_loss: 325.0528\n",
            "Epoch 1772/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 548.6862 - val_loss: 307.8432\n",
            "Epoch 1773/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 553.9734 - val_loss: 323.1967\n",
            "Epoch 1774/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 553.2173 - val_loss: 345.5817\n",
            "Epoch 1775/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 520.2994 - val_loss: 300.3214\n",
            "Epoch 1776/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 510.6536 - val_loss: 293.5702\n",
            "Epoch 1777/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 539.3080 - val_loss: 318.7667\n",
            "Epoch 1778/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 488.3594 - val_loss: 273.2696\n",
            "Epoch 1779/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 522.0876 - val_loss: 293.0482\n",
            "Epoch 1780/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 537.4917 - val_loss: 280.4966\n",
            "Epoch 1781/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 529.6666 - val_loss: 278.6989\n",
            "Epoch 1782/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 508.0423 - val_loss: 292.8372\n",
            "Epoch 1783/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 561.4670 - val_loss: 308.9079\n",
            "Epoch 1784/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 521.2588 - val_loss: 363.6931\n",
            "Epoch 1785/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 497.5503 - val_loss: 290.7315\n",
            "Epoch 1786/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 573.2114 - val_loss: 323.9088\n",
            "Epoch 1787/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 512.9900 - val_loss: 328.6508\n",
            "Epoch 1788/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 547.4091 - val_loss: 343.6684\n",
            "Epoch 1789/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 516.4962 - val_loss: 311.7851\n",
            "Epoch 1790/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 530.1076 - val_loss: 313.4268\n",
            "Epoch 1791/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 503.2647 - val_loss: 298.1905\n",
            "Epoch 1792/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 502.4949 - val_loss: 317.8698\n",
            "Epoch 1793/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 464.0056 - val_loss: 295.6700\n",
            "Epoch 1794/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 515.3503 - val_loss: 282.1689\n",
            "Epoch 1795/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 510.1595 - val_loss: 299.0124\n",
            "Epoch 1796/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.7689 - val_loss: 321.7854\n",
            "Epoch 1797/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 517.6531 - val_loss: 306.0316\n",
            "Epoch 1798/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 547.8220 - val_loss: 332.5754\n",
            "Epoch 1799/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 503.3912 - val_loss: 270.8366\n",
            "Epoch 1800/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 512.1413 - val_loss: 286.1643\n",
            "Epoch 1801/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 544.0576 - val_loss: 305.6386\n",
            "Epoch 1802/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 481.4641 - val_loss: 268.8195\n",
            "Epoch 1803/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 504.5240 - val_loss: 313.4768\n",
            "Epoch 1804/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 528.6901 - val_loss: 304.7012\n",
            "Epoch 1805/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 514.2789 - val_loss: 308.3824\n",
            "Epoch 1806/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 518.1302 - val_loss: 268.6497\n",
            "Epoch 1807/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 498.8141 - val_loss: 290.1207\n",
            "Epoch 1808/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 504.0994 - val_loss: 288.1476\n",
            "Epoch 1809/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 495.3457 - val_loss: 330.2779\n",
            "Epoch 1810/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 508.7594 - val_loss: 278.7957\n",
            "Epoch 1811/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 549.4512 - val_loss: 317.3252\n",
            "Epoch 1812/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 529.2939 - val_loss: 280.3607\n",
            "Epoch 1813/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 515.7592 - val_loss: 286.0574\n",
            "Epoch 1814/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 500.5549 - val_loss: 304.2136\n",
            "Epoch 1815/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 519.0477 - val_loss: 281.6531\n",
            "Epoch 1816/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 482.3284 - val_loss: 283.8067\n",
            "Epoch 1817/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 527.6637 - val_loss: 325.6818\n",
            "Epoch 1818/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 527.7554 - val_loss: 265.1512\n",
            "Epoch 1819/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 511.3845 - val_loss: 264.8966\n",
            "Epoch 1820/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 493.6194 - val_loss: 321.3406\n",
            "Epoch 1821/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 494.9182 - val_loss: 279.7170\n",
            "Epoch 1822/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 499.2436 - val_loss: 269.8424\n",
            "Epoch 1823/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 524.6868 - val_loss: 264.3539\n",
            "Epoch 1824/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 516.4592 - val_loss: 291.8717\n",
            "Epoch 1825/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 513.3196 - val_loss: 301.9928\n",
            "Epoch 1826/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 489.4777 - val_loss: 287.9857\n",
            "Epoch 1827/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 520.3977 - val_loss: 291.6992\n",
            "Epoch 1828/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 500.0564 - val_loss: 308.9923\n",
            "Epoch 1829/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 490.3039 - val_loss: 267.5738\n",
            "Epoch 1830/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 481.9309 - val_loss: 267.6512\n",
            "Epoch 1831/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 530.8490 - val_loss: 304.2014\n",
            "Epoch 1832/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 540.7098 - val_loss: 276.8375\n",
            "Epoch 1833/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 481.5399 - val_loss: 282.8052\n",
            "Epoch 1834/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.4712 - val_loss: 270.1334\n",
            "Epoch 1835/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 501.1776 - val_loss: 299.4175\n",
            "Epoch 1836/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 478.4167 - val_loss: 266.4646\n",
            "Epoch 1837/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 493.6265 - val_loss: 273.5598\n",
            "Epoch 1838/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 489.5475 - val_loss: 326.1897\n",
            "Epoch 1839/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 490.3393 - val_loss: 269.8668\n",
            "Epoch 1840/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 494.6724 - val_loss: 276.8265\n",
            "Epoch 1841/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 502.4553 - val_loss: 304.0261\n",
            "Epoch 1842/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 520.6495 - val_loss: 303.8698\n",
            "Epoch 1843/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 538.6741 - val_loss: 284.7171\n",
            "Epoch 1844/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 512.2491 - val_loss: 324.8975\n",
            "Epoch 1845/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 521.8527 - val_loss: 275.7600\n",
            "Epoch 1846/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 497.1733 - val_loss: 266.2063\n",
            "Epoch 1847/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 483.7991 - val_loss: 292.5755\n",
            "Epoch 1848/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 514.1030 - val_loss: 288.1824\n",
            "Epoch 1849/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 537.3217 - val_loss: 317.7005\n",
            "Epoch 1850/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 517.4877 - val_loss: 279.4871\n",
            "Epoch 1851/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 531.5730 - val_loss: 304.8300\n",
            "Epoch 1852/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 508.7725 - val_loss: 294.0571\n",
            "Epoch 1853/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 522.0954 - val_loss: 289.6462\n",
            "Epoch 1854/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 488.5161 - val_loss: 306.7238\n",
            "Epoch 1855/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 511.2356 - val_loss: 295.1354\n",
            "Epoch 1856/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 515.8238 - val_loss: 291.6134\n",
            "Epoch 1857/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 504.9233 - val_loss: 304.6482\n",
            "Epoch 1858/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 524.7100 - val_loss: 329.0306\n",
            "Epoch 1859/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 529.7637 - val_loss: 290.4700\n",
            "Epoch 1860/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 536.7128 - val_loss: 305.5739\n",
            "Epoch 1861/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 529.6356 - val_loss: 322.2882\n",
            "Epoch 1862/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 488.7427 - val_loss: 302.4975\n",
            "Epoch 1863/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 497.2008 - val_loss: 280.5609\n",
            "Epoch 1864/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 532.5112 - val_loss: 277.0827\n",
            "Epoch 1865/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 510.3078 - val_loss: 329.9846\n",
            "Epoch 1866/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 531.6936 - val_loss: 316.9446\n",
            "Epoch 1867/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 517.8284 - val_loss: 309.1802\n",
            "Epoch 1868/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.9800 - val_loss: 273.3495\n",
            "Epoch 1869/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 468.1419 - val_loss: 301.0085\n",
            "Epoch 1870/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 545.5024 - val_loss: 294.7188\n",
            "Epoch 1871/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 533.0141 - val_loss: 259.0255\n",
            "Epoch 1872/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 503.8623 - val_loss: 273.8711\n",
            "Epoch 1873/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 497.2993 - val_loss: 299.4028\n",
            "Epoch 1874/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 533.4476 - val_loss: 291.3734\n",
            "Epoch 1875/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 484.6545 - val_loss: 274.1213\n",
            "Epoch 1876/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 493.8843 - val_loss: 305.6472\n",
            "Epoch 1877/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 529.5861 - val_loss: 288.9914\n",
            "Epoch 1878/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 521.5954 - val_loss: 300.9112\n",
            "Epoch 1879/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 498.7614 - val_loss: 322.1750\n",
            "Epoch 1880/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 480.3295 - val_loss: 276.3253\n",
            "Epoch 1881/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 500.0643 - val_loss: 269.0416\n",
            "Epoch 1882/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 521.2274 - val_loss: 259.4867\n",
            "Epoch 1883/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 537.2719 - val_loss: 271.9756\n",
            "Epoch 1884/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 503.4371 - val_loss: 331.5811\n",
            "Epoch 1885/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 489.2427 - val_loss: 291.4176\n",
            "Epoch 1886/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 505.8496 - val_loss: 281.0226\n",
            "Epoch 1887/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 512.7426 - val_loss: 287.9642\n",
            "Epoch 1888/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.3416 - val_loss: 287.4185\n",
            "Epoch 1889/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 526.0644 - val_loss: 264.6611\n",
            "Epoch 1890/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 521.5054 - val_loss: 272.1962\n",
            "Epoch 1891/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 473.4294 - val_loss: 277.6532\n",
            "Epoch 1892/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 480.0102 - val_loss: 289.7790\n",
            "Epoch 1893/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 501.2195 - val_loss: 314.6240\n",
            "Epoch 1894/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 516.0756 - val_loss: 291.1610\n",
            "Epoch 1895/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.7537 - val_loss: 277.0318\n",
            "Epoch 1896/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 498.8443 - val_loss: 300.9007\n",
            "Epoch 1897/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 511.8148 - val_loss: 321.5995\n",
            "Epoch 1898/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 496.2168 - val_loss: 300.1159\n",
            "Epoch 1899/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 479.4004 - val_loss: 274.2670\n",
            "Epoch 1900/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 522.1771 - val_loss: 284.6877\n",
            "Epoch 1901/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 531.8801 - val_loss: 291.0288\n",
            "Epoch 1902/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 523.8456 - val_loss: 296.7354\n",
            "Epoch 1903/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 504.1206 - val_loss: 268.1178\n",
            "Epoch 1904/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 468.1192 - val_loss: 297.0510\n",
            "Epoch 1905/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 510.4920 - val_loss: 301.1657\n",
            "Epoch 1906/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 449.3494 - val_loss: 329.0902\n",
            "Epoch 1907/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 489.7966 - val_loss: 309.3791\n",
            "Epoch 1908/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 530.4701 - val_loss: 311.1591\n",
            "Epoch 1909/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 492.1581 - val_loss: 309.0471\n",
            "Epoch 1910/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 491.1819 - val_loss: 312.7301\n",
            "Epoch 1911/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 484.2692 - val_loss: 282.2451\n",
            "Epoch 1912/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 478.0618 - val_loss: 299.0939\n",
            "Epoch 1913/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 520.7465 - val_loss: 294.0842\n",
            "Epoch 1914/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 473.1566 - val_loss: 320.1111\n",
            "Epoch 1915/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 505.0271 - val_loss: 293.1901\n",
            "Epoch 1916/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 512.2983 - val_loss: 264.0057\n",
            "Epoch 1917/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 519.4734 - val_loss: 290.9466\n",
            "Epoch 1918/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 508.3526 - val_loss: 319.6815\n",
            "Epoch 1919/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 504.5066 - val_loss: 348.9875\n",
            "Epoch 1920/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 495.9572 - val_loss: 303.7094\n",
            "Epoch 1921/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 500.7861 - val_loss: 274.7303\n",
            "Epoch 1922/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 496.6180 - val_loss: 283.9539\n",
            "Epoch 1923/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 489.2886 - val_loss: 301.2193\n",
            "Epoch 1924/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 480.4884 - val_loss: 288.9765\n",
            "Epoch 1925/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 480.9913 - val_loss: 291.1545\n",
            "Epoch 1926/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 478.4114 - val_loss: 283.7679\n",
            "Epoch 1927/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 499.5970 - val_loss: 302.3646\n",
            "Epoch 1928/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 490.2996 - val_loss: 277.6398\n",
            "Epoch 1929/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 497.0395 - val_loss: 300.4715\n",
            "Epoch 1930/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 486.1766 - val_loss: 265.6757\n",
            "Epoch 1931/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 473.7383 - val_loss: 283.5395\n",
            "Epoch 1932/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 504.1864 - val_loss: 299.6850\n",
            "Epoch 1933/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 489.5084 - val_loss: 270.4727\n",
            "Epoch 1934/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 513.8551 - val_loss: 308.0589\n",
            "Epoch 1935/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 495.3432 - val_loss: 271.2712\n",
            "Epoch 1936/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 465.4523 - val_loss: 292.7895\n",
            "Epoch 1937/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 503.3206 - val_loss: 326.9646\n",
            "Epoch 1938/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 499.9881 - val_loss: 313.4880\n",
            "Epoch 1939/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 466.6287 - val_loss: 293.4504\n",
            "Epoch 1940/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 482.3782 - val_loss: 299.3062\n",
            "Epoch 1941/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 491.3659 - val_loss: 279.9476\n",
            "Epoch 1942/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 472.7304 - val_loss: 268.1199\n",
            "Epoch 1943/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 545.6643 - val_loss: 286.4522\n",
            "Epoch 1944/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 488.0980 - val_loss: 261.4583\n",
            "Epoch 1945/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 459.6917 - val_loss: 306.7256\n",
            "Epoch 1946/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 493.5249 - val_loss: 295.5218\n",
            "Epoch 1947/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 492.2599 - val_loss: 313.7793\n",
            "Epoch 1948/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 508.4016 - val_loss: 303.0474\n",
            "Epoch 1949/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 446.1133 - val_loss: 280.9874\n",
            "Epoch 1950/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 488.0782 - val_loss: 274.4602\n",
            "Epoch 1951/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 543.0294 - val_loss: 294.9629\n",
            "Epoch 1952/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 499.8611 - val_loss: 281.7646\n",
            "Epoch 1953/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 500.8348 - val_loss: 270.9485\n",
            "Epoch 1954/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 478.2544 - val_loss: 292.9589\n",
            "Epoch 1955/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 501.3268 - val_loss: 283.3738\n",
            "Epoch 1956/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 501.6211 - val_loss: 309.2605\n",
            "Epoch 1957/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 487.0750 - val_loss: 298.7964\n",
            "Epoch 1958/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 490.5457 - val_loss: 333.6958\n",
            "Epoch 1959/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 497.9237 - val_loss: 277.5707\n",
            "Epoch 1960/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 474.6668 - val_loss: 306.0754\n",
            "Epoch 1961/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 485.9776 - val_loss: 303.1645\n",
            "Epoch 1962/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 483.2205 - val_loss: 331.8503\n",
            "Epoch 1963/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 482.1493 - val_loss: 299.2477\n",
            "Epoch 1964/2000\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 493.9214 - val_loss: 306.5091\n",
            "Epoch 1965/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 485.5364 - val_loss: 294.9549\n",
            "Epoch 1966/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 497.6883 - val_loss: 319.6184\n",
            "Epoch 1967/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 501.9792 - val_loss: 275.3994\n",
            "Epoch 1968/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 532.8446 - val_loss: 317.2157\n",
            "Epoch 1969/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 510.4602 - val_loss: 322.9274\n",
            "Epoch 1970/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 483.8690 - val_loss: 286.9958\n",
            "Epoch 1971/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 474.9253 - val_loss: 301.3521\n",
            "Epoch 1972/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 492.9898 - val_loss: 285.1900\n",
            "Epoch 1973/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 492.4067 - val_loss: 316.4319\n",
            "Epoch 1974/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 501.5095 - val_loss: 274.4466\n",
            "Epoch 1975/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 470.5084 - val_loss: 295.5215\n",
            "Epoch 1976/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 483.5361 - val_loss: 282.1235\n",
            "Epoch 1977/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 500.6025 - val_loss: 303.9010\n",
            "Epoch 1978/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 485.2704 - val_loss: 296.7061\n",
            "Epoch 1979/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 497.7366 - val_loss: 291.4875\n",
            "Epoch 1980/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 465.7443 - val_loss: 292.0371\n",
            "Epoch 1981/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 504.3795 - val_loss: 292.4247\n",
            "Epoch 1982/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 501.2681 - val_loss: 306.8602\n",
            "Epoch 1983/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 477.0479 - val_loss: 331.0249\n",
            "Epoch 1984/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 473.6641 - val_loss: 306.0576\n",
            "Epoch 1985/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 496.9332 - val_loss: 317.5579\n",
            "Epoch 1986/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 453.4223 - val_loss: 293.8174\n",
            "Epoch 1987/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 470.0360 - val_loss: 315.0798\n",
            "Epoch 1988/2000\n",
            "44/44 [==============================] - 0s 9ms/step - loss: 450.2402 - val_loss: 287.4415\n",
            "Epoch 1989/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 488.4581 - val_loss: 295.3571\n",
            "Epoch 1990/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 491.0871 - val_loss: 279.0805\n",
            "Epoch 1991/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 483.9502 - val_loss: 288.0219\n",
            "Epoch 1992/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 505.9694 - val_loss: 326.6870\n",
            "Epoch 1993/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 486.3029 - val_loss: 282.2268\n",
            "Epoch 1994/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 501.0429 - val_loss: 315.8388\n",
            "Epoch 1995/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 499.1677 - val_loss: 306.5564\n",
            "Epoch 1996/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 518.6776 - val_loss: 279.8649\n",
            "Epoch 1997/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 543.1125 - val_loss: 311.1809\n",
            "Epoch 1998/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 496.1407 - val_loss: 326.6502\n",
            "Epoch 1999/2000\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 499.6155 - val_loss: 303.3500\n",
            "Epoch 2000/2000\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 469.0790 - val_loss: 310.6571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTTKB9VkrO2K",
        "outputId": "6d33ad0c-e547-448c-87f7-af544ae49b04"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "id": "fSqsmKH6GTsh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q695z1NKZgcF",
        "outputId": "80119103-b2e7-40d9-9af7-f1ae456a191e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                832       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 83,393\n",
            "Trainable params: 83,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(16,8))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.savefig('/content/drive/MyDrive/Colab Notebooks/IPL Score_Analysis/Plots/nn_model_score_byball.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "tIX7XEYJt8Uv",
        "outputId": "c5cf3ff4-af5f-45dd-e789-e6ba18410277"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1test = y1test.ravel()"
      ],
      "metadata": {
        "id": "xvpKL9iYJnJj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(tnewt)\n",
        "sample = pd.DataFrame(predictions,columns=['Predict'])\n",
        "sample['Actual']=y1test\n",
        "sample.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mv9unr5dW71T",
        "outputId": "7f8fa96e-6908-44a1-c3a9-b8daadc1b16c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-572888c4-37e7-41af-be5a-5b3d2b9f11df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predict</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101.575577</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.348579</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183.766754</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>152.148499</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>167.989655</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>168.644852</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>178.245087</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>167.001328</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>156.903931</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>152.662262</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-572888c4-37e7-41af-be5a-5b3d2b9f11df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-572888c4-37e7-41af-be5a-5b3d2b9f11df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-572888c4-37e7-41af-be5a-5b3d2b9f11df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Predict  Actual\n",
              "0  101.575577      70\n",
              "1  110.348579      71\n",
              "2  183.766754     181\n",
              "3  152.148499     183\n",
              "4  167.989655     213\n",
              "5  168.644852     176\n",
              "6  178.245087     184\n",
              "7  167.001328     170\n",
              "8  156.903931     147\n",
              "9  152.662262     150"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_accuracy(y_test,y_pred,thresold):\n",
        "    right = 0\n",
        "    l = len(y_pred)\n",
        "    for i in range(0,l):\n",
        "        if(abs(y_pred[i]-y_test[i]) <= thresold):\n",
        "            right += 1\n",
        "    return ((right/l)*100)"
      ],
      "metadata": {
        "id": "3boeHXs2GqDx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_accuracy(sample['Actual'] , sample['Predict'],12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWM2QVuvGwQV",
        "outputId": "4c81ef87-f5b4-417f-8f06-d6fcd36ae8ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.44827586206896"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.loc[len(df)] = your_array\n",
        "# results.loc[len(results)] = res2\n",
        "# df.append(pd.DataFrame(arr).T)\n",
        "# results = results.append(pd.DataFrame(res2))\n",
        "# results.append(pd.DataFrame(res3))"
      ],
      "metadata": {
        "id": "qiIBS1FzNv0E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ar1 = sample['Actual'].unique()\n",
        "results = pd.DataFrame()\n",
        "for items in ar1:\n",
        "  # print(items)\n",
        "  try2 = sample[sample.Actual == items]\n",
        "  result = (try2.sum())/try2.shape[0]\n",
        "  # print(result)\n",
        "  res = result.values.reshape(1,2)\n",
        "  # print(res)\n",
        "  results = results.append(pd.DataFrame(res))"
      ],
      "metadata": {
        "id": "wtMer1Q1Ly_o"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rankings_pd.rename(columns = {'test':'TEST'}, inplace = True)\n",
        "results.rename(columns = {0: 'Predict',\n",
        "                          1: 'Actual'\n",
        "                          }, inplace = True)"
      ],
      "metadata": {
        "id": "0LVNNslSf5vT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.reset_index(drop = True).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6xM3AvBrhkUX",
        "outputId": "8993fcef-ee73-4885-a1b2-d4d282ad1f9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c00a13eb-67d1-492b-916c-d1196882d53d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predict</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101.575577</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110.348579</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>168.347382</td>\n",
              "      <td>181.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>159.547913</td>\n",
              "      <td>183.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>174.168640</td>\n",
              "      <td>213.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c00a13eb-67d1-492b-916c-d1196882d53d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c00a13eb-67d1-492b-916c-d1196882d53d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c00a13eb-67d1-492b-916c-d1196882d53d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Predict  Actual\n",
              "0  101.575577    70.0\n",
              "1  110.348579    71.0\n",
              "2  168.347382   181.0\n",
              "3  159.547913   183.0\n",
              "4  174.168640   213.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(custom_accuracy(results['Actual'].ravel(),results['Predict'].ravel(),12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz8hpEeehlpx",
        "outputId": "d2774a70-902b-4703-898e-c7a73cefc2d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # results.info()"
      ],
      "metadata": {
        "id": "FdI3A_Pnh6tS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results['Actual']"
      ],
      "metadata": {
        "id": "0aF9iynGiKIF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data set (2021)"
      ],
      "metadata": {
        "id": "4kqjrptoJivo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IPL Score_Analysis/CSV/testset.csv')\n",
        "# tests.head()\n",
        "tests.drop(columns = ['Unnamed: 0'], inplace = True)\n",
        "tests.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "XUgRBtRljIa3",
        "outputId": "dc287fc8-5bf0-4b76-a003-1d593884987b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e523375-2f91-40b5-8226-cafea3b4a137\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>total_runs_y</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1254058</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1254058</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1254058</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1254058</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1254058</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e523375-2f91-40b5-8226-cafea3b4a137')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e523375-2f91-40b5-8226-cafea3b4a137 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e523375-2f91-40b5-8226-cafea3b4a137');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id        date  team1  ...  total_runs_y  cum_total  cum_wicket\n",
              "0  1254058  2021-04-09     12  ...           159          2           0\n",
              "1  1254058  2021-04-09     12  ...           159          2           0\n",
              "2  1254058  2021-04-09     12  ...           159          2           0\n",
              "3  1254058  2021-04-09     12  ...           159          4           0\n",
              "4  1254058  2021-04-09     12  ...           159          4           0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sets = tests.drop(tests[(tests.over < 15.5) | (tests.over >=15.6)].index)\n",
        "sets.reset_index(drop = True)\n",
        "yt1 = sets['total_runs_y']\n",
        "yt2 = sets['winner']\n",
        "tt_2021 = tests['id'].reset_index(drop = True)\n",
        "tt_2021 = tt_2021.to_frame().reset_index(drop = True)\n",
        "sets.drop(columns = ['id', 'date', 'total_runs_y', 'winner'], inplace = True)\n",
        "sets.reset_index(drop=True).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eiVvU1RmsCs8",
        "outputId": "467becca-7f6c-4b99-82f2-74f6939e827a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fae87eee-d2ed-4fb5-a1a2-4c5d6092e520\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team1</th>\n",
              "      <th>team2</th>\n",
              "      <th>toss_winner</th>\n",
              "      <th>inning</th>\n",
              "      <th>over</th>\n",
              "      <th>batting_team</th>\n",
              "      <th>bowling_team</th>\n",
              "      <th>field</th>\n",
              "      <th>D/L</th>\n",
              "      <th>eliminator?</th>\n",
              "      <th>cum_total</th>\n",
              "      <th>cum_wicket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>15.5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>15.5</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fae87eee-d2ed-4fb5-a1a2-4c5d6092e520')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fae87eee-d2ed-4fb5-a1a2-4c5d6092e520 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fae87eee-d2ed-4fb5-a1a2-4c5d6092e520');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   team1  team2  toss_winner  inning  ...  D/L  eliminator?  cum_total  cum_wicket\n",
              "0     12      5            5       1  ...    0            0        135           3\n",
              "1     12      5            5       2  ...    0            0        120           5\n",
              "2     11      6            6       1  ...    0            0        142           6\n",
              "3     11      6            6       2  ...    0            0        157           1\n",
              "4      9      7            7       1  ...    0            0        151           2\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sets.shape"
      ],
      "metadata": {
        "id": "9wHac_51-IcL",
        "outputId": "f8976ab1-8492-4227-ea9a-a3ba8786ec74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yt1 = yt1.ravel()"
      ],
      "metadata": {
        "id": "kEeoXH2OuUEt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = sc.fit_transform(sets)"
      ],
      "metadata": {
        "id": "Tcfs1B3t0KTb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(xs)\n",
        "sample = pd.DataFrame(predictions,columns=['Predict'])\n",
        "sample['Actual']=yt1\n",
        "sample.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "egnrUhkosnl6",
        "outputId": "45374373-6baf-4ba9-89e2-8f26e5a8040a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5449c3fb-7223-45a1-9bdc-5d9796195465\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predict</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>177.922104</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>146.403519</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>176.317825</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177.874512</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>184.392273</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>154.469696</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>188.760071</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>185.767670</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>155.855560</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>154.978577</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5449c3fb-7223-45a1-9bdc-5d9796195465')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5449c3fb-7223-45a1-9bdc-5d9796195465 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5449c3fb-7223-45a1-9bdc-5d9796195465');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Predict  Actual\n",
              "0  177.922104     159\n",
              "1  146.403519     160\n",
              "2  176.317825     188\n",
              "3  177.874512     190\n",
              "4  184.392273     187\n",
              "5  154.469696     177\n",
              "6  188.760071     221\n",
              "7  185.767670     217\n",
              "8  155.855560     152\n",
              "9  154.978577     142"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ar1 = sample['Actual'].unique()\n",
        "results = pd.DataFrame()\n",
        "for items in ar1:\n",
        "  # print(items)\n",
        "  try2 = sample[sample.Actual == items]\n",
        "  result = (try2.sum())/try2.shape[0]\n",
        "  # print(result)\n",
        "  res = result.values.reshape(1,2)\n",
        "  # print(res)\n",
        "  results = results.append(pd.DataFrame(res))"
      ],
      "metadata": {
        "id": "vjsHE_CbzJIo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.rename(columns = {0: 'Predict',\n",
        "                          1: 'Actual'\n",
        "                          }, inplace = True)\n",
        "results.reset_index(drop = True)\n",
        "print(custom_accuracy(results['Actual'].ravel(),results['Predict'].ravel(),12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zee1OFEJ0wFw",
        "outputId": "83c4d62f-bf32-4c40-81b9-d7102eaf6ff8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52.94117647058824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Winner Prediction"
      ],
      "metadata": {
        "id": "M8hn-K1YJokJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# model.add(Dense(88, activation = 'relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(50, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(25, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(14, activation = 'softmax'))\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer='sgd', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "zgVmZ7fY06aD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "win_pred = model.fit(x=xnewt, y=y2train, epochs=1200, \n",
        "          validation_data=(tnewt,y2test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpSDDvj2h8Bo",
        "outputId": "cb25a282-a73b-4a54-da1a-bae6c64fddd0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "44/44 [==============================] - 1s 7ms/step - loss: 2.8735 - accuracy: 0.0392 - val_loss: 2.6384 - val_accuracy: 0.0431\n",
            "Epoch 2/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.7356 - accuracy: 0.0684 - val_loss: 2.5778 - val_accuracy: 0.0690\n",
            "Epoch 3/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.6866 - accuracy: 0.0891 - val_loss: 2.5394 - val_accuracy: 0.1293\n",
            "Epoch 4/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.6420 - accuracy: 0.0969 - val_loss: 2.5071 - val_accuracy: 0.1466\n",
            "Epoch 5/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.6055 - accuracy: 0.1062 - val_loss: 2.4821 - val_accuracy: 0.1552\n",
            "Epoch 6/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.5829 - accuracy: 0.1119 - val_loss: 2.4628 - val_accuracy: 0.1724\n",
            "Epoch 7/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.5463 - accuracy: 0.1183 - val_loss: 2.4415 - val_accuracy: 0.1983\n",
            "Epoch 8/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.5276 - accuracy: 0.1162 - val_loss: 2.4176 - val_accuracy: 0.2069\n",
            "Epoch 9/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.5139 - accuracy: 0.1233 - val_loss: 2.3974 - val_accuracy: 0.2155\n",
            "Epoch 10/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4851 - accuracy: 0.1262 - val_loss: 2.3800 - val_accuracy: 0.2155\n",
            "Epoch 11/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.4977 - accuracy: 0.1169 - val_loss: 2.3628 - val_accuracy: 0.2155\n",
            "Epoch 12/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4662 - accuracy: 0.1390 - val_loss: 2.3439 - val_accuracy: 0.2328\n",
            "Epoch 13/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4519 - accuracy: 0.1368 - val_loss: 2.3266 - val_accuracy: 0.2414\n",
            "Epoch 14/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4425 - accuracy: 0.1340 - val_loss: 2.3084 - val_accuracy: 0.2328\n",
            "Epoch 15/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4400 - accuracy: 0.1525 - val_loss: 2.2930 - val_accuracy: 0.2155\n",
            "Epoch 16/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4360 - accuracy: 0.1397 - val_loss: 2.2818 - val_accuracy: 0.2155\n",
            "Epoch 17/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4257 - accuracy: 0.1276 - val_loss: 2.2676 - val_accuracy: 0.2069\n",
            "Epoch 18/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.1575 - val_loss: 2.2503 - val_accuracy: 0.2155\n",
            "Epoch 19/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.4065 - accuracy: 0.1461 - val_loss: 2.2395 - val_accuracy: 0.2069\n",
            "Epoch 20/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 2.3864 - accuracy: 0.1347 - val_loss: 2.2250 - val_accuracy: 0.2241\n",
            "Epoch 21/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3798 - accuracy: 0.1397 - val_loss: 2.2155 - val_accuracy: 0.2069\n",
            "Epoch 22/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3772 - accuracy: 0.1518 - val_loss: 2.2094 - val_accuracy: 0.2328\n",
            "Epoch 23/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3625 - accuracy: 0.1525 - val_loss: 2.1996 - val_accuracy: 0.2328\n",
            "Epoch 24/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3572 - accuracy: 0.1568 - val_loss: 2.1883 - val_accuracy: 0.2241\n",
            "Epoch 25/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3616 - accuracy: 0.1618 - val_loss: 2.1819 - val_accuracy: 0.2155\n",
            "Epoch 26/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3498 - accuracy: 0.1604 - val_loss: 2.1779 - val_accuracy: 0.2241\n",
            "Epoch 27/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3173 - accuracy: 0.1632 - val_loss: 2.1609 - val_accuracy: 0.2241\n",
            "Epoch 28/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3169 - accuracy: 0.1646 - val_loss: 2.1472 - val_accuracy: 0.2069\n",
            "Epoch 29/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3182 - accuracy: 0.1525 - val_loss: 2.1390 - val_accuracy: 0.2069\n",
            "Epoch 30/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3249 - accuracy: 0.1618 - val_loss: 2.1333 - val_accuracy: 0.2069\n",
            "Epoch 31/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3203 - accuracy: 0.1718 - val_loss: 2.1240 - val_accuracy: 0.2069\n",
            "Epoch 32/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3030 - accuracy: 0.1775 - val_loss: 2.1158 - val_accuracy: 0.2069\n",
            "Epoch 33/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3114 - accuracy: 0.1661 - val_loss: 2.1093 - val_accuracy: 0.2069\n",
            "Epoch 34/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2883 - accuracy: 0.1839 - val_loss: 2.0991 - val_accuracy: 0.2069\n",
            "Epoch 35/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.3013 - accuracy: 0.1839 - val_loss: 2.0907 - val_accuracy: 0.2155\n",
            "Epoch 36/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2805 - accuracy: 0.1810 - val_loss: 2.0847 - val_accuracy: 0.2069\n",
            "Epoch 37/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2957 - accuracy: 0.1725 - val_loss: 2.0782 - val_accuracy: 0.2069\n",
            "Epoch 38/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2942 - accuracy: 0.1803 - val_loss: 2.0760 - val_accuracy: 0.2069\n",
            "Epoch 39/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2769 - accuracy: 0.1732 - val_loss: 2.0678 - val_accuracy: 0.2069\n",
            "Epoch 40/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2736 - accuracy: 0.1725 - val_loss: 2.0595 - val_accuracy: 0.2069\n",
            "Epoch 41/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2717 - accuracy: 0.1711 - val_loss: 2.0559 - val_accuracy: 0.1983\n",
            "Epoch 42/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2663 - accuracy: 0.1946 - val_loss: 2.0507 - val_accuracy: 0.1983\n",
            "Epoch 43/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2506 - accuracy: 0.1939 - val_loss: 2.0401 - val_accuracy: 0.1983\n",
            "Epoch 44/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2711 - accuracy: 0.1789 - val_loss: 2.0367 - val_accuracy: 0.1983\n",
            "Epoch 45/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2556 - accuracy: 0.1818 - val_loss: 2.0323 - val_accuracy: 0.1897\n",
            "Epoch 46/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2438 - accuracy: 0.2003 - val_loss: 2.0260 - val_accuracy: 0.1897\n",
            "Epoch 47/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2438 - accuracy: 0.1867 - val_loss: 2.0204 - val_accuracy: 0.1897\n",
            "Epoch 48/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2412 - accuracy: 0.1917 - val_loss: 2.0170 - val_accuracy: 0.1897\n",
            "Epoch 49/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2396 - accuracy: 0.1953 - val_loss: 2.0145 - val_accuracy: 0.2069\n",
            "Epoch 50/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2527 - accuracy: 0.1846 - val_loss: 2.0109 - val_accuracy: 0.2069\n",
            "Epoch 51/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2131 - accuracy: 0.1981 - val_loss: 2.0024 - val_accuracy: 0.2241\n",
            "Epoch 52/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2337 - accuracy: 0.1946 - val_loss: 1.9958 - val_accuracy: 0.2241\n",
            "Epoch 53/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2362 - accuracy: 0.1960 - val_loss: 1.9949 - val_accuracy: 0.2414\n",
            "Epoch 54/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2394 - accuracy: 0.1846 - val_loss: 1.9909 - val_accuracy: 0.2328\n",
            "Epoch 55/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2240 - accuracy: 0.2053 - val_loss: 1.9908 - val_accuracy: 0.2328\n",
            "Epoch 56/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.2358 - accuracy: 0.1818 - val_loss: 1.9876 - val_accuracy: 0.2241\n",
            "Epoch 57/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2172 - accuracy: 0.2067 - val_loss: 1.9842 - val_accuracy: 0.2155\n",
            "Epoch 58/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2178 - accuracy: 0.2067 - val_loss: 1.9812 - val_accuracy: 0.2241\n",
            "Epoch 59/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2123 - accuracy: 0.2181 - val_loss: 1.9737 - val_accuracy: 0.2328\n",
            "Epoch 60/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1947 - accuracy: 0.2074 - val_loss: 1.9689 - val_accuracy: 0.2328\n",
            "Epoch 61/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2022 - accuracy: 0.2195 - val_loss: 1.9608 - val_accuracy: 0.2328\n",
            "Epoch 62/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2002 - accuracy: 0.2003 - val_loss: 1.9596 - val_accuracy: 0.2328\n",
            "Epoch 63/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2209 - accuracy: 0.1989 - val_loss: 1.9563 - val_accuracy: 0.2241\n",
            "Epoch 64/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.2257 - accuracy: 0.2110 - val_loss: 1.9561 - val_accuracy: 0.2241\n",
            "Epoch 65/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1742 - accuracy: 0.2181 - val_loss: 1.9481 - val_accuracy: 0.2155\n",
            "Epoch 66/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1824 - accuracy: 0.1989 - val_loss: 1.9412 - val_accuracy: 0.2155\n",
            "Epoch 67/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1815 - accuracy: 0.2096 - val_loss: 1.9354 - val_accuracy: 0.2155\n",
            "Epoch 68/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1666 - accuracy: 0.2160 - val_loss: 1.9327 - val_accuracy: 0.2241\n",
            "Epoch 69/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1831 - accuracy: 0.1974 - val_loss: 1.9318 - val_accuracy: 0.2155\n",
            "Epoch 70/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1745 - accuracy: 0.2110 - val_loss: 1.9287 - val_accuracy: 0.2241\n",
            "Epoch 71/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1722 - accuracy: 0.2217 - val_loss: 1.9268 - val_accuracy: 0.2155\n",
            "Epoch 72/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1623 - accuracy: 0.2217 - val_loss: 1.9240 - val_accuracy: 0.2328\n",
            "Epoch 73/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1915 - accuracy: 0.1932 - val_loss: 1.9202 - val_accuracy: 0.2241\n",
            "Epoch 74/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1637 - accuracy: 0.2252 - val_loss: 1.9190 - val_accuracy: 0.2155\n",
            "Epoch 75/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1729 - accuracy: 0.2217 - val_loss: 1.9135 - val_accuracy: 0.2241\n",
            "Epoch 76/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1805 - accuracy: 0.2131 - val_loss: 1.9108 - val_accuracy: 0.2241\n",
            "Epoch 77/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1472 - accuracy: 0.2031 - val_loss: 1.9112 - val_accuracy: 0.2241\n",
            "Epoch 78/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1780 - accuracy: 0.2053 - val_loss: 1.9149 - val_accuracy: 0.2155\n",
            "Epoch 79/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1913 - accuracy: 0.2088 - val_loss: 1.9138 - val_accuracy: 0.2155\n",
            "Epoch 80/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1533 - accuracy: 0.2245 - val_loss: 1.9097 - val_accuracy: 0.2155\n",
            "Epoch 81/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1525 - accuracy: 0.2167 - val_loss: 1.9020 - val_accuracy: 0.2155\n",
            "Epoch 82/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1602 - accuracy: 0.2153 - val_loss: 1.9052 - val_accuracy: 0.2155\n",
            "Epoch 83/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1455 - accuracy: 0.2160 - val_loss: 1.9035 - val_accuracy: 0.2155\n",
            "Epoch 84/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1386 - accuracy: 0.2110 - val_loss: 1.8974 - val_accuracy: 0.2155\n",
            "Epoch 85/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1626 - accuracy: 0.2416 - val_loss: 1.8981 - val_accuracy: 0.2155\n",
            "Epoch 86/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1671 - accuracy: 0.2074 - val_loss: 1.8987 - val_accuracy: 0.2155\n",
            "Epoch 87/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1592 - accuracy: 0.2181 - val_loss: 1.8958 - val_accuracy: 0.2155\n",
            "Epoch 88/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1264 - accuracy: 0.2274 - val_loss: 1.8864 - val_accuracy: 0.2241\n",
            "Epoch 89/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1570 - accuracy: 0.2096 - val_loss: 1.8879 - val_accuracy: 0.2241\n",
            "Epoch 90/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1324 - accuracy: 0.2174 - val_loss: 1.8839 - val_accuracy: 0.2241\n",
            "Epoch 91/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1345 - accuracy: 0.2295 - val_loss: 1.8820 - val_accuracy: 0.2672\n",
            "Epoch 92/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1366 - accuracy: 0.2202 - val_loss: 1.8761 - val_accuracy: 0.2155\n",
            "Epoch 93/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1181 - accuracy: 0.2217 - val_loss: 1.8745 - val_accuracy: 0.2328\n",
            "Epoch 94/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1371 - accuracy: 0.2174 - val_loss: 1.8713 - val_accuracy: 0.2155\n",
            "Epoch 95/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1216 - accuracy: 0.2373 - val_loss: 1.8697 - val_accuracy: 0.2241\n",
            "Epoch 96/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1417 - accuracy: 0.2103 - val_loss: 1.8794 - val_accuracy: 0.2328\n",
            "Epoch 97/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1307 - accuracy: 0.2238 - val_loss: 1.8775 - val_accuracy: 0.2500\n",
            "Epoch 98/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1290 - accuracy: 0.2302 - val_loss: 1.8749 - val_accuracy: 0.2155\n",
            "Epoch 99/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1109 - accuracy: 0.2217 - val_loss: 1.8719 - val_accuracy: 0.2155\n",
            "Epoch 100/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1292 - accuracy: 0.2202 - val_loss: 1.8701 - val_accuracy: 0.2155\n",
            "Epoch 101/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1182 - accuracy: 0.2359 - val_loss: 1.8690 - val_accuracy: 0.2414\n",
            "Epoch 102/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1119 - accuracy: 0.2145 - val_loss: 1.8647 - val_accuracy: 0.2328\n",
            "Epoch 103/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1352 - accuracy: 0.2160 - val_loss: 1.8664 - val_accuracy: 0.2414\n",
            "Epoch 104/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1083 - accuracy: 0.2210 - val_loss: 1.8636 - val_accuracy: 0.2328\n",
            "Epoch 105/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1084 - accuracy: 0.2438 - val_loss: 1.8617 - val_accuracy: 0.2241\n",
            "Epoch 106/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1305 - accuracy: 0.2309 - val_loss: 1.8698 - val_accuracy: 0.2328\n",
            "Epoch 107/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1161 - accuracy: 0.2167 - val_loss: 1.8652 - val_accuracy: 0.2500\n",
            "Epoch 108/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1177 - accuracy: 0.2366 - val_loss: 1.8637 - val_accuracy: 0.2414\n",
            "Epoch 109/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1174 - accuracy: 0.2110 - val_loss: 1.8597 - val_accuracy: 0.2414\n",
            "Epoch 110/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1195 - accuracy: 0.2231 - val_loss: 1.8611 - val_accuracy: 0.2328\n",
            "Epoch 111/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1105 - accuracy: 0.2181 - val_loss: 1.8540 - val_accuracy: 0.2155\n",
            "Epoch 112/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1052 - accuracy: 0.2188 - val_loss: 1.8560 - val_accuracy: 0.2155\n",
            "Epoch 113/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1008 - accuracy: 0.2274 - val_loss: 1.8602 - val_accuracy: 0.2328\n",
            "Epoch 114/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1080 - accuracy: 0.2345 - val_loss: 1.8516 - val_accuracy: 0.2155\n",
            "Epoch 115/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0705 - accuracy: 0.2438 - val_loss: 1.8450 - val_accuracy: 0.2155\n",
            "Epoch 116/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1151 - accuracy: 0.2359 - val_loss: 1.8452 - val_accuracy: 0.2241\n",
            "Epoch 117/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.1024 - accuracy: 0.2252 - val_loss: 1.8490 - val_accuracy: 0.2155\n",
            "Epoch 118/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0928 - accuracy: 0.2416 - val_loss: 1.8462 - val_accuracy: 0.2241\n",
            "Epoch 119/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0854 - accuracy: 0.2345 - val_loss: 1.8427 - val_accuracy: 0.2328\n",
            "Epoch 120/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0887 - accuracy: 0.2373 - val_loss: 1.8432 - val_accuracy: 0.2155\n",
            "Epoch 121/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0908 - accuracy: 0.2231 - val_loss: 1.8432 - val_accuracy: 0.2155\n",
            "Epoch 122/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.1030 - accuracy: 0.2338 - val_loss: 1.8471 - val_accuracy: 0.2155\n",
            "Epoch 123/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0878 - accuracy: 0.2366 - val_loss: 1.8458 - val_accuracy: 0.2155\n",
            "Epoch 124/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0881 - accuracy: 0.2259 - val_loss: 1.8442 - val_accuracy: 0.2241\n",
            "Epoch 125/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0737 - accuracy: 0.2359 - val_loss: 1.8402 - val_accuracy: 0.2155\n",
            "Epoch 126/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0708 - accuracy: 0.2466 - val_loss: 1.8372 - val_accuracy: 0.2155\n",
            "Epoch 127/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0902 - accuracy: 0.2267 - val_loss: 1.8374 - val_accuracy: 0.2241\n",
            "Epoch 128/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0809 - accuracy: 0.2431 - val_loss: 1.8377 - val_accuracy: 0.2241\n",
            "Epoch 129/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0693 - accuracy: 0.2537 - val_loss: 1.8368 - val_accuracy: 0.2241\n",
            "Epoch 130/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0841 - accuracy: 0.2452 - val_loss: 1.8370 - val_accuracy: 0.2241\n",
            "Epoch 131/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0819 - accuracy: 0.2331 - val_loss: 1.8354 - val_accuracy: 0.2241\n",
            "Epoch 132/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0842 - accuracy: 0.2202 - val_loss: 1.8311 - val_accuracy: 0.2155\n",
            "Epoch 133/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0695 - accuracy: 0.2338 - val_loss: 1.8332 - val_accuracy: 0.2155\n",
            "Epoch 134/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0821 - accuracy: 0.2324 - val_loss: 1.8307 - val_accuracy: 0.2241\n",
            "Epoch 135/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0762 - accuracy: 0.2373 - val_loss: 1.8285 - val_accuracy: 0.2241\n",
            "Epoch 136/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0781 - accuracy: 0.2388 - val_loss: 1.8268 - val_accuracy: 0.2241\n",
            "Epoch 137/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0617 - accuracy: 0.2388 - val_loss: 1.8259 - val_accuracy: 0.2241\n",
            "Epoch 138/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0814 - accuracy: 0.2274 - val_loss: 1.8271 - val_accuracy: 0.2328\n",
            "Epoch 139/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0891 - accuracy: 0.2252 - val_loss: 1.8304 - val_accuracy: 0.2155\n",
            "Epoch 140/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0761 - accuracy: 0.2324 - val_loss: 1.8295 - val_accuracy: 0.2241\n",
            "Epoch 141/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0706 - accuracy: 0.2388 - val_loss: 1.8308 - val_accuracy: 0.2241\n",
            "Epoch 142/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0692 - accuracy: 0.2523 - val_loss: 1.8290 - val_accuracy: 0.2328\n",
            "Epoch 143/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0588 - accuracy: 0.2416 - val_loss: 1.8212 - val_accuracy: 0.2328\n",
            "Epoch 144/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0787 - accuracy: 0.2530 - val_loss: 1.8227 - val_accuracy: 0.2241\n",
            "Epoch 145/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0350 - accuracy: 0.2316 - val_loss: 1.8221 - val_accuracy: 0.2241\n",
            "Epoch 146/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0712 - accuracy: 0.2359 - val_loss: 1.8233 - val_accuracy: 0.2241\n",
            "Epoch 147/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0498 - accuracy: 0.2359 - val_loss: 1.8187 - val_accuracy: 0.2155\n",
            "Epoch 148/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0552 - accuracy: 0.2409 - val_loss: 1.8189 - val_accuracy: 0.2328\n",
            "Epoch 149/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0425 - accuracy: 0.2573 - val_loss: 1.8200 - val_accuracy: 0.2328\n",
            "Epoch 150/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0400 - accuracy: 0.2395 - val_loss: 1.8175 - val_accuracy: 0.2328\n",
            "Epoch 151/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0524 - accuracy: 0.2431 - val_loss: 1.8209 - val_accuracy: 0.2155\n",
            "Epoch 152/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0508 - accuracy: 0.2473 - val_loss: 1.8176 - val_accuracy: 0.2155\n",
            "Epoch 153/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0625 - accuracy: 0.2409 - val_loss: 1.8181 - val_accuracy: 0.2328\n",
            "Epoch 154/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0642 - accuracy: 0.2438 - val_loss: 1.8200 - val_accuracy: 0.2155\n",
            "Epoch 155/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0700 - accuracy: 0.2445 - val_loss: 1.8182 - val_accuracy: 0.2241\n",
            "Epoch 156/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0558 - accuracy: 0.2373 - val_loss: 1.8173 - val_accuracy: 0.2155\n",
            "Epoch 157/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0502 - accuracy: 0.2537 - val_loss: 1.8158 - val_accuracy: 0.2241\n",
            "Epoch 158/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0574 - accuracy: 0.2331 - val_loss: 1.8207 - val_accuracy: 0.2155\n",
            "Epoch 159/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0370 - accuracy: 0.2402 - val_loss: 1.8186 - val_accuracy: 0.2500\n",
            "Epoch 160/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0652 - accuracy: 0.2395 - val_loss: 1.8193 - val_accuracy: 0.2414\n",
            "Epoch 161/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0617 - accuracy: 0.2488 - val_loss: 1.8123 - val_accuracy: 0.2328\n",
            "Epoch 162/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0532 - accuracy: 0.2566 - val_loss: 1.8168 - val_accuracy: 0.2328\n",
            "Epoch 163/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0523 - accuracy: 0.2352 - val_loss: 1.8184 - val_accuracy: 0.2155\n",
            "Epoch 164/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0546 - accuracy: 0.2630 - val_loss: 1.8181 - val_accuracy: 0.2241\n",
            "Epoch 165/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0294 - accuracy: 0.2552 - val_loss: 1.8174 - val_accuracy: 0.2241\n",
            "Epoch 166/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0462 - accuracy: 0.2402 - val_loss: 1.8148 - val_accuracy: 0.2155\n",
            "Epoch 167/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0514 - accuracy: 0.2359 - val_loss: 1.8155 - val_accuracy: 0.2500\n",
            "Epoch 168/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0567 - accuracy: 0.2530 - val_loss: 1.8152 - val_accuracy: 0.2155\n",
            "Epoch 169/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0299 - accuracy: 0.2609 - val_loss: 1.8159 - val_accuracy: 0.2241\n",
            "Epoch 170/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0537 - accuracy: 0.2566 - val_loss: 1.8174 - val_accuracy: 0.2155\n",
            "Epoch 171/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0459 - accuracy: 0.2687 - val_loss: 1.8148 - val_accuracy: 0.2155\n",
            "Epoch 172/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0365 - accuracy: 0.2409 - val_loss: 1.8119 - val_accuracy: 0.2155\n",
            "Epoch 173/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0451 - accuracy: 0.2452 - val_loss: 1.8145 - val_accuracy: 0.2241\n",
            "Epoch 174/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0488 - accuracy: 0.2480 - val_loss: 1.8092 - val_accuracy: 0.2328\n",
            "Epoch 175/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0344 - accuracy: 0.2509 - val_loss: 1.8105 - val_accuracy: 0.2328\n",
            "Epoch 176/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0395 - accuracy: 0.2594 - val_loss: 1.8055 - val_accuracy: 0.2328\n",
            "Epoch 177/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0358 - accuracy: 0.2530 - val_loss: 1.8052 - val_accuracy: 0.2328\n",
            "Epoch 178/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0533 - accuracy: 0.2708 - val_loss: 1.8061 - val_accuracy: 0.2414\n",
            "Epoch 179/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0425 - accuracy: 0.2416 - val_loss: 1.8020 - val_accuracy: 0.2414\n",
            "Epoch 180/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0157 - accuracy: 0.2616 - val_loss: 1.8029 - val_accuracy: 0.2414\n",
            "Epoch 181/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0084 - accuracy: 0.2523 - val_loss: 1.8057 - val_accuracy: 0.2500\n",
            "Epoch 182/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0214 - accuracy: 0.2516 - val_loss: 1.8019 - val_accuracy: 0.2414\n",
            "Epoch 183/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0314 - accuracy: 0.2623 - val_loss: 1.7989 - val_accuracy: 0.2500\n",
            "Epoch 184/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0395 - accuracy: 0.2480 - val_loss: 1.7962 - val_accuracy: 0.2759\n",
            "Epoch 185/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0214 - accuracy: 0.2594 - val_loss: 1.7980 - val_accuracy: 0.2759\n",
            "Epoch 186/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0507 - accuracy: 0.2495 - val_loss: 1.7989 - val_accuracy: 0.2500\n",
            "Epoch 187/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0316 - accuracy: 0.2438 - val_loss: 1.8000 - val_accuracy: 0.2586\n",
            "Epoch 188/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0377 - accuracy: 0.2416 - val_loss: 1.7970 - val_accuracy: 0.2500\n",
            "Epoch 189/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0331 - accuracy: 0.2488 - val_loss: 1.7971 - val_accuracy: 0.2586\n",
            "Epoch 190/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0068 - accuracy: 0.2566 - val_loss: 1.7913 - val_accuracy: 0.2500\n",
            "Epoch 191/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0342 - accuracy: 0.2609 - val_loss: 1.7967 - val_accuracy: 0.2759\n",
            "Epoch 192/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0481 - accuracy: 0.2459 - val_loss: 1.7991 - val_accuracy: 0.2759\n",
            "Epoch 193/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0284 - accuracy: 0.2566 - val_loss: 1.7934 - val_accuracy: 0.2586\n",
            "Epoch 194/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0129 - accuracy: 0.2552 - val_loss: 1.7925 - val_accuracy: 0.2586\n",
            "Epoch 195/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0182 - accuracy: 0.2616 - val_loss: 1.7911 - val_accuracy: 0.2586\n",
            "Epoch 196/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0294 - accuracy: 0.2495 - val_loss: 1.7921 - val_accuracy: 0.2586\n",
            "Epoch 197/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0161 - accuracy: 0.2723 - val_loss: 1.7848 - val_accuracy: 0.2500\n",
            "Epoch 198/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0466 - accuracy: 0.2573 - val_loss: 1.7918 - val_accuracy: 0.2845\n",
            "Epoch 199/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0197 - accuracy: 0.2495 - val_loss: 1.7867 - val_accuracy: 0.2586\n",
            "Epoch 200/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 2.0118 - accuracy: 0.2687 - val_loss: 1.7855 - val_accuracy: 0.2500\n",
            "Epoch 201/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0174 - accuracy: 0.2566 - val_loss: 1.7845 - val_accuracy: 0.2500\n",
            "Epoch 202/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0116 - accuracy: 0.2523 - val_loss: 1.7832 - val_accuracy: 0.2586\n",
            "Epoch 203/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9937 - accuracy: 0.2630 - val_loss: 1.7799 - val_accuracy: 0.2586\n",
            "Epoch 204/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0065 - accuracy: 0.2623 - val_loss: 1.7836 - val_accuracy: 0.2845\n",
            "Epoch 205/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 2.0117 - accuracy: 0.2651 - val_loss: 1.7835 - val_accuracy: 0.2672\n",
            "Epoch 206/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0075 - accuracy: 0.2594 - val_loss: 1.7856 - val_accuracy: 0.2931\n",
            "Epoch 207/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9965 - accuracy: 0.2495 - val_loss: 1.7801 - val_accuracy: 0.2672\n",
            "Epoch 208/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0125 - accuracy: 0.2602 - val_loss: 1.7834 - val_accuracy: 0.2845\n",
            "Epoch 209/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9944 - accuracy: 0.2516 - val_loss: 1.7865 - val_accuracy: 0.2845\n",
            "Epoch 210/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9850 - accuracy: 0.2723 - val_loss: 1.7799 - val_accuracy: 0.2931\n",
            "Epoch 211/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9937 - accuracy: 0.2666 - val_loss: 1.7784 - val_accuracy: 0.2845\n",
            "Epoch 212/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0116 - accuracy: 0.2573 - val_loss: 1.7767 - val_accuracy: 0.2586\n",
            "Epoch 213/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0287 - accuracy: 0.2708 - val_loss: 1.7796 - val_accuracy: 0.2931\n",
            "Epoch 214/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0045 - accuracy: 0.2552 - val_loss: 1.7801 - val_accuracy: 0.3017\n",
            "Epoch 215/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9889 - accuracy: 0.2651 - val_loss: 1.7737 - val_accuracy: 0.2672\n",
            "Epoch 216/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9869 - accuracy: 0.2623 - val_loss: 1.7696 - val_accuracy: 0.2672\n",
            "Epoch 217/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9740 - accuracy: 0.2887 - val_loss: 1.7680 - val_accuracy: 0.2500\n",
            "Epoch 218/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9960 - accuracy: 0.2751 - val_loss: 1.7737 - val_accuracy: 0.2672\n",
            "Epoch 219/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0193 - accuracy: 0.2594 - val_loss: 1.7724 - val_accuracy: 0.2586\n",
            "Epoch 220/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0040 - accuracy: 0.2530 - val_loss: 1.7685 - val_accuracy: 0.2672\n",
            "Epoch 221/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0114 - accuracy: 0.2673 - val_loss: 1.7687 - val_accuracy: 0.2759\n",
            "Epoch 222/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9953 - accuracy: 0.2573 - val_loss: 1.7655 - val_accuracy: 0.3017\n",
            "Epoch 223/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0101 - accuracy: 0.2815 - val_loss: 1.7655 - val_accuracy: 0.2845\n",
            "Epoch 224/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0171 - accuracy: 0.2651 - val_loss: 1.7700 - val_accuracy: 0.3017\n",
            "Epoch 225/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0062 - accuracy: 0.2594 - val_loss: 1.7663 - val_accuracy: 0.3103\n",
            "Epoch 226/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9916 - accuracy: 0.2630 - val_loss: 1.7630 - val_accuracy: 0.3017\n",
            "Epoch 227/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9905 - accuracy: 0.2623 - val_loss: 1.7595 - val_accuracy: 0.3103\n",
            "Epoch 228/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9844 - accuracy: 0.2708 - val_loss: 1.7570 - val_accuracy: 0.3017\n",
            "Epoch 229/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9952 - accuracy: 0.2730 - val_loss: 1.7651 - val_accuracy: 0.3103\n",
            "Epoch 230/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9899 - accuracy: 0.2616 - val_loss: 1.7635 - val_accuracy: 0.3190\n",
            "Epoch 231/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9922 - accuracy: 0.2823 - val_loss: 1.7603 - val_accuracy: 0.3017\n",
            "Epoch 232/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0100 - accuracy: 0.2716 - val_loss: 1.7632 - val_accuracy: 0.3017\n",
            "Epoch 233/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9905 - accuracy: 0.2666 - val_loss: 1.7585 - val_accuracy: 0.2931\n",
            "Epoch 234/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9865 - accuracy: 0.2666 - val_loss: 1.7606 - val_accuracy: 0.3103\n",
            "Epoch 235/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0043 - accuracy: 0.2851 - val_loss: 1.7623 - val_accuracy: 0.2759\n",
            "Epoch 236/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0008 - accuracy: 0.2687 - val_loss: 1.7678 - val_accuracy: 0.2931\n",
            "Epoch 237/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9896 - accuracy: 0.2808 - val_loss: 1.7647 - val_accuracy: 0.2931\n",
            "Epoch 238/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9956 - accuracy: 0.2716 - val_loss: 1.7634 - val_accuracy: 0.2759\n",
            "Epoch 239/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9873 - accuracy: 0.2573 - val_loss: 1.7622 - val_accuracy: 0.2759\n",
            "Epoch 240/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9726 - accuracy: 0.2794 - val_loss: 1.7612 - val_accuracy: 0.2931\n",
            "Epoch 241/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9852 - accuracy: 0.2559 - val_loss: 1.7601 - val_accuracy: 0.2931\n",
            "Epoch 242/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9873 - accuracy: 0.2716 - val_loss: 1.7578 - val_accuracy: 0.2845\n",
            "Epoch 243/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0003 - accuracy: 0.2516 - val_loss: 1.7609 - val_accuracy: 0.2845\n",
            "Epoch 244/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9793 - accuracy: 0.2708 - val_loss: 1.7594 - val_accuracy: 0.3017\n",
            "Epoch 245/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9695 - accuracy: 0.2865 - val_loss: 1.7544 - val_accuracy: 0.3017\n",
            "Epoch 246/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9832 - accuracy: 0.2787 - val_loss: 1.7567 - val_accuracy: 0.3017\n",
            "Epoch 247/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9754 - accuracy: 0.2637 - val_loss: 1.7546 - val_accuracy: 0.3017\n",
            "Epoch 248/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9981 - accuracy: 0.2808 - val_loss: 1.7538 - val_accuracy: 0.3017\n",
            "Epoch 249/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9429 - accuracy: 0.3015 - val_loss: 1.7528 - val_accuracy: 0.3017\n",
            "Epoch 250/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9776 - accuracy: 0.2723 - val_loss: 1.7551 - val_accuracy: 0.2931\n",
            "Epoch 251/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9727 - accuracy: 0.2723 - val_loss: 1.7557 - val_accuracy: 0.3017\n",
            "Epoch 252/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9735 - accuracy: 0.2958 - val_loss: 1.7533 - val_accuracy: 0.2931\n",
            "Epoch 253/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9877 - accuracy: 0.2815 - val_loss: 1.7530 - val_accuracy: 0.3017\n",
            "Epoch 254/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9755 - accuracy: 0.2758 - val_loss: 1.7494 - val_accuracy: 0.3017\n",
            "Epoch 255/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9723 - accuracy: 0.2780 - val_loss: 1.7485 - val_accuracy: 0.3017\n",
            "Epoch 256/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9786 - accuracy: 0.2766 - val_loss: 1.7476 - val_accuracy: 0.3017\n",
            "Epoch 257/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9877 - accuracy: 0.2666 - val_loss: 1.7481 - val_accuracy: 0.3103\n",
            "Epoch 258/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 2.0007 - accuracy: 0.2766 - val_loss: 1.7542 - val_accuracy: 0.3017\n",
            "Epoch 259/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9701 - accuracy: 0.2723 - val_loss: 1.7468 - val_accuracy: 0.3103\n",
            "Epoch 260/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9655 - accuracy: 0.2908 - val_loss: 1.7441 - val_accuracy: 0.3017\n",
            "Epoch 261/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9924 - accuracy: 0.2730 - val_loss: 1.7473 - val_accuracy: 0.3103\n",
            "Epoch 262/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9901 - accuracy: 0.2773 - val_loss: 1.7507 - val_accuracy: 0.3017\n",
            "Epoch 263/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9769 - accuracy: 0.2766 - val_loss: 1.7483 - val_accuracy: 0.3017\n",
            "Epoch 264/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9645 - accuracy: 0.2737 - val_loss: 1.7489 - val_accuracy: 0.2931\n",
            "Epoch 265/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9684 - accuracy: 0.2815 - val_loss: 1.7494 - val_accuracy: 0.2931\n",
            "Epoch 266/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9744 - accuracy: 0.2787 - val_loss: 1.7442 - val_accuracy: 0.2931\n",
            "Epoch 267/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9445 - accuracy: 0.2823 - val_loss: 1.7437 - val_accuracy: 0.2931\n",
            "Epoch 268/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9590 - accuracy: 0.2823 - val_loss: 1.7370 - val_accuracy: 0.3017\n",
            "Epoch 269/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9898 - accuracy: 0.2815 - val_loss: 1.7377 - val_accuracy: 0.3017\n",
            "Epoch 270/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9552 - accuracy: 0.2844 - val_loss: 1.7341 - val_accuracy: 0.3103\n",
            "Epoch 271/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9693 - accuracy: 0.2673 - val_loss: 1.7366 - val_accuracy: 0.3276\n",
            "Epoch 272/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9704 - accuracy: 0.2730 - val_loss: 1.7377 - val_accuracy: 0.3017\n",
            "Epoch 273/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9811 - accuracy: 0.2794 - val_loss: 1.7413 - val_accuracy: 0.3017\n",
            "Epoch 274/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9505 - accuracy: 0.2808 - val_loss: 1.7396 - val_accuracy: 0.3103\n",
            "Epoch 275/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9725 - accuracy: 0.2766 - val_loss: 1.7395 - val_accuracy: 0.3017\n",
            "Epoch 276/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9821 - accuracy: 0.2680 - val_loss: 1.7388 - val_accuracy: 0.2931\n",
            "Epoch 277/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9535 - accuracy: 0.2837 - val_loss: 1.7354 - val_accuracy: 0.3190\n",
            "Epoch 278/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9425 - accuracy: 0.3008 - val_loss: 1.7313 - val_accuracy: 0.3190\n",
            "Epoch 279/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9545 - accuracy: 0.2787 - val_loss: 1.7355 - val_accuracy: 0.3276\n",
            "Epoch 280/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9510 - accuracy: 0.2751 - val_loss: 1.7318 - val_accuracy: 0.3190\n",
            "Epoch 281/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9783 - accuracy: 0.2794 - val_loss: 1.7349 - val_accuracy: 0.3103\n",
            "Epoch 282/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9545 - accuracy: 0.2865 - val_loss: 1.7337 - val_accuracy: 0.3103\n",
            "Epoch 283/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9521 - accuracy: 0.2808 - val_loss: 1.7299 - val_accuracy: 0.3017\n",
            "Epoch 284/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9399 - accuracy: 0.2837 - val_loss: 1.7265 - val_accuracy: 0.3103\n",
            "Epoch 285/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9408 - accuracy: 0.2780 - val_loss: 1.7261 - val_accuracy: 0.2931\n",
            "Epoch 286/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9348 - accuracy: 0.2929 - val_loss: 1.7200 - val_accuracy: 0.3276\n",
            "Epoch 287/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9426 - accuracy: 0.2659 - val_loss: 1.7161 - val_accuracy: 0.3190\n",
            "Epoch 288/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9644 - accuracy: 0.2837 - val_loss: 1.7228 - val_accuracy: 0.3190\n",
            "Epoch 289/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9281 - accuracy: 0.2851 - val_loss: 1.7200 - val_accuracy: 0.3103\n",
            "Epoch 290/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9552 - accuracy: 0.2929 - val_loss: 1.7172 - val_accuracy: 0.3103\n",
            "Epoch 291/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9468 - accuracy: 0.2865 - val_loss: 1.7197 - val_accuracy: 0.3362\n",
            "Epoch 292/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9522 - accuracy: 0.2744 - val_loss: 1.7169 - val_accuracy: 0.3103\n",
            "Epoch 293/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9137 - accuracy: 0.2972 - val_loss: 1.7062 - val_accuracy: 0.3103\n",
            "Epoch 294/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9596 - accuracy: 0.2851 - val_loss: 1.7147 - val_accuracy: 0.3103\n",
            "Epoch 295/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9540 - accuracy: 0.2659 - val_loss: 1.7169 - val_accuracy: 0.3190\n",
            "Epoch 296/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9445 - accuracy: 0.2851 - val_loss: 1.7189 - val_accuracy: 0.3017\n",
            "Epoch 297/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9405 - accuracy: 0.2865 - val_loss: 1.7164 - val_accuracy: 0.3103\n",
            "Epoch 298/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9626 - accuracy: 0.2773 - val_loss: 1.7216 - val_accuracy: 0.3448\n",
            "Epoch 299/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9353 - accuracy: 0.2808 - val_loss: 1.7203 - val_accuracy: 0.3103\n",
            "Epoch 300/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9490 - accuracy: 0.2908 - val_loss: 1.7208 - val_accuracy: 0.3103\n",
            "Epoch 301/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9635 - accuracy: 0.2844 - val_loss: 1.7187 - val_accuracy: 0.3017\n",
            "Epoch 302/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9405 - accuracy: 0.2730 - val_loss: 1.7212 - val_accuracy: 0.3276\n",
            "Epoch 303/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9418 - accuracy: 0.2701 - val_loss: 1.7173 - val_accuracy: 0.3362\n",
            "Epoch 304/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9514 - accuracy: 0.2837 - val_loss: 1.7116 - val_accuracy: 0.2931\n",
            "Epoch 305/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9478 - accuracy: 0.2773 - val_loss: 1.7144 - val_accuracy: 0.3448\n",
            "Epoch 306/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9391 - accuracy: 0.2880 - val_loss: 1.7132 - val_accuracy: 0.3190\n",
            "Epoch 307/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9205 - accuracy: 0.2865 - val_loss: 1.7087 - val_accuracy: 0.3190\n",
            "Epoch 308/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9158 - accuracy: 0.2972 - val_loss: 1.7102 - val_accuracy: 0.3534\n",
            "Epoch 309/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9414 - accuracy: 0.2823 - val_loss: 1.7133 - val_accuracy: 0.3276\n",
            "Epoch 310/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9177 - accuracy: 0.2851 - val_loss: 1.7160 - val_accuracy: 0.3448\n",
            "Epoch 311/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9364 - accuracy: 0.2865 - val_loss: 1.7127 - val_accuracy: 0.3448\n",
            "Epoch 312/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9344 - accuracy: 0.2766 - val_loss: 1.7146 - val_accuracy: 0.3448\n",
            "Epoch 313/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9348 - accuracy: 0.2937 - val_loss: 1.7082 - val_accuracy: 0.3017\n",
            "Epoch 314/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9265 - accuracy: 0.2858 - val_loss: 1.7146 - val_accuracy: 0.2931\n",
            "Epoch 315/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9399 - accuracy: 0.2801 - val_loss: 1.7127 - val_accuracy: 0.3448\n",
            "Epoch 316/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9403 - accuracy: 0.2787 - val_loss: 1.7159 - val_accuracy: 0.3534\n",
            "Epoch 317/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9367 - accuracy: 0.2737 - val_loss: 1.7098 - val_accuracy: 0.3621\n",
            "Epoch 318/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9163 - accuracy: 0.2965 - val_loss: 1.7025 - val_accuracy: 0.3103\n",
            "Epoch 319/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9151 - accuracy: 0.2915 - val_loss: 1.7040 - val_accuracy: 0.3707\n",
            "Epoch 320/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9495 - accuracy: 0.2944 - val_loss: 1.7035 - val_accuracy: 0.3534\n",
            "Epoch 321/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9507 - accuracy: 0.2901 - val_loss: 1.7003 - val_accuracy: 0.3103\n",
            "Epoch 322/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9157 - accuracy: 0.3072 - val_loss: 1.6975 - val_accuracy: 0.3017\n",
            "Epoch 323/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9149 - accuracy: 0.3001 - val_loss: 1.6942 - val_accuracy: 0.3103\n",
            "Epoch 324/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9279 - accuracy: 0.2830 - val_loss: 1.6993 - val_accuracy: 0.3534\n",
            "Epoch 325/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9307 - accuracy: 0.2666 - val_loss: 1.6967 - val_accuracy: 0.3362\n",
            "Epoch 326/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9311 - accuracy: 0.2880 - val_loss: 1.6957 - val_accuracy: 0.3362\n",
            "Epoch 327/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9616 - accuracy: 0.2780 - val_loss: 1.6957 - val_accuracy: 0.3017\n",
            "Epoch 328/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8956 - accuracy: 0.2986 - val_loss: 1.6983 - val_accuracy: 0.3448\n",
            "Epoch 329/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9506 - accuracy: 0.2716 - val_loss: 1.7060 - val_accuracy: 0.3362\n",
            "Epoch 330/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9058 - accuracy: 0.3001 - val_loss: 1.6970 - val_accuracy: 0.3017\n",
            "Epoch 331/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9236 - accuracy: 0.2865 - val_loss: 1.7020 - val_accuracy: 0.3190\n",
            "Epoch 332/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9036 - accuracy: 0.3015 - val_loss: 1.6924 - val_accuracy: 0.3362\n",
            "Epoch 333/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9114 - accuracy: 0.2944 - val_loss: 1.6929 - val_accuracy: 0.3448\n",
            "Epoch 334/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9281 - accuracy: 0.2837 - val_loss: 1.6986 - val_accuracy: 0.3362\n",
            "Epoch 335/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9358 - accuracy: 0.2808 - val_loss: 1.7006 - val_accuracy: 0.3362\n",
            "Epoch 336/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9248 - accuracy: 0.2737 - val_loss: 1.7020 - val_accuracy: 0.3362\n",
            "Epoch 337/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9215 - accuracy: 0.2858 - val_loss: 1.7008 - val_accuracy: 0.3276\n",
            "Epoch 338/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9179 - accuracy: 0.2758 - val_loss: 1.6994 - val_accuracy: 0.3362\n",
            "Epoch 339/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9133 - accuracy: 0.2915 - val_loss: 1.7002 - val_accuracy: 0.3448\n",
            "Epoch 340/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9220 - accuracy: 0.2887 - val_loss: 1.6928 - val_accuracy: 0.3362\n",
            "Epoch 341/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9091 - accuracy: 0.2929 - val_loss: 1.6951 - val_accuracy: 0.3103\n",
            "Epoch 342/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9204 - accuracy: 0.2908 - val_loss: 1.7014 - val_accuracy: 0.3190\n",
            "Epoch 343/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9271 - accuracy: 0.2951 - val_loss: 1.6988 - val_accuracy: 0.3362\n",
            "Epoch 344/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9361 - accuracy: 0.2880 - val_loss: 1.7015 - val_accuracy: 0.3362\n",
            "Epoch 345/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9028 - accuracy: 0.2986 - val_loss: 1.6990 - val_accuracy: 0.3276\n",
            "Epoch 346/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9308 - accuracy: 0.2580 - val_loss: 1.6916 - val_accuracy: 0.3103\n",
            "Epoch 347/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8736 - accuracy: 0.3001 - val_loss: 1.6930 - val_accuracy: 0.3276\n",
            "Epoch 348/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9257 - accuracy: 0.2851 - val_loss: 1.6943 - val_accuracy: 0.3276\n",
            "Epoch 349/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9052 - accuracy: 0.2830 - val_loss: 1.6880 - val_accuracy: 0.3362\n",
            "Epoch 350/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8835 - accuracy: 0.2922 - val_loss: 1.6879 - val_accuracy: 0.3448\n",
            "Epoch 351/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9026 - accuracy: 0.2773 - val_loss: 1.6861 - val_accuracy: 0.3621\n",
            "Epoch 352/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9040 - accuracy: 0.3072 - val_loss: 1.6854 - val_accuracy: 0.3103\n",
            "Epoch 353/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8870 - accuracy: 0.2937 - val_loss: 1.6806 - val_accuracy: 0.2931\n",
            "Epoch 354/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9085 - accuracy: 0.2901 - val_loss: 1.6847 - val_accuracy: 0.3190\n",
            "Epoch 355/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9192 - accuracy: 0.2887 - val_loss: 1.6831 - val_accuracy: 0.2931\n",
            "Epoch 356/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9260 - accuracy: 0.2823 - val_loss: 1.6859 - val_accuracy: 0.3448\n",
            "Epoch 357/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8896 - accuracy: 0.3001 - val_loss: 1.6844 - val_accuracy: 0.3017\n",
            "Epoch 358/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9043 - accuracy: 0.3051 - val_loss: 1.6865 - val_accuracy: 0.3103\n",
            "Epoch 359/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9128 - accuracy: 0.2880 - val_loss: 1.6893 - val_accuracy: 0.3448\n",
            "Epoch 360/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9171 - accuracy: 0.2994 - val_loss: 1.6967 - val_accuracy: 0.3448\n",
            "Epoch 361/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9147 - accuracy: 0.2815 - val_loss: 1.6976 - val_accuracy: 0.3362\n",
            "Epoch 362/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8972 - accuracy: 0.2994 - val_loss: 1.6860 - val_accuracy: 0.3017\n",
            "Epoch 363/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8898 - accuracy: 0.2944 - val_loss: 1.6814 - val_accuracy: 0.3448\n",
            "Epoch 364/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9090 - accuracy: 0.2901 - val_loss: 1.6837 - val_accuracy: 0.3017\n",
            "Epoch 365/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8945 - accuracy: 0.2958 - val_loss: 1.6826 - val_accuracy: 0.3190\n",
            "Epoch 366/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8944 - accuracy: 0.2865 - val_loss: 1.6853 - val_accuracy: 0.3276\n",
            "Epoch 367/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8877 - accuracy: 0.2901 - val_loss: 1.6801 - val_accuracy: 0.3362\n",
            "Epoch 368/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9142 - accuracy: 0.2979 - val_loss: 1.6826 - val_accuracy: 0.3448\n",
            "Epoch 369/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8923 - accuracy: 0.3072 - val_loss: 1.6835 - val_accuracy: 0.3448\n",
            "Epoch 370/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9092 - accuracy: 0.2979 - val_loss: 1.6811 - val_accuracy: 0.3276\n",
            "Epoch 371/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9165 - accuracy: 0.2972 - val_loss: 1.6804 - val_accuracy: 0.3448\n",
            "Epoch 372/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9258 - accuracy: 0.2915 - val_loss: 1.6834 - val_accuracy: 0.3276\n",
            "Epoch 373/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8897 - accuracy: 0.3051 - val_loss: 1.6854 - val_accuracy: 0.3276\n",
            "Epoch 374/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8919 - accuracy: 0.2994 - val_loss: 1.6810 - val_accuracy: 0.3362\n",
            "Epoch 375/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.9188 - accuracy: 0.2986 - val_loss: 1.6772 - val_accuracy: 0.2845\n",
            "Epoch 376/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8680 - accuracy: 0.2994 - val_loss: 1.6802 - val_accuracy: 0.3534\n",
            "Epoch 377/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8721 - accuracy: 0.3093 - val_loss: 1.6794 - val_accuracy: 0.3017\n",
            "Epoch 378/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8921 - accuracy: 0.2994 - val_loss: 1.6772 - val_accuracy: 0.3103\n",
            "Epoch 379/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9049 - accuracy: 0.2872 - val_loss: 1.6792 - val_accuracy: 0.3103\n",
            "Epoch 380/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8738 - accuracy: 0.2972 - val_loss: 1.6796 - val_accuracy: 0.3534\n",
            "Epoch 381/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8871 - accuracy: 0.3001 - val_loss: 1.6816 - val_accuracy: 0.3534\n",
            "Epoch 382/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.9047 - accuracy: 0.2929 - val_loss: 1.6774 - val_accuracy: 0.3448\n",
            "Epoch 383/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.8845 - accuracy: 0.3065 - val_loss: 1.6709 - val_accuracy: 0.3103\n",
            "Epoch 384/1200\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.9063 - accuracy: 0.2858 - val_loss: 1.6776 - val_accuracy: 0.3534\n",
            "Epoch 385/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8830 - accuracy: 0.2944 - val_loss: 1.6742 - val_accuracy: 0.3362\n",
            "Epoch 386/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8843 - accuracy: 0.3079 - val_loss: 1.6775 - val_accuracy: 0.3362\n",
            "Epoch 387/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8960 - accuracy: 0.2880 - val_loss: 1.6768 - val_accuracy: 0.3448\n",
            "Epoch 388/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8889 - accuracy: 0.2758 - val_loss: 1.6749 - val_accuracy: 0.3017\n",
            "Epoch 389/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8786 - accuracy: 0.2844 - val_loss: 1.6757 - val_accuracy: 0.3534\n",
            "Epoch 390/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8695 - accuracy: 0.3015 - val_loss: 1.6712 - val_accuracy: 0.3017\n",
            "Epoch 391/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8697 - accuracy: 0.2994 - val_loss: 1.6672 - val_accuracy: 0.2931\n",
            "Epoch 392/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8892 - accuracy: 0.3036 - val_loss: 1.6609 - val_accuracy: 0.3017\n",
            "Epoch 393/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8833 - accuracy: 0.2937 - val_loss: 1.6660 - val_accuracy: 0.3362\n",
            "Epoch 394/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8726 - accuracy: 0.2872 - val_loss: 1.6619 - val_accuracy: 0.3190\n",
            "Epoch 395/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8724 - accuracy: 0.2972 - val_loss: 1.6633 - val_accuracy: 0.3017\n",
            "Epoch 396/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8792 - accuracy: 0.2944 - val_loss: 1.6678 - val_accuracy: 0.3448\n",
            "Epoch 397/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8806 - accuracy: 0.2972 - val_loss: 1.6621 - val_accuracy: 0.2931\n",
            "Epoch 398/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8750 - accuracy: 0.2958 - val_loss: 1.6655 - val_accuracy: 0.3534\n",
            "Epoch 399/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8775 - accuracy: 0.3058 - val_loss: 1.6659 - val_accuracy: 0.3362\n",
            "Epoch 400/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8650 - accuracy: 0.2937 - val_loss: 1.6601 - val_accuracy: 0.3190\n",
            "Epoch 401/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8753 - accuracy: 0.3051 - val_loss: 1.6603 - val_accuracy: 0.2845\n",
            "Epoch 402/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8855 - accuracy: 0.3008 - val_loss: 1.6662 - val_accuracy: 0.3276\n",
            "Epoch 403/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8858 - accuracy: 0.3022 - val_loss: 1.6587 - val_accuracy: 0.3276\n",
            "Epoch 404/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8860 - accuracy: 0.2887 - val_loss: 1.6588 - val_accuracy: 0.3276\n",
            "Epoch 405/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8739 - accuracy: 0.2958 - val_loss: 1.6631 - val_accuracy: 0.3276\n",
            "Epoch 406/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8538 - accuracy: 0.3136 - val_loss: 1.6604 - val_accuracy: 0.2931\n",
            "Epoch 407/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8750 - accuracy: 0.3051 - val_loss: 1.6679 - val_accuracy: 0.3276\n",
            "Epoch 408/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8764 - accuracy: 0.2915 - val_loss: 1.6612 - val_accuracy: 0.3362\n",
            "Epoch 409/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8647 - accuracy: 0.2958 - val_loss: 1.6602 - val_accuracy: 0.2931\n",
            "Epoch 410/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8737 - accuracy: 0.2872 - val_loss: 1.6651 - val_accuracy: 0.3276\n",
            "Epoch 411/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8755 - accuracy: 0.2944 - val_loss: 1.6642 - val_accuracy: 0.3362\n",
            "Epoch 412/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8450 - accuracy: 0.3058 - val_loss: 1.6574 - val_accuracy: 0.3276\n",
            "Epoch 413/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8584 - accuracy: 0.3243 - val_loss: 1.6660 - val_accuracy: 0.3276\n",
            "Epoch 414/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8483 - accuracy: 0.3079 - val_loss: 1.6606 - val_accuracy: 0.3448\n",
            "Epoch 415/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8793 - accuracy: 0.2979 - val_loss: 1.6693 - val_accuracy: 0.3534\n",
            "Epoch 416/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8513 - accuracy: 0.3129 - val_loss: 1.6634 - val_accuracy: 0.3017\n",
            "Epoch 417/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8698 - accuracy: 0.2880 - val_loss: 1.6614 - val_accuracy: 0.3362\n",
            "Epoch 418/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8557 - accuracy: 0.2972 - val_loss: 1.6589 - val_accuracy: 0.3017\n",
            "Epoch 419/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8779 - accuracy: 0.3058 - val_loss: 1.6640 - val_accuracy: 0.3103\n",
            "Epoch 420/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8577 - accuracy: 0.3086 - val_loss: 1.6630 - val_accuracy: 0.3448\n",
            "Epoch 421/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8551 - accuracy: 0.3136 - val_loss: 1.6628 - val_accuracy: 0.3448\n",
            "Epoch 422/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8563 - accuracy: 0.3058 - val_loss: 1.6566 - val_accuracy: 0.3362\n",
            "Epoch 423/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8641 - accuracy: 0.3072 - val_loss: 1.6504 - val_accuracy: 0.3448\n",
            "Epoch 424/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8741 - accuracy: 0.2815 - val_loss: 1.6577 - val_accuracy: 0.3276\n",
            "Epoch 425/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8564 - accuracy: 0.3143 - val_loss: 1.6550 - val_accuracy: 0.3448\n",
            "Epoch 426/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8509 - accuracy: 0.2972 - val_loss: 1.6479 - val_accuracy: 0.3448\n",
            "Epoch 427/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8734 - accuracy: 0.3008 - val_loss: 1.6484 - val_accuracy: 0.3448\n",
            "Epoch 428/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8484 - accuracy: 0.3072 - val_loss: 1.6489 - val_accuracy: 0.3017\n",
            "Epoch 429/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8618 - accuracy: 0.3029 - val_loss: 1.6503 - val_accuracy: 0.3276\n",
            "Epoch 430/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8499 - accuracy: 0.2937 - val_loss: 1.6553 - val_accuracy: 0.3534\n",
            "Epoch 431/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8469 - accuracy: 0.3072 - val_loss: 1.6542 - val_accuracy: 0.3276\n",
            "Epoch 432/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8523 - accuracy: 0.3100 - val_loss: 1.6547 - val_accuracy: 0.3534\n",
            "Epoch 433/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8680 - accuracy: 0.3065 - val_loss: 1.6537 - val_accuracy: 0.3448\n",
            "Epoch 434/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8524 - accuracy: 0.3036 - val_loss: 1.6526 - val_accuracy: 0.3534\n",
            "Epoch 435/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8542 - accuracy: 0.2929 - val_loss: 1.6512 - val_accuracy: 0.3276\n",
            "Epoch 436/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8456 - accuracy: 0.3058 - val_loss: 1.6491 - val_accuracy: 0.3362\n",
            "Epoch 437/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8397 - accuracy: 0.3158 - val_loss: 1.6468 - val_accuracy: 0.3362\n",
            "Epoch 438/1200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.8757 - accuracy: 0.2958 - val_loss: 1.6490 - val_accuracy: 0.3276\n",
            "Epoch 439/1200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.8646 - accuracy: 0.2894 - val_loss: 1.6491 - val_accuracy: 0.3362\n",
            "Epoch 440/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8616 - accuracy: 0.3150 - val_loss: 1.6583 - val_accuracy: 0.3362\n",
            "Epoch 441/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8674 - accuracy: 0.3093 - val_loss: 1.6509 - val_accuracy: 0.3276\n",
            "Epoch 442/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8499 - accuracy: 0.3065 - val_loss: 1.6501 - val_accuracy: 0.3362\n",
            "Epoch 443/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8461 - accuracy: 0.3001 - val_loss: 1.6468 - val_accuracy: 0.3276\n",
            "Epoch 444/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8335 - accuracy: 0.3072 - val_loss: 1.6564 - val_accuracy: 0.3276\n",
            "Epoch 445/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8244 - accuracy: 0.3051 - val_loss: 1.6558 - val_accuracy: 0.3362\n",
            "Epoch 446/1200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.8519 - accuracy: 0.3029 - val_loss: 1.6507 - val_accuracy: 0.3276\n",
            "Epoch 447/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8399 - accuracy: 0.3179 - val_loss: 1.6482 - val_accuracy: 0.3276\n",
            "Epoch 448/1200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.8599 - accuracy: 0.3072 - val_loss: 1.6478 - val_accuracy: 0.3362\n",
            "Epoch 449/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8640 - accuracy: 0.3001 - val_loss: 1.6497 - val_accuracy: 0.3276\n",
            "Epoch 450/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8483 - accuracy: 0.3179 - val_loss: 1.6557 - val_accuracy: 0.3276\n",
            "Epoch 451/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8524 - accuracy: 0.3129 - val_loss: 1.6554 - val_accuracy: 0.3276\n",
            "Epoch 452/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8334 - accuracy: 0.3200 - val_loss: 1.6517 - val_accuracy: 0.3362\n",
            "Epoch 453/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8401 - accuracy: 0.2972 - val_loss: 1.6533 - val_accuracy: 0.3362\n",
            "Epoch 454/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8303 - accuracy: 0.3086 - val_loss: 1.6484 - val_accuracy: 0.3448\n",
            "Epoch 455/1200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1.8508 - accuracy: 0.2972 - val_loss: 1.6481 - val_accuracy: 0.3276\n",
            "Epoch 456/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8289 - accuracy: 0.3058 - val_loss: 1.6529 - val_accuracy: 0.3276\n",
            "Epoch 457/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8550 - accuracy: 0.2922 - val_loss: 1.6512 - val_accuracy: 0.3448\n",
            "Epoch 458/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8325 - accuracy: 0.3058 - val_loss: 1.6568 - val_accuracy: 0.3448\n",
            "Epoch 459/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8381 - accuracy: 0.3022 - val_loss: 1.6520 - val_accuracy: 0.3362\n",
            "Epoch 460/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8544 - accuracy: 0.2937 - val_loss: 1.6464 - val_accuracy: 0.3276\n",
            "Epoch 461/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8344 - accuracy: 0.3222 - val_loss: 1.6532 - val_accuracy: 0.3190\n",
            "Epoch 462/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8635 - accuracy: 0.2830 - val_loss: 1.6445 - val_accuracy: 0.3448\n",
            "Epoch 463/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8552 - accuracy: 0.3036 - val_loss: 1.6424 - val_accuracy: 0.3362\n",
            "Epoch 464/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8516 - accuracy: 0.3036 - val_loss: 1.6491 - val_accuracy: 0.3103\n",
            "Epoch 465/1200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1.8411 - accuracy: 0.3193 - val_loss: 1.6380 - val_accuracy: 0.3103\n",
            "Epoch 466/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8214 - accuracy: 0.3150 - val_loss: 1.6417 - val_accuracy: 0.3190\n",
            "Epoch 467/1200\n",
            "44/44 [==============================] - 0s 8ms/step - loss: 1.8376 - accuracy: 0.3172 - val_loss: 1.6430 - val_accuracy: 0.3103\n",
            "Epoch 468/1200\n",
            "44/44 [==============================] - 0s 7ms/step - loss: 1.8132 - accuracy: 0.3129 - val_loss: 1.6454 - val_accuracy: 0.3190\n",
            "Epoch 469/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8345 - accuracy: 0.3186 - val_loss: 1.6401 - val_accuracy: 0.3362\n",
            "Epoch 470/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8414 - accuracy: 0.2979 - val_loss: 1.6409 - val_accuracy: 0.3362\n",
            "Epoch 471/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8261 - accuracy: 0.3072 - val_loss: 1.6378 - val_accuracy: 0.3276\n",
            "Epoch 472/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8540 - accuracy: 0.2929 - val_loss: 1.6321 - val_accuracy: 0.3190\n",
            "Epoch 473/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8579 - accuracy: 0.3036 - val_loss: 1.6372 - val_accuracy: 0.3190\n",
            "Epoch 474/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8124 - accuracy: 0.3079 - val_loss: 1.6337 - val_accuracy: 0.3103\n",
            "Epoch 475/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8505 - accuracy: 0.3165 - val_loss: 1.6357 - val_accuracy: 0.3103\n",
            "Epoch 476/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8399 - accuracy: 0.3036 - val_loss: 1.6415 - val_accuracy: 0.3190\n",
            "Epoch 477/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8371 - accuracy: 0.3100 - val_loss: 1.6347 - val_accuracy: 0.3362\n",
            "Epoch 478/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8330 - accuracy: 0.3086 - val_loss: 1.6350 - val_accuracy: 0.3017\n",
            "Epoch 479/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8317 - accuracy: 0.3229 - val_loss: 1.6387 - val_accuracy: 0.3190\n",
            "Epoch 480/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8376 - accuracy: 0.3058 - val_loss: 1.6448 - val_accuracy: 0.3017\n",
            "Epoch 481/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8405 - accuracy: 0.2979 - val_loss: 1.6370 - val_accuracy: 0.3017\n",
            "Epoch 482/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8364 - accuracy: 0.3108 - val_loss: 1.6360 - val_accuracy: 0.2931\n",
            "Epoch 483/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8454 - accuracy: 0.2901 - val_loss: 1.6349 - val_accuracy: 0.3190\n",
            "Epoch 484/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8445 - accuracy: 0.3008 - val_loss: 1.6311 - val_accuracy: 0.2845\n",
            "Epoch 485/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.8353 - accuracy: 0.3143 - val_loss: 1.6367 - val_accuracy: 0.3362\n",
            "Epoch 486/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8250 - accuracy: 0.2951 - val_loss: 1.6325 - val_accuracy: 0.2931\n",
            "Epoch 487/1200\n",
            "44/44 [==============================] - 0s 6ms/step - loss: 1.8332 - accuracy: 0.3029 - val_loss: 1.6394 - val_accuracy: 0.3276\n",
            "Epoch 488/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8433 - accuracy: 0.3065 - val_loss: 1.6381 - val_accuracy: 0.3362\n",
            "Epoch 489/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8148 - accuracy: 0.3058 - val_loss: 1.6429 - val_accuracy: 0.2759\n",
            "Epoch 490/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8470 - accuracy: 0.3015 - val_loss: 1.6446 - val_accuracy: 0.3190\n",
            "Epoch 491/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8284 - accuracy: 0.3036 - val_loss: 1.6395 - val_accuracy: 0.3017\n",
            "Epoch 492/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8123 - accuracy: 0.3108 - val_loss: 1.6402 - val_accuracy: 0.2845\n",
            "Epoch 493/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8172 - accuracy: 0.3036 - val_loss: 1.6384 - val_accuracy: 0.3190\n",
            "Epoch 494/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8152 - accuracy: 0.3215 - val_loss: 1.6357 - val_accuracy: 0.3103\n",
            "Epoch 495/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8388 - accuracy: 0.3051 - val_loss: 1.6425 - val_accuracy: 0.3534\n",
            "Epoch 496/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8259 - accuracy: 0.3079 - val_loss: 1.6417 - val_accuracy: 0.3448\n",
            "Epoch 497/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8326 - accuracy: 0.3172 - val_loss: 1.6464 - val_accuracy: 0.3448\n",
            "Epoch 498/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8432 - accuracy: 0.3036 - val_loss: 1.6425 - val_accuracy: 0.3448\n",
            "Epoch 499/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8258 - accuracy: 0.3243 - val_loss: 1.6479 - val_accuracy: 0.3362\n",
            "Epoch 500/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8146 - accuracy: 0.3172 - val_loss: 1.6469 - val_accuracy: 0.3362\n",
            "Epoch 501/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8343 - accuracy: 0.3172 - val_loss: 1.6470 - val_accuracy: 0.3103\n",
            "Epoch 502/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8045 - accuracy: 0.3086 - val_loss: 1.6446 - val_accuracy: 0.3448\n",
            "Epoch 503/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8471 - accuracy: 0.3029 - val_loss: 1.6480 - val_accuracy: 0.3190\n",
            "Epoch 504/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8255 - accuracy: 0.3165 - val_loss: 1.6459 - val_accuracy: 0.3190\n",
            "Epoch 505/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8035 - accuracy: 0.3364 - val_loss: 1.6406 - val_accuracy: 0.3276\n",
            "Epoch 506/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8065 - accuracy: 0.3172 - val_loss: 1.6413 - val_accuracy: 0.3190\n",
            "Epoch 507/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8251 - accuracy: 0.3150 - val_loss: 1.6488 - val_accuracy: 0.3190\n",
            "Epoch 508/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8124 - accuracy: 0.3136 - val_loss: 1.6404 - val_accuracy: 0.3276\n",
            "Epoch 509/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8310 - accuracy: 0.3108 - val_loss: 1.6416 - val_accuracy: 0.3190\n",
            "Epoch 510/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8128 - accuracy: 0.3022 - val_loss: 1.6457 - val_accuracy: 0.3276\n",
            "Epoch 511/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7998 - accuracy: 0.3093 - val_loss: 1.6341 - val_accuracy: 0.3190\n",
            "Epoch 512/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8009 - accuracy: 0.3250 - val_loss: 1.6335 - val_accuracy: 0.3534\n",
            "Epoch 513/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8091 - accuracy: 0.3136 - val_loss: 1.6305 - val_accuracy: 0.3448\n",
            "Epoch 514/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8130 - accuracy: 0.3122 - val_loss: 1.6275 - val_accuracy: 0.3534\n",
            "Epoch 515/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8061 - accuracy: 0.2965 - val_loss: 1.6317 - val_accuracy: 0.3362\n",
            "Epoch 516/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8127 - accuracy: 0.3072 - val_loss: 1.6324 - val_accuracy: 0.3362\n",
            "Epoch 517/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8061 - accuracy: 0.3043 - val_loss: 1.6329 - val_accuracy: 0.3362\n",
            "Epoch 518/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8263 - accuracy: 0.3065 - val_loss: 1.6422 - val_accuracy: 0.2759\n",
            "Epoch 519/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7867 - accuracy: 0.3150 - val_loss: 1.6215 - val_accuracy: 0.3190\n",
            "Epoch 520/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8213 - accuracy: 0.3193 - val_loss: 1.6269 - val_accuracy: 0.3276\n",
            "Epoch 521/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8073 - accuracy: 0.3179 - val_loss: 1.6398 - val_accuracy: 0.3103\n",
            "Epoch 522/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8052 - accuracy: 0.3236 - val_loss: 1.6349 - val_accuracy: 0.3448\n",
            "Epoch 523/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8245 - accuracy: 0.3200 - val_loss: 1.6311 - val_accuracy: 0.3448\n",
            "Epoch 524/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8064 - accuracy: 0.3015 - val_loss: 1.6291 - val_accuracy: 0.3448\n",
            "Epoch 525/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8211 - accuracy: 0.3015 - val_loss: 1.6296 - val_accuracy: 0.3190\n",
            "Epoch 526/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8175 - accuracy: 0.3172 - val_loss: 1.6255 - val_accuracy: 0.2931\n",
            "Epoch 527/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7994 - accuracy: 0.3143 - val_loss: 1.6301 - val_accuracy: 0.3448\n",
            "Epoch 528/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8235 - accuracy: 0.2986 - val_loss: 1.6323 - val_accuracy: 0.3190\n",
            "Epoch 529/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8234 - accuracy: 0.3150 - val_loss: 1.6362 - val_accuracy: 0.3362\n",
            "Epoch 530/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8237 - accuracy: 0.3093 - val_loss: 1.6340 - val_accuracy: 0.3534\n",
            "Epoch 531/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8136 - accuracy: 0.3136 - val_loss: 1.6225 - val_accuracy: 0.3276\n",
            "Epoch 532/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8095 - accuracy: 0.3093 - val_loss: 1.6239 - val_accuracy: 0.3103\n",
            "Epoch 533/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8237 - accuracy: 0.3093 - val_loss: 1.6329 - val_accuracy: 0.3448\n",
            "Epoch 534/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8139 - accuracy: 0.3200 - val_loss: 1.6247 - val_accuracy: 0.3017\n",
            "Epoch 535/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8336 - accuracy: 0.3086 - val_loss: 1.6297 - val_accuracy: 0.3103\n",
            "Epoch 536/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8125 - accuracy: 0.3172 - val_loss: 1.6365 - val_accuracy: 0.3534\n",
            "Epoch 537/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8148 - accuracy: 0.3079 - val_loss: 1.6260 - val_accuracy: 0.3534\n",
            "Epoch 538/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8062 - accuracy: 0.3186 - val_loss: 1.6238 - val_accuracy: 0.3017\n",
            "Epoch 539/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8374 - accuracy: 0.3022 - val_loss: 1.6210 - val_accuracy: 0.3103\n",
            "Epoch 540/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8135 - accuracy: 0.3108 - val_loss: 1.6131 - val_accuracy: 0.3190\n",
            "Epoch 541/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7954 - accuracy: 0.3186 - val_loss: 1.6213 - val_accuracy: 0.3362\n",
            "Epoch 542/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8052 - accuracy: 0.3001 - val_loss: 1.6229 - val_accuracy: 0.3362\n",
            "Epoch 543/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7877 - accuracy: 0.3300 - val_loss: 1.6310 - val_accuracy: 0.3448\n",
            "Epoch 544/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8042 - accuracy: 0.3136 - val_loss: 1.6275 - val_accuracy: 0.3448\n",
            "Epoch 545/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8029 - accuracy: 0.3200 - val_loss: 1.6256 - val_accuracy: 0.3448\n",
            "Epoch 546/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8165 - accuracy: 0.3158 - val_loss: 1.6276 - val_accuracy: 0.3362\n",
            "Epoch 547/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8090 - accuracy: 0.3065 - val_loss: 1.6278 - val_accuracy: 0.3276\n",
            "Epoch 548/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8020 - accuracy: 0.3150 - val_loss: 1.6251 - val_accuracy: 0.3448\n",
            "Epoch 549/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7700 - accuracy: 0.3300 - val_loss: 1.6285 - val_accuracy: 0.3276\n",
            "Epoch 550/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8129 - accuracy: 0.3186 - val_loss: 1.6316 - val_accuracy: 0.3448\n",
            "Epoch 551/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7968 - accuracy: 0.3329 - val_loss: 1.6373 - val_accuracy: 0.3276\n",
            "Epoch 552/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8116 - accuracy: 0.3165 - val_loss: 1.6336 - val_accuracy: 0.3276\n",
            "Epoch 553/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8029 - accuracy: 0.3129 - val_loss: 1.6352 - val_accuracy: 0.3276\n",
            "Epoch 554/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7978 - accuracy: 0.3122 - val_loss: 1.6297 - val_accuracy: 0.3276\n",
            "Epoch 555/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8021 - accuracy: 0.3051 - val_loss: 1.6345 - val_accuracy: 0.3362\n",
            "Epoch 556/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7806 - accuracy: 0.3207 - val_loss: 1.6201 - val_accuracy: 0.3276\n",
            "Epoch 557/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7797 - accuracy: 0.3364 - val_loss: 1.6187 - val_accuracy: 0.3103\n",
            "Epoch 558/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7937 - accuracy: 0.3257 - val_loss: 1.6234 - val_accuracy: 0.3103\n",
            "Epoch 559/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8023 - accuracy: 0.3272 - val_loss: 1.6345 - val_accuracy: 0.3190\n",
            "Epoch 560/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7967 - accuracy: 0.3022 - val_loss: 1.6265 - val_accuracy: 0.3448\n",
            "Epoch 561/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7845 - accuracy: 0.3264 - val_loss: 1.6215 - val_accuracy: 0.3103\n",
            "Epoch 562/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8062 - accuracy: 0.3122 - val_loss: 1.6295 - val_accuracy: 0.3534\n",
            "Epoch 563/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7947 - accuracy: 0.3115 - val_loss: 1.6272 - val_accuracy: 0.3448\n",
            "Epoch 564/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8173 - accuracy: 0.2937 - val_loss: 1.6287 - val_accuracy: 0.3362\n",
            "Epoch 565/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7990 - accuracy: 0.3307 - val_loss: 1.6325 - val_accuracy: 0.3362\n",
            "Epoch 566/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8128 - accuracy: 0.2965 - val_loss: 1.6241 - val_accuracy: 0.3448\n",
            "Epoch 567/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7953 - accuracy: 0.3186 - val_loss: 1.6282 - val_accuracy: 0.3276\n",
            "Epoch 568/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8008 - accuracy: 0.3158 - val_loss: 1.6253 - val_accuracy: 0.3362\n",
            "Epoch 569/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7824 - accuracy: 0.3357 - val_loss: 1.6194 - val_accuracy: 0.3276\n",
            "Epoch 570/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7887 - accuracy: 0.3229 - val_loss: 1.6205 - val_accuracy: 0.3362\n",
            "Epoch 571/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7911 - accuracy: 0.3172 - val_loss: 1.6222 - val_accuracy: 0.3190\n",
            "Epoch 572/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8048 - accuracy: 0.3200 - val_loss: 1.6300 - val_accuracy: 0.3276\n",
            "Epoch 573/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7833 - accuracy: 0.3165 - val_loss: 1.6317 - val_accuracy: 0.3103\n",
            "Epoch 574/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7875 - accuracy: 0.3036 - val_loss: 1.6271 - val_accuracy: 0.3190\n",
            "Epoch 575/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7874 - accuracy: 0.3222 - val_loss: 1.6240 - val_accuracy: 0.3190\n",
            "Epoch 576/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7959 - accuracy: 0.3222 - val_loss: 1.6252 - val_accuracy: 0.3362\n",
            "Epoch 577/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7984 - accuracy: 0.3215 - val_loss: 1.6206 - val_accuracy: 0.3362\n",
            "Epoch 578/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8016 - accuracy: 0.3250 - val_loss: 1.6287 - val_accuracy: 0.3362\n",
            "Epoch 579/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8283 - accuracy: 0.3008 - val_loss: 1.6265 - val_accuracy: 0.3448\n",
            "Epoch 580/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8131 - accuracy: 0.3065 - val_loss: 1.6338 - val_accuracy: 0.3276\n",
            "Epoch 581/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7705 - accuracy: 0.3193 - val_loss: 1.6326 - val_accuracy: 0.3534\n",
            "Epoch 582/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7846 - accuracy: 0.3336 - val_loss: 1.6249 - val_accuracy: 0.3448\n",
            "Epoch 583/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7954 - accuracy: 0.3058 - val_loss: 1.6319 - val_accuracy: 0.3362\n",
            "Epoch 584/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7793 - accuracy: 0.3172 - val_loss: 1.6329 - val_accuracy: 0.3276\n",
            "Epoch 585/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7765 - accuracy: 0.3250 - val_loss: 1.6326 - val_accuracy: 0.3276\n",
            "Epoch 586/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8092 - accuracy: 0.3207 - val_loss: 1.6333 - val_accuracy: 0.3276\n",
            "Epoch 587/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7618 - accuracy: 0.3222 - val_loss: 1.6286 - val_accuracy: 0.3448\n",
            "Epoch 588/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7893 - accuracy: 0.3229 - val_loss: 1.6221 - val_accuracy: 0.3448\n",
            "Epoch 589/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7949 - accuracy: 0.3229 - val_loss: 1.6191 - val_accuracy: 0.3448\n",
            "Epoch 590/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7797 - accuracy: 0.3207 - val_loss: 1.6261 - val_accuracy: 0.3448\n",
            "Epoch 591/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.7689 - accuracy: 0.3065 - val_loss: 1.6194 - val_accuracy: 0.3362\n",
            "Epoch 592/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8042 - accuracy: 0.3186 - val_loss: 1.6218 - val_accuracy: 0.3621\n",
            "Epoch 593/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7753 - accuracy: 0.3122 - val_loss: 1.6260 - val_accuracy: 0.3534\n",
            "Epoch 594/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8014 - accuracy: 0.3136 - val_loss: 1.6361 - val_accuracy: 0.3103\n",
            "Epoch 595/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.8147 - accuracy: 0.3122 - val_loss: 1.6233 - val_accuracy: 0.3448\n",
            "Epoch 596/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7829 - accuracy: 0.3172 - val_loss: 1.6341 - val_accuracy: 0.3276\n",
            "Epoch 597/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7840 - accuracy: 0.3143 - val_loss: 1.6292 - val_accuracy: 0.3362\n",
            "Epoch 598/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7868 - accuracy: 0.3172 - val_loss: 1.6238 - val_accuracy: 0.3448\n",
            "Epoch 599/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7630 - accuracy: 0.3279 - val_loss: 1.6265 - val_accuracy: 0.3534\n",
            "Epoch 600/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7729 - accuracy: 0.3535 - val_loss: 1.6248 - val_accuracy: 0.3190\n",
            "Epoch 601/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7742 - accuracy: 0.3179 - val_loss: 1.6287 - val_accuracy: 0.3276\n",
            "Epoch 602/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7985 - accuracy: 0.3243 - val_loss: 1.6318 - val_accuracy: 0.2672\n",
            "Epoch 603/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7780 - accuracy: 0.3236 - val_loss: 1.6211 - val_accuracy: 0.3362\n",
            "Epoch 604/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7798 - accuracy: 0.3165 - val_loss: 1.6334 - val_accuracy: 0.3448\n",
            "Epoch 605/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7825 - accuracy: 0.3008 - val_loss: 1.6261 - val_accuracy: 0.3276\n",
            "Epoch 606/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7941 - accuracy: 0.3272 - val_loss: 1.6272 - val_accuracy: 0.3276\n",
            "Epoch 607/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7980 - accuracy: 0.3122 - val_loss: 1.6285 - val_accuracy: 0.3276\n",
            "Epoch 608/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8016 - accuracy: 0.3093 - val_loss: 1.6344 - val_accuracy: 0.3362\n",
            "Epoch 609/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7724 - accuracy: 0.3272 - val_loss: 1.6311 - val_accuracy: 0.3621\n",
            "Epoch 610/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7802 - accuracy: 0.3200 - val_loss: 1.6237 - val_accuracy: 0.3448\n",
            "Epoch 611/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7779 - accuracy: 0.3136 - val_loss: 1.6277 - val_accuracy: 0.3276\n",
            "Epoch 612/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7813 - accuracy: 0.3029 - val_loss: 1.6270 - val_accuracy: 0.3190\n",
            "Epoch 613/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.3207 - val_loss: 1.6369 - val_accuracy: 0.2586\n",
            "Epoch 614/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7505 - accuracy: 0.3279 - val_loss: 1.6232 - val_accuracy: 0.3190\n",
            "Epoch 615/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7897 - accuracy: 0.3329 - val_loss: 1.6330 - val_accuracy: 0.3190\n",
            "Epoch 616/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7902 - accuracy: 0.3029 - val_loss: 1.6273 - val_accuracy: 0.3362\n",
            "Epoch 617/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7755 - accuracy: 0.3329 - val_loss: 1.6254 - val_accuracy: 0.3276\n",
            "Epoch 618/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7695 - accuracy: 0.3250 - val_loss: 1.6310 - val_accuracy: 0.3362\n",
            "Epoch 619/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7604 - accuracy: 0.3264 - val_loss: 1.6415 - val_accuracy: 0.2586\n",
            "Epoch 620/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7817 - accuracy: 0.3200 - val_loss: 1.6323 - val_accuracy: 0.3103\n",
            "Epoch 621/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.8017 - accuracy: 0.3172 - val_loss: 1.6268 - val_accuracy: 0.3448\n",
            "Epoch 622/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7792 - accuracy: 0.3257 - val_loss: 1.6170 - val_accuracy: 0.3448\n",
            "Epoch 623/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7893 - accuracy: 0.3051 - val_loss: 1.6175 - val_accuracy: 0.3190\n",
            "Epoch 624/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7815 - accuracy: 0.3165 - val_loss: 1.6288 - val_accuracy: 0.3103\n",
            "Epoch 625/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7904 - accuracy: 0.3172 - val_loss: 1.6186 - val_accuracy: 0.3448\n",
            "Epoch 626/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7695 - accuracy: 0.3008 - val_loss: 1.6254 - val_accuracy: 0.3276\n",
            "Epoch 627/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7710 - accuracy: 0.3186 - val_loss: 1.6368 - val_accuracy: 0.2759\n",
            "Epoch 628/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7950 - accuracy: 0.3136 - val_loss: 1.6269 - val_accuracy: 0.3448\n",
            "Epoch 629/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7621 - accuracy: 0.3172 - val_loss: 1.6237 - val_accuracy: 0.3448\n",
            "Epoch 630/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7866 - accuracy: 0.3122 - val_loss: 1.6186 - val_accuracy: 0.3448\n",
            "Epoch 631/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7855 - accuracy: 0.3207 - val_loss: 1.6229 - val_accuracy: 0.3448\n",
            "Epoch 632/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7737 - accuracy: 0.3257 - val_loss: 1.6254 - val_accuracy: 0.3276\n",
            "Epoch 633/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7710 - accuracy: 0.3300 - val_loss: 1.6336 - val_accuracy: 0.3190\n",
            "Epoch 634/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7597 - accuracy: 0.3222 - val_loss: 1.6178 - val_accuracy: 0.3448\n",
            "Epoch 635/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7565 - accuracy: 0.3293 - val_loss: 1.6274 - val_accuracy: 0.3190\n",
            "Epoch 636/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7821 - accuracy: 0.3115 - val_loss: 1.6316 - val_accuracy: 0.3448\n",
            "Epoch 637/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7662 - accuracy: 0.3172 - val_loss: 1.6299 - val_accuracy: 0.3534\n",
            "Epoch 638/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7610 - accuracy: 0.3293 - val_loss: 1.6243 - val_accuracy: 0.3534\n",
            "Epoch 639/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7872 - accuracy: 0.3371 - val_loss: 1.6233 - val_accuracy: 0.3534\n",
            "Epoch 640/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7658 - accuracy: 0.3336 - val_loss: 1.6221 - val_accuracy: 0.3362\n",
            "Epoch 641/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7824 - accuracy: 0.3136 - val_loss: 1.6280 - val_accuracy: 0.2672\n",
            "Epoch 642/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7689 - accuracy: 0.3229 - val_loss: 1.6170 - val_accuracy: 0.3362\n",
            "Epoch 643/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7708 - accuracy: 0.3329 - val_loss: 1.6233 - val_accuracy: 0.3362\n",
            "Epoch 644/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7774 - accuracy: 0.3165 - val_loss: 1.6116 - val_accuracy: 0.3448\n",
            "Epoch 645/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7625 - accuracy: 0.3364 - val_loss: 1.6135 - val_accuracy: 0.3448\n",
            "Epoch 646/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7643 - accuracy: 0.3364 - val_loss: 1.6140 - val_accuracy: 0.3448\n",
            "Epoch 647/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7745 - accuracy: 0.3357 - val_loss: 1.6055 - val_accuracy: 0.3362\n",
            "Epoch 648/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7753 - accuracy: 0.3222 - val_loss: 1.6267 - val_accuracy: 0.3448\n",
            "Epoch 649/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7498 - accuracy: 0.3336 - val_loss: 1.6162 - val_accuracy: 0.3190\n",
            "Epoch 650/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7754 - accuracy: 0.3136 - val_loss: 1.6155 - val_accuracy: 0.3448\n",
            "Epoch 651/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7596 - accuracy: 0.3364 - val_loss: 1.6195 - val_accuracy: 0.3448\n",
            "Epoch 652/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7950 - accuracy: 0.3086 - val_loss: 1.6244 - val_accuracy: 0.3362\n",
            "Epoch 653/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7383 - accuracy: 0.3172 - val_loss: 1.6249 - val_accuracy: 0.2845\n",
            "Epoch 654/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7611 - accuracy: 0.3279 - val_loss: 1.6283 - val_accuracy: 0.2845\n",
            "Epoch 655/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7708 - accuracy: 0.3172 - val_loss: 1.6125 - val_accuracy: 0.3190\n",
            "Epoch 656/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7519 - accuracy: 0.3250 - val_loss: 1.6063 - val_accuracy: 0.3362\n",
            "Epoch 657/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7485 - accuracy: 0.3343 - val_loss: 1.6123 - val_accuracy: 0.3362\n",
            "Epoch 658/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7844 - accuracy: 0.3236 - val_loss: 1.6150 - val_accuracy: 0.3276\n",
            "Epoch 659/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7633 - accuracy: 0.3100 - val_loss: 1.6117 - val_accuracy: 0.3534\n",
            "Epoch 660/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7728 - accuracy: 0.3222 - val_loss: 1.6164 - val_accuracy: 0.3448\n",
            "Epoch 661/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7619 - accuracy: 0.3314 - val_loss: 1.6248 - val_accuracy: 0.2759\n",
            "Epoch 662/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7497 - accuracy: 0.3200 - val_loss: 1.6145 - val_accuracy: 0.3103\n",
            "Epoch 663/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7708 - accuracy: 0.3065 - val_loss: 1.6198 - val_accuracy: 0.3534\n",
            "Epoch 664/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7541 - accuracy: 0.3264 - val_loss: 1.6132 - val_accuracy: 0.3362\n",
            "Epoch 665/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7927 - accuracy: 0.3272 - val_loss: 1.6167 - val_accuracy: 0.3276\n",
            "Epoch 666/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7686 - accuracy: 0.3257 - val_loss: 1.6267 - val_accuracy: 0.3534\n",
            "Epoch 667/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7891 - accuracy: 0.3407 - val_loss: 1.6237 - val_accuracy: 0.3276\n",
            "Epoch 668/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7703 - accuracy: 0.3122 - val_loss: 1.6268 - val_accuracy: 0.3362\n",
            "Epoch 669/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7631 - accuracy: 0.3386 - val_loss: 1.6211 - val_accuracy: 0.3448\n",
            "Epoch 670/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7610 - accuracy: 0.3193 - val_loss: 1.6205 - val_accuracy: 0.3534\n",
            "Epoch 671/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7686 - accuracy: 0.3207 - val_loss: 1.6207 - val_accuracy: 0.3362\n",
            "Epoch 672/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7501 - accuracy: 0.3172 - val_loss: 1.6173 - val_accuracy: 0.3190\n",
            "Epoch 673/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7691 - accuracy: 0.3264 - val_loss: 1.6099 - val_accuracy: 0.3362\n",
            "Epoch 674/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7484 - accuracy: 0.3257 - val_loss: 1.6155 - val_accuracy: 0.3534\n",
            "Epoch 675/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7651 - accuracy: 0.3200 - val_loss: 1.6204 - val_accuracy: 0.3448\n",
            "Epoch 676/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7576 - accuracy: 0.3150 - val_loss: 1.6295 - val_accuracy: 0.3534\n",
            "Epoch 677/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7604 - accuracy: 0.3236 - val_loss: 1.6236 - val_accuracy: 0.3362\n",
            "Epoch 678/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7753 - accuracy: 0.3165 - val_loss: 1.6199 - val_accuracy: 0.3362\n",
            "Epoch 679/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7393 - accuracy: 0.3350 - val_loss: 1.6256 - val_accuracy: 0.3362\n",
            "Epoch 680/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7541 - accuracy: 0.3307 - val_loss: 1.6327 - val_accuracy: 0.3103\n",
            "Epoch 681/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7887 - accuracy: 0.3136 - val_loss: 1.6201 - val_accuracy: 0.3448\n",
            "Epoch 682/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7563 - accuracy: 0.3329 - val_loss: 1.6245 - val_accuracy: 0.3448\n",
            "Epoch 683/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7567 - accuracy: 0.3243 - val_loss: 1.6316 - val_accuracy: 0.3276\n",
            "Epoch 684/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7473 - accuracy: 0.3364 - val_loss: 1.6242 - val_accuracy: 0.3190\n",
            "Epoch 685/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7553 - accuracy: 0.3357 - val_loss: 1.6144 - val_accuracy: 0.3276\n",
            "Epoch 686/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7613 - accuracy: 0.3207 - val_loss: 1.6258 - val_accuracy: 0.3190\n",
            "Epoch 687/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7626 - accuracy: 0.3314 - val_loss: 1.6226 - val_accuracy: 0.3190\n",
            "Epoch 688/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7629 - accuracy: 0.3143 - val_loss: 1.6187 - val_accuracy: 0.3276\n",
            "Epoch 689/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7543 - accuracy: 0.3243 - val_loss: 1.6097 - val_accuracy: 0.3448\n",
            "Epoch 690/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7695 - accuracy: 0.3264 - val_loss: 1.6056 - val_accuracy: 0.3362\n",
            "Epoch 691/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7743 - accuracy: 0.3186 - val_loss: 1.6158 - val_accuracy: 0.2759\n",
            "Epoch 692/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7744 - accuracy: 0.3279 - val_loss: 1.6135 - val_accuracy: 0.3276\n",
            "Epoch 693/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7523 - accuracy: 0.3321 - val_loss: 1.6128 - val_accuracy: 0.3362\n",
            "Epoch 694/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7321 - accuracy: 0.3378 - val_loss: 1.6221 - val_accuracy: 0.3362\n",
            "Epoch 695/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7714 - accuracy: 0.3165 - val_loss: 1.6101 - val_accuracy: 0.3362\n",
            "Epoch 696/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7498 - accuracy: 0.3172 - val_loss: 1.6195 - val_accuracy: 0.3276\n",
            "Epoch 697/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7645 - accuracy: 0.3158 - val_loss: 1.6158 - val_accuracy: 0.3190\n",
            "Epoch 698/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7738 - accuracy: 0.3236 - val_loss: 1.6261 - val_accuracy: 0.3448\n",
            "Epoch 699/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7713 - accuracy: 0.3158 - val_loss: 1.6287 - val_accuracy: 0.3103\n",
            "Epoch 700/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7675 - accuracy: 0.3093 - val_loss: 1.6218 - val_accuracy: 0.3362\n",
            "Epoch 701/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7507 - accuracy: 0.3293 - val_loss: 1.6105 - val_accuracy: 0.3276\n",
            "Epoch 702/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7569 - accuracy: 0.3435 - val_loss: 1.6093 - val_accuracy: 0.3276\n",
            "Epoch 703/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7745 - accuracy: 0.3314 - val_loss: 1.6259 - val_accuracy: 0.3362\n",
            "Epoch 704/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7545 - accuracy: 0.3207 - val_loss: 1.6397 - val_accuracy: 0.3448\n",
            "Epoch 705/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7549 - accuracy: 0.3500 - val_loss: 1.6308 - val_accuracy: 0.3448\n",
            "Epoch 706/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7529 - accuracy: 0.3457 - val_loss: 1.6305 - val_accuracy: 0.3190\n",
            "Epoch 707/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7485 - accuracy: 0.3300 - val_loss: 1.6350 - val_accuracy: 0.3448\n",
            "Epoch 708/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7954 - accuracy: 0.3236 - val_loss: 1.6324 - val_accuracy: 0.3448\n",
            "Epoch 709/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7674 - accuracy: 0.3093 - val_loss: 1.6230 - val_accuracy: 0.3276\n",
            "Epoch 710/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7582 - accuracy: 0.3172 - val_loss: 1.6186 - val_accuracy: 0.3362\n",
            "Epoch 711/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7335 - accuracy: 0.3264 - val_loss: 1.6224 - val_accuracy: 0.3362\n",
            "Epoch 712/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7622 - accuracy: 0.3108 - val_loss: 1.6232 - val_accuracy: 0.3534\n",
            "Epoch 713/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7566 - accuracy: 0.3257 - val_loss: 1.6146 - val_accuracy: 0.3362\n",
            "Epoch 714/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7415 - accuracy: 0.3250 - val_loss: 1.6186 - val_accuracy: 0.3362\n",
            "Epoch 715/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7417 - accuracy: 0.3279 - val_loss: 1.6014 - val_accuracy: 0.3276\n",
            "Epoch 716/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7610 - accuracy: 0.3215 - val_loss: 1.6118 - val_accuracy: 0.3362\n",
            "Epoch 717/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7398 - accuracy: 0.3314 - val_loss: 1.6104 - val_accuracy: 0.3534\n",
            "Epoch 718/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7612 - accuracy: 0.3300 - val_loss: 1.6152 - val_accuracy: 0.3621\n",
            "Epoch 719/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7665 - accuracy: 0.3186 - val_loss: 1.6156 - val_accuracy: 0.3362\n",
            "Epoch 720/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7488 - accuracy: 0.3300 - val_loss: 1.6086 - val_accuracy: 0.3362\n",
            "Epoch 721/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7269 - accuracy: 0.3386 - val_loss: 1.6148 - val_accuracy: 0.3534\n",
            "Epoch 722/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7438 - accuracy: 0.3079 - val_loss: 1.6155 - val_accuracy: 0.3190\n",
            "Epoch 723/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7368 - accuracy: 0.3314 - val_loss: 1.6177 - val_accuracy: 0.3276\n",
            "Epoch 724/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7644 - accuracy: 0.3158 - val_loss: 1.6098 - val_accuracy: 0.3534\n",
            "Epoch 725/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7595 - accuracy: 0.3100 - val_loss: 1.6166 - val_accuracy: 0.3276\n",
            "Epoch 726/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7433 - accuracy: 0.3186 - val_loss: 1.6136 - val_accuracy: 0.3103\n",
            "Epoch 727/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7642 - accuracy: 0.3179 - val_loss: 1.6228 - val_accuracy: 0.3362\n",
            "Epoch 728/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7449 - accuracy: 0.3279 - val_loss: 1.6093 - val_accuracy: 0.3362\n",
            "Epoch 729/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7342 - accuracy: 0.3343 - val_loss: 1.6119 - val_accuracy: 0.3362\n",
            "Epoch 730/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7646 - accuracy: 0.3179 - val_loss: 1.6186 - val_accuracy: 0.3448\n",
            "Epoch 731/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7338 - accuracy: 0.3314 - val_loss: 1.6124 - val_accuracy: 0.3534\n",
            "Epoch 732/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7485 - accuracy: 0.3264 - val_loss: 1.6058 - val_accuracy: 0.3534\n",
            "Epoch 733/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7309 - accuracy: 0.3314 - val_loss: 1.6088 - val_accuracy: 0.3276\n",
            "Epoch 734/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7432 - accuracy: 0.3222 - val_loss: 1.6151 - val_accuracy: 0.3362\n",
            "Epoch 735/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7195 - accuracy: 0.3443 - val_loss: 1.6099 - val_accuracy: 0.3448\n",
            "Epoch 736/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7714 - accuracy: 0.3336 - val_loss: 1.6155 - val_accuracy: 0.3276\n",
            "Epoch 737/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7495 - accuracy: 0.3279 - val_loss: 1.6021 - val_accuracy: 0.3534\n",
            "Epoch 738/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7351 - accuracy: 0.3193 - val_loss: 1.6051 - val_accuracy: 0.3448\n",
            "Epoch 739/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7645 - accuracy: 0.3236 - val_loss: 1.6032 - val_accuracy: 0.3448\n",
            "Epoch 740/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7260 - accuracy: 0.3414 - val_loss: 1.6154 - val_accuracy: 0.3017\n",
            "Epoch 741/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7307 - accuracy: 0.3314 - val_loss: 1.5931 - val_accuracy: 0.3448\n",
            "Epoch 742/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7597 - accuracy: 0.3215 - val_loss: 1.5950 - val_accuracy: 0.3362\n",
            "Epoch 743/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.3243 - val_loss: 1.6166 - val_accuracy: 0.2759\n",
            "Epoch 744/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7446 - accuracy: 0.3215 - val_loss: 1.6167 - val_accuracy: 0.3190\n",
            "Epoch 745/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7539 - accuracy: 0.3329 - val_loss: 1.6110 - val_accuracy: 0.3362\n",
            "Epoch 746/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7493 - accuracy: 0.3300 - val_loss: 1.6007 - val_accuracy: 0.3190\n",
            "Epoch 747/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7538 - accuracy: 0.3186 - val_loss: 1.6043 - val_accuracy: 0.3103\n",
            "Epoch 748/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7290 - accuracy: 0.3343 - val_loss: 1.6012 - val_accuracy: 0.3190\n",
            "Epoch 749/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7305 - accuracy: 0.3364 - val_loss: 1.6072 - val_accuracy: 0.3362\n",
            "Epoch 750/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7577 - accuracy: 0.3457 - val_loss: 1.6195 - val_accuracy: 0.2931\n",
            "Epoch 751/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7497 - accuracy: 0.3079 - val_loss: 1.6153 - val_accuracy: 0.3534\n",
            "Epoch 752/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7424 - accuracy: 0.3229 - val_loss: 1.6202 - val_accuracy: 0.3448\n",
            "Epoch 753/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7480 - accuracy: 0.3443 - val_loss: 1.6035 - val_accuracy: 0.3190\n",
            "Epoch 754/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7719 - accuracy: 0.3264 - val_loss: 1.6229 - val_accuracy: 0.3190\n",
            "Epoch 755/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.7267 - accuracy: 0.3236 - val_loss: 1.6174 - val_accuracy: 0.3362\n",
            "Epoch 756/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7398 - accuracy: 0.3243 - val_loss: 1.6084 - val_accuracy: 0.3190\n",
            "Epoch 757/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7422 - accuracy: 0.3207 - val_loss: 1.6134 - val_accuracy: 0.3190\n",
            "Epoch 758/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7199 - accuracy: 0.3535 - val_loss: 1.6053 - val_accuracy: 0.3276\n",
            "Epoch 759/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7364 - accuracy: 0.3350 - val_loss: 1.6057 - val_accuracy: 0.3276\n",
            "Epoch 760/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7433 - accuracy: 0.3336 - val_loss: 1.6070 - val_accuracy: 0.3534\n",
            "Epoch 761/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7539 - accuracy: 0.3193 - val_loss: 1.6213 - val_accuracy: 0.3448\n",
            "Epoch 762/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7431 - accuracy: 0.3364 - val_loss: 1.6021 - val_accuracy: 0.3276\n",
            "Epoch 763/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7156 - accuracy: 0.3393 - val_loss: 1.6076 - val_accuracy: 0.3448\n",
            "Epoch 764/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7301 - accuracy: 0.3336 - val_loss: 1.6085 - val_accuracy: 0.3362\n",
            "Epoch 765/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7428 - accuracy: 0.3364 - val_loss: 1.6123 - val_accuracy: 0.3362\n",
            "Epoch 766/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7495 - accuracy: 0.3079 - val_loss: 1.6072 - val_accuracy: 0.3448\n",
            "Epoch 767/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7377 - accuracy: 0.3307 - val_loss: 1.5972 - val_accuracy: 0.3362\n",
            "Epoch 768/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7489 - accuracy: 0.3129 - val_loss: 1.6077 - val_accuracy: 0.3448\n",
            "Epoch 769/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7579 - accuracy: 0.3286 - val_loss: 1.6135 - val_accuracy: 0.3362\n",
            "Epoch 770/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7364 - accuracy: 0.3286 - val_loss: 1.6173 - val_accuracy: 0.3276\n",
            "Epoch 771/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7528 - accuracy: 0.3393 - val_loss: 1.6118 - val_accuracy: 0.3362\n",
            "Epoch 772/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7760 - accuracy: 0.3158 - val_loss: 1.6150 - val_accuracy: 0.2931\n",
            "Epoch 773/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7500 - accuracy: 0.3179 - val_loss: 1.6273 - val_accuracy: 0.2931\n",
            "Epoch 774/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7516 - accuracy: 0.3243 - val_loss: 1.6151 - val_accuracy: 0.3362\n",
            "Epoch 775/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7367 - accuracy: 0.3329 - val_loss: 1.6036 - val_accuracy: 0.3103\n",
            "Epoch 776/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7291 - accuracy: 0.3357 - val_loss: 1.6143 - val_accuracy: 0.3103\n",
            "Epoch 777/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7328 - accuracy: 0.3300 - val_loss: 1.6053 - val_accuracy: 0.3190\n",
            "Epoch 778/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7195 - accuracy: 0.3279 - val_loss: 1.6027 - val_accuracy: 0.3448\n",
            "Epoch 779/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7466 - accuracy: 0.3165 - val_loss: 1.5968 - val_accuracy: 0.3276\n",
            "Epoch 780/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7204 - accuracy: 0.3414 - val_loss: 1.6045 - val_accuracy: 0.3621\n",
            "Epoch 781/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7336 - accuracy: 0.3464 - val_loss: 1.5951 - val_accuracy: 0.3190\n",
            "Epoch 782/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7272 - accuracy: 0.3407 - val_loss: 1.6054 - val_accuracy: 0.3362\n",
            "Epoch 783/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7411 - accuracy: 0.3222 - val_loss: 1.6089 - val_accuracy: 0.3362\n",
            "Epoch 784/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7337 - accuracy: 0.3314 - val_loss: 1.6192 - val_accuracy: 0.3190\n",
            "Epoch 785/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7299 - accuracy: 0.3357 - val_loss: 1.6109 - val_accuracy: 0.2672\n",
            "Epoch 786/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7474 - accuracy: 0.3165 - val_loss: 1.6116 - val_accuracy: 0.2931\n",
            "Epoch 787/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7517 - accuracy: 0.3336 - val_loss: 1.6258 - val_accuracy: 0.3276\n",
            "Epoch 788/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7344 - accuracy: 0.3150 - val_loss: 1.6168 - val_accuracy: 0.3362\n",
            "Epoch 789/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7201 - accuracy: 0.3279 - val_loss: 1.6197 - val_accuracy: 0.3276\n",
            "Epoch 790/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7566 - accuracy: 0.3222 - val_loss: 1.6089 - val_accuracy: 0.3448\n",
            "Epoch 791/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7357 - accuracy: 0.3143 - val_loss: 1.6049 - val_accuracy: 0.3276\n",
            "Epoch 792/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7409 - accuracy: 0.3357 - val_loss: 1.6250 - val_accuracy: 0.3017\n",
            "Epoch 793/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.7352 - accuracy: 0.3200 - val_loss: 1.6121 - val_accuracy: 0.3103\n",
            "Epoch 794/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7263 - accuracy: 0.3264 - val_loss: 1.6212 - val_accuracy: 0.3017\n",
            "Epoch 795/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7443 - accuracy: 0.3343 - val_loss: 1.6217 - val_accuracy: 0.2845\n",
            "Epoch 796/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7131 - accuracy: 0.3272 - val_loss: 1.6246 - val_accuracy: 0.3017\n",
            "Epoch 797/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7384 - accuracy: 0.3172 - val_loss: 1.6075 - val_accuracy: 0.3017\n",
            "Epoch 798/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7276 - accuracy: 0.3378 - val_loss: 1.6215 - val_accuracy: 0.3276\n",
            "Epoch 799/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7265 - accuracy: 0.3350 - val_loss: 1.6159 - val_accuracy: 0.3362\n",
            "Epoch 800/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7530 - accuracy: 0.3378 - val_loss: 1.6122 - val_accuracy: 0.3534\n",
            "Epoch 801/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7358 - accuracy: 0.3293 - val_loss: 1.6144 - val_accuracy: 0.3276\n",
            "Epoch 802/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7384 - accuracy: 0.3321 - val_loss: 1.6105 - val_accuracy: 0.3448\n",
            "Epoch 803/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7061 - accuracy: 0.3257 - val_loss: 1.6167 - val_accuracy: 0.3448\n",
            "Epoch 804/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7295 - accuracy: 0.3243 - val_loss: 1.6159 - val_accuracy: 0.3448\n",
            "Epoch 805/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7278 - accuracy: 0.3350 - val_loss: 1.6285 - val_accuracy: 0.2759\n",
            "Epoch 806/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7300 - accuracy: 0.3293 - val_loss: 1.6279 - val_accuracy: 0.3276\n",
            "Epoch 807/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7459 - accuracy: 0.3165 - val_loss: 1.6225 - val_accuracy: 0.3362\n",
            "Epoch 808/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7338 - accuracy: 0.3243 - val_loss: 1.6241 - val_accuracy: 0.3190\n",
            "Epoch 809/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7306 - accuracy: 0.3307 - val_loss: 1.6194 - val_accuracy: 0.3190\n",
            "Epoch 810/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7108 - accuracy: 0.3414 - val_loss: 1.6247 - val_accuracy: 0.3103\n",
            "Epoch 811/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7096 - accuracy: 0.3400 - val_loss: 1.6144 - val_accuracy: 0.3103\n",
            "Epoch 812/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7461 - accuracy: 0.3414 - val_loss: 1.6312 - val_accuracy: 0.3362\n",
            "Epoch 813/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7265 - accuracy: 0.3350 - val_loss: 1.6257 - val_accuracy: 0.3190\n",
            "Epoch 814/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7252 - accuracy: 0.3450 - val_loss: 1.6362 - val_accuracy: 0.3276\n",
            "Epoch 815/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7247 - accuracy: 0.3443 - val_loss: 1.6210 - val_accuracy: 0.3362\n",
            "Epoch 816/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7290 - accuracy: 0.3286 - val_loss: 1.6152 - val_accuracy: 0.3190\n",
            "Epoch 817/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7080 - accuracy: 0.3364 - val_loss: 1.6328 - val_accuracy: 0.3190\n",
            "Epoch 818/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7271 - accuracy: 0.3393 - val_loss: 1.6241 - val_accuracy: 0.3276\n",
            "Epoch 819/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7348 - accuracy: 0.3350 - val_loss: 1.6214 - val_accuracy: 0.3362\n",
            "Epoch 820/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7252 - accuracy: 0.3435 - val_loss: 1.6330 - val_accuracy: 0.3276\n",
            "Epoch 821/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7237 - accuracy: 0.3393 - val_loss: 1.6167 - val_accuracy: 0.3362\n",
            "Epoch 822/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7136 - accuracy: 0.3257 - val_loss: 1.6123 - val_accuracy: 0.3103\n",
            "Epoch 823/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7339 - accuracy: 0.3521 - val_loss: 1.6102 - val_accuracy: 0.3190\n",
            "Epoch 824/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7346 - accuracy: 0.3257 - val_loss: 1.6121 - val_accuracy: 0.3276\n",
            "Epoch 825/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7239 - accuracy: 0.3165 - val_loss: 1.6139 - val_accuracy: 0.3362\n",
            "Epoch 826/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7263 - accuracy: 0.3264 - val_loss: 1.6127 - val_accuracy: 0.3190\n",
            "Epoch 827/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7266 - accuracy: 0.3279 - val_loss: 1.6078 - val_accuracy: 0.3276\n",
            "Epoch 828/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7055 - accuracy: 0.3371 - val_loss: 1.6158 - val_accuracy: 0.2931\n",
            "Epoch 829/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6940 - accuracy: 0.3407 - val_loss: 1.6127 - val_accuracy: 0.3190\n",
            "Epoch 830/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7031 - accuracy: 0.3428 - val_loss: 1.6130 - val_accuracy: 0.3276\n",
            "Epoch 831/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7007 - accuracy: 0.3272 - val_loss: 1.6290 - val_accuracy: 0.3276\n",
            "Epoch 832/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6993 - accuracy: 0.3421 - val_loss: 1.6271 - val_accuracy: 0.3448\n",
            "Epoch 833/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7355 - accuracy: 0.3371 - val_loss: 1.6360 - val_accuracy: 0.3362\n",
            "Epoch 834/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7312 - accuracy: 0.3535 - val_loss: 1.6264 - val_accuracy: 0.3190\n",
            "Epoch 835/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7313 - accuracy: 0.3300 - val_loss: 1.6188 - val_accuracy: 0.3017\n",
            "Epoch 836/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7080 - accuracy: 0.3300 - val_loss: 1.6132 - val_accuracy: 0.3362\n",
            "Epoch 837/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7320 - accuracy: 0.3193 - val_loss: 1.6231 - val_accuracy: 0.3362\n",
            "Epoch 838/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6967 - accuracy: 0.3364 - val_loss: 1.5983 - val_accuracy: 0.3362\n",
            "Epoch 839/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7249 - accuracy: 0.3329 - val_loss: 1.6082 - val_accuracy: 0.3190\n",
            "Epoch 840/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7392 - accuracy: 0.3222 - val_loss: 1.6035 - val_accuracy: 0.3362\n",
            "Epoch 841/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7367 - accuracy: 0.3293 - val_loss: 1.6125 - val_accuracy: 0.3017\n",
            "Epoch 842/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7244 - accuracy: 0.3542 - val_loss: 1.6168 - val_accuracy: 0.3534\n",
            "Epoch 843/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7226 - accuracy: 0.3279 - val_loss: 1.6157 - val_accuracy: 0.3276\n",
            "Epoch 844/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7427 - accuracy: 0.3250 - val_loss: 1.6080 - val_accuracy: 0.3190\n",
            "Epoch 845/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7110 - accuracy: 0.3457 - val_loss: 1.6159 - val_accuracy: 0.2759\n",
            "Epoch 846/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7216 - accuracy: 0.3350 - val_loss: 1.6121 - val_accuracy: 0.2845\n",
            "Epoch 847/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7260 - accuracy: 0.3150 - val_loss: 1.6093 - val_accuracy: 0.3448\n",
            "Epoch 848/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7089 - accuracy: 0.3364 - val_loss: 1.6090 - val_accuracy: 0.3103\n",
            "Epoch 849/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7314 - accuracy: 0.3421 - val_loss: 1.6280 - val_accuracy: 0.3103\n",
            "Epoch 850/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7378 - accuracy: 0.3300 - val_loss: 1.6137 - val_accuracy: 0.3103\n",
            "Epoch 851/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7177 - accuracy: 0.3350 - val_loss: 1.6173 - val_accuracy: 0.3276\n",
            "Epoch 852/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7096 - accuracy: 0.3307 - val_loss: 1.6121 - val_accuracy: 0.3448\n",
            "Epoch 853/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7175 - accuracy: 0.3293 - val_loss: 1.6173 - val_accuracy: 0.3362\n",
            "Epoch 854/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6920 - accuracy: 0.3443 - val_loss: 1.6221 - val_accuracy: 0.3190\n",
            "Epoch 855/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7073 - accuracy: 0.3571 - val_loss: 1.6118 - val_accuracy: 0.3448\n",
            "Epoch 856/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7057 - accuracy: 0.3393 - val_loss: 1.6117 - val_accuracy: 0.3448\n",
            "Epoch 857/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7421 - accuracy: 0.3243 - val_loss: 1.6121 - val_accuracy: 0.3362\n",
            "Epoch 858/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7302 - accuracy: 0.3186 - val_loss: 1.6145 - val_accuracy: 0.3103\n",
            "Epoch 859/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7191 - accuracy: 0.3542 - val_loss: 1.6241 - val_accuracy: 0.3276\n",
            "Epoch 860/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7228 - accuracy: 0.3357 - val_loss: 1.6274 - val_accuracy: 0.3103\n",
            "Epoch 861/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7116 - accuracy: 0.3357 - val_loss: 1.6197 - val_accuracy: 0.3017\n",
            "Epoch 862/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7171 - accuracy: 0.3400 - val_loss: 1.6314 - val_accuracy: 0.3362\n",
            "Epoch 863/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7078 - accuracy: 0.3286 - val_loss: 1.6189 - val_accuracy: 0.3276\n",
            "Epoch 864/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7171 - accuracy: 0.3357 - val_loss: 1.6296 - val_accuracy: 0.3103\n",
            "Epoch 865/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7249 - accuracy: 0.3364 - val_loss: 1.6327 - val_accuracy: 0.3103\n",
            "Epoch 866/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7238 - accuracy: 0.3307 - val_loss: 1.6386 - val_accuracy: 0.3103\n",
            "Epoch 867/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7165 - accuracy: 0.3236 - val_loss: 1.6137 - val_accuracy: 0.3276\n",
            "Epoch 868/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7114 - accuracy: 0.3414 - val_loss: 1.6167 - val_accuracy: 0.3103\n",
            "Epoch 869/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6958 - accuracy: 0.3542 - val_loss: 1.6335 - val_accuracy: 0.3362\n",
            "Epoch 870/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6941 - accuracy: 0.3471 - val_loss: 1.6236 - val_accuracy: 0.3276\n",
            "Epoch 871/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7311 - accuracy: 0.3371 - val_loss: 1.6263 - val_accuracy: 0.3448\n",
            "Epoch 872/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7125 - accuracy: 0.3300 - val_loss: 1.6210 - val_accuracy: 0.3190\n",
            "Epoch 873/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7208 - accuracy: 0.3407 - val_loss: 1.6236 - val_accuracy: 0.3276\n",
            "Epoch 874/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7252 - accuracy: 0.3407 - val_loss: 1.6347 - val_accuracy: 0.3190\n",
            "Epoch 875/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7137 - accuracy: 0.3343 - val_loss: 1.6229 - val_accuracy: 0.3190\n",
            "Epoch 876/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6993 - accuracy: 0.3493 - val_loss: 1.6298 - val_accuracy: 0.2845\n",
            "Epoch 877/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7028 - accuracy: 0.3435 - val_loss: 1.6253 - val_accuracy: 0.2931\n",
            "Epoch 878/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7100 - accuracy: 0.3521 - val_loss: 1.6247 - val_accuracy: 0.3362\n",
            "Epoch 879/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7210 - accuracy: 0.3200 - val_loss: 1.6181 - val_accuracy: 0.3190\n",
            "Epoch 880/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7201 - accuracy: 0.3257 - val_loss: 1.6258 - val_accuracy: 0.3103\n",
            "Epoch 881/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7167 - accuracy: 0.3350 - val_loss: 1.6270 - val_accuracy: 0.3276\n",
            "Epoch 882/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7161 - accuracy: 0.3464 - val_loss: 1.6194 - val_accuracy: 0.3362\n",
            "Epoch 883/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6999 - accuracy: 0.3443 - val_loss: 1.6246 - val_accuracy: 0.3103\n",
            "Epoch 884/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7052 - accuracy: 0.3371 - val_loss: 1.6331 - val_accuracy: 0.3190\n",
            "Epoch 885/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7012 - accuracy: 0.3443 - val_loss: 1.6268 - val_accuracy: 0.3534\n",
            "Epoch 886/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6885 - accuracy: 0.3307 - val_loss: 1.6263 - val_accuracy: 0.3448\n",
            "Epoch 887/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6930 - accuracy: 0.3400 - val_loss: 1.6218 - val_accuracy: 0.3534\n",
            "Epoch 888/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7266 - accuracy: 0.3393 - val_loss: 1.6160 - val_accuracy: 0.3103\n",
            "Epoch 889/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7125 - accuracy: 0.3400 - val_loss: 1.6076 - val_accuracy: 0.3103\n",
            "Epoch 890/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7246 - accuracy: 0.3535 - val_loss: 1.6265 - val_accuracy: 0.3103\n",
            "Epoch 891/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7184 - accuracy: 0.3435 - val_loss: 1.6235 - val_accuracy: 0.3103\n",
            "Epoch 892/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6773 - accuracy: 0.3557 - val_loss: 1.6164 - val_accuracy: 0.3190\n",
            "Epoch 893/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7218 - accuracy: 0.3457 - val_loss: 1.6242 - val_accuracy: 0.2672\n",
            "Epoch 894/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7026 - accuracy: 0.3386 - val_loss: 1.6168 - val_accuracy: 0.3103\n",
            "Epoch 895/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6949 - accuracy: 0.3407 - val_loss: 1.6201 - val_accuracy: 0.3276\n",
            "Epoch 896/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7164 - accuracy: 0.3215 - val_loss: 1.6371 - val_accuracy: 0.3017\n",
            "Epoch 897/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7109 - accuracy: 0.3350 - val_loss: 1.6226 - val_accuracy: 0.3362\n",
            "Epoch 898/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6845 - accuracy: 0.3435 - val_loss: 1.6328 - val_accuracy: 0.3103\n",
            "Epoch 899/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6992 - accuracy: 0.3321 - val_loss: 1.6325 - val_accuracy: 0.3103\n",
            "Epoch 900/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6818 - accuracy: 0.3607 - val_loss: 1.6183 - val_accuracy: 0.3017\n",
            "Epoch 901/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6927 - accuracy: 0.3500 - val_loss: 1.6184 - val_accuracy: 0.3103\n",
            "Epoch 902/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7055 - accuracy: 0.3286 - val_loss: 1.6124 - val_accuracy: 0.3017\n",
            "Epoch 903/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7237 - accuracy: 0.3478 - val_loss: 1.6244 - val_accuracy: 0.3190\n",
            "Epoch 904/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6550 - accuracy: 0.3535 - val_loss: 1.6176 - val_accuracy: 0.3276\n",
            "Epoch 905/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7047 - accuracy: 0.3286 - val_loss: 1.6258 - val_accuracy: 0.3276\n",
            "Epoch 906/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6935 - accuracy: 0.3507 - val_loss: 1.6178 - val_accuracy: 0.3190\n",
            "Epoch 907/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6952 - accuracy: 0.3421 - val_loss: 1.6289 - val_accuracy: 0.3534\n",
            "Epoch 908/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7069 - accuracy: 0.3336 - val_loss: 1.6209 - val_accuracy: 0.3017\n",
            "Epoch 909/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7195 - accuracy: 0.3257 - val_loss: 1.6259 - val_accuracy: 0.3534\n",
            "Epoch 910/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6963 - accuracy: 0.3457 - val_loss: 1.6226 - val_accuracy: 0.3103\n",
            "Epoch 911/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7033 - accuracy: 0.3514 - val_loss: 1.6133 - val_accuracy: 0.3103\n",
            "Epoch 912/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7256 - accuracy: 0.3407 - val_loss: 1.6211 - val_accuracy: 0.3362\n",
            "Epoch 913/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6896 - accuracy: 0.3528 - val_loss: 1.6171 - val_accuracy: 0.3448\n",
            "Epoch 914/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6960 - accuracy: 0.3371 - val_loss: 1.5993 - val_accuracy: 0.3017\n",
            "Epoch 915/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6707 - accuracy: 0.3307 - val_loss: 1.6041 - val_accuracy: 0.3276\n",
            "Epoch 916/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7061 - accuracy: 0.3329 - val_loss: 1.6070 - val_accuracy: 0.3103\n",
            "Epoch 917/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7079 - accuracy: 0.3535 - val_loss: 1.6167 - val_accuracy: 0.2586\n",
            "Epoch 918/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7194 - accuracy: 0.3364 - val_loss: 1.5970 - val_accuracy: 0.3017\n",
            "Epoch 919/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6693 - accuracy: 0.3535 - val_loss: 1.6006 - val_accuracy: 0.3103\n",
            "Epoch 920/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6814 - accuracy: 0.3428 - val_loss: 1.6067 - val_accuracy: 0.3190\n",
            "Epoch 921/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7017 - accuracy: 0.3435 - val_loss: 1.6120 - val_accuracy: 0.2931\n",
            "Epoch 922/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7079 - accuracy: 0.3236 - val_loss: 1.6225 - val_accuracy: 0.2672\n",
            "Epoch 923/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7122 - accuracy: 0.3478 - val_loss: 1.6006 - val_accuracy: 0.2931\n",
            "Epoch 924/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7010 - accuracy: 0.3450 - val_loss: 1.6193 - val_accuracy: 0.2845\n",
            "Epoch 925/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7361 - accuracy: 0.3350 - val_loss: 1.6140 - val_accuracy: 0.3276\n",
            "Epoch 926/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6969 - accuracy: 0.3300 - val_loss: 1.6020 - val_accuracy: 0.3103\n",
            "Epoch 927/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6793 - accuracy: 0.3450 - val_loss: 1.6214 - val_accuracy: 0.3362\n",
            "Epoch 928/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6974 - accuracy: 0.3550 - val_loss: 1.6163 - val_accuracy: 0.3362\n",
            "Epoch 929/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6848 - accuracy: 0.3414 - val_loss: 1.6273 - val_accuracy: 0.2931\n",
            "Epoch 930/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7004 - accuracy: 0.3421 - val_loss: 1.6194 - val_accuracy: 0.2759\n",
            "Epoch 931/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7254 - accuracy: 0.3307 - val_loss: 1.6152 - val_accuracy: 0.3448\n",
            "Epoch 932/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6989 - accuracy: 0.3407 - val_loss: 1.6222 - val_accuracy: 0.3534\n",
            "Epoch 933/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6999 - accuracy: 0.3257 - val_loss: 1.6292 - val_accuracy: 0.3448\n",
            "Epoch 934/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6812 - accuracy: 0.3371 - val_loss: 1.6109 - val_accuracy: 0.2845\n",
            "Epoch 935/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6938 - accuracy: 0.3457 - val_loss: 1.6183 - val_accuracy: 0.3362\n",
            "Epoch 936/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7063 - accuracy: 0.3243 - val_loss: 1.6162 - val_accuracy: 0.3276\n",
            "Epoch 937/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6852 - accuracy: 0.3585 - val_loss: 1.6121 - val_accuracy: 0.3276\n",
            "Epoch 938/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6945 - accuracy: 0.3457 - val_loss: 1.6049 - val_accuracy: 0.3017\n",
            "Epoch 939/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6981 - accuracy: 0.3393 - val_loss: 1.6146 - val_accuracy: 0.3190\n",
            "Epoch 940/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6943 - accuracy: 0.3250 - val_loss: 1.6229 - val_accuracy: 0.3362\n",
            "Epoch 941/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6742 - accuracy: 0.3450 - val_loss: 1.5978 - val_accuracy: 0.3103\n",
            "Epoch 942/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7115 - accuracy: 0.3300 - val_loss: 1.6036 - val_accuracy: 0.3190\n",
            "Epoch 943/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7145 - accuracy: 0.3329 - val_loss: 1.6207 - val_accuracy: 0.3276\n",
            "Epoch 944/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6716 - accuracy: 0.3535 - val_loss: 1.6152 - val_accuracy: 0.3017\n",
            "Epoch 945/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7076 - accuracy: 0.3386 - val_loss: 1.6182 - val_accuracy: 0.3276\n",
            "Epoch 946/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6973 - accuracy: 0.3300 - val_loss: 1.6096 - val_accuracy: 0.3190\n",
            "Epoch 947/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6856 - accuracy: 0.3293 - val_loss: 1.6139 - val_accuracy: 0.2931\n",
            "Epoch 948/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6924 - accuracy: 0.3421 - val_loss: 1.5976 - val_accuracy: 0.2845\n",
            "Epoch 949/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6821 - accuracy: 0.3571 - val_loss: 1.5997 - val_accuracy: 0.3362\n",
            "Epoch 950/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6914 - accuracy: 0.3336 - val_loss: 1.6182 - val_accuracy: 0.2845\n",
            "Epoch 951/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7010 - accuracy: 0.3457 - val_loss: 1.6073 - val_accuracy: 0.3190\n",
            "Epoch 952/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6928 - accuracy: 0.3471 - val_loss: 1.6258 - val_accuracy: 0.2759\n",
            "Epoch 953/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7048 - accuracy: 0.3507 - val_loss: 1.6250 - val_accuracy: 0.3103\n",
            "Epoch 954/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6894 - accuracy: 0.3272 - val_loss: 1.6184 - val_accuracy: 0.3103\n",
            "Epoch 955/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7073 - accuracy: 0.3435 - val_loss: 1.6054 - val_accuracy: 0.3276\n",
            "Epoch 956/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6816 - accuracy: 0.3364 - val_loss: 1.6394 - val_accuracy: 0.2672\n",
            "Epoch 957/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6601 - accuracy: 0.3507 - val_loss: 1.6107 - val_accuracy: 0.3190\n",
            "Epoch 958/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6920 - accuracy: 0.3542 - val_loss: 1.6168 - val_accuracy: 0.3534\n",
            "Epoch 959/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7039 - accuracy: 0.3485 - val_loss: 1.6092 - val_accuracy: 0.3276\n",
            "Epoch 960/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7303 - accuracy: 0.3172 - val_loss: 1.6172 - val_accuracy: 0.3103\n",
            "Epoch 961/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7044 - accuracy: 0.3286 - val_loss: 1.6132 - val_accuracy: 0.3276\n",
            "Epoch 962/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6966 - accuracy: 0.3493 - val_loss: 1.6183 - val_accuracy: 0.3017\n",
            "Epoch 963/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6822 - accuracy: 0.3421 - val_loss: 1.6245 - val_accuracy: 0.3190\n",
            "Epoch 964/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7124 - accuracy: 0.3471 - val_loss: 1.6134 - val_accuracy: 0.3103\n",
            "Epoch 965/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6870 - accuracy: 0.3371 - val_loss: 1.6113 - val_accuracy: 0.3190\n",
            "Epoch 966/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6820 - accuracy: 0.3314 - val_loss: 1.6148 - val_accuracy: 0.2931\n",
            "Epoch 967/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6943 - accuracy: 0.3421 - val_loss: 1.6199 - val_accuracy: 0.3017\n",
            "Epoch 968/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6806 - accuracy: 0.3485 - val_loss: 1.6119 - val_accuracy: 0.3103\n",
            "Epoch 969/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6926 - accuracy: 0.3557 - val_loss: 1.6251 - val_accuracy: 0.3362\n",
            "Epoch 970/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6979 - accuracy: 0.3421 - val_loss: 1.6275 - val_accuracy: 0.3276\n",
            "Epoch 971/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6649 - accuracy: 0.3471 - val_loss: 1.6296 - val_accuracy: 0.3103\n",
            "Epoch 972/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6763 - accuracy: 0.3321 - val_loss: 1.6267 - val_accuracy: 0.3190\n",
            "Epoch 973/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7107 - accuracy: 0.3421 - val_loss: 1.6210 - val_accuracy: 0.3190\n",
            "Epoch 974/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6859 - accuracy: 0.3485 - val_loss: 1.6348 - val_accuracy: 0.3276\n",
            "Epoch 975/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6883 - accuracy: 0.3343 - val_loss: 1.6149 - val_accuracy: 0.3017\n",
            "Epoch 976/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7073 - accuracy: 0.3371 - val_loss: 1.6171 - val_accuracy: 0.3276\n",
            "Epoch 977/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6758 - accuracy: 0.3428 - val_loss: 1.6376 - val_accuracy: 0.2672\n",
            "Epoch 978/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6730 - accuracy: 0.3507 - val_loss: 1.6310 - val_accuracy: 0.3190\n",
            "Epoch 979/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6829 - accuracy: 0.3471 - val_loss: 1.6389 - val_accuracy: 0.2759\n",
            "Epoch 980/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7134 - accuracy: 0.3264 - val_loss: 1.6317 - val_accuracy: 0.3190\n",
            "Epoch 981/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6873 - accuracy: 0.3464 - val_loss: 1.6114 - val_accuracy: 0.2759\n",
            "Epoch 982/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6782 - accuracy: 0.3578 - val_loss: 1.6288 - val_accuracy: 0.2931\n",
            "Epoch 983/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6707 - accuracy: 0.3471 - val_loss: 1.6224 - val_accuracy: 0.2845\n",
            "Epoch 984/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7020 - accuracy: 0.3493 - val_loss: 1.6211 - val_accuracy: 0.3190\n",
            "Epoch 985/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6669 - accuracy: 0.3671 - val_loss: 1.6215 - val_accuracy: 0.3103\n",
            "Epoch 986/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7000 - accuracy: 0.3236 - val_loss: 1.6290 - val_accuracy: 0.3276\n",
            "Epoch 987/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7069 - accuracy: 0.3443 - val_loss: 1.6348 - val_accuracy: 0.3017\n",
            "Epoch 988/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6956 - accuracy: 0.3493 - val_loss: 1.6311 - val_accuracy: 0.2931\n",
            "Epoch 989/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6816 - accuracy: 0.3350 - val_loss: 1.6244 - val_accuracy: 0.3017\n",
            "Epoch 990/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6914 - accuracy: 0.3443 - val_loss: 1.6273 - val_accuracy: 0.3276\n",
            "Epoch 991/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7026 - accuracy: 0.3371 - val_loss: 1.6255 - val_accuracy: 0.3017\n",
            "Epoch 992/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6836 - accuracy: 0.3407 - val_loss: 1.6179 - val_accuracy: 0.2931\n",
            "Epoch 993/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6804 - accuracy: 0.3443 - val_loss: 1.6211 - val_accuracy: 0.3017\n",
            "Epoch 994/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6901 - accuracy: 0.3500 - val_loss: 1.6287 - val_accuracy: 0.3276\n",
            "Epoch 995/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6832 - accuracy: 0.3671 - val_loss: 1.6366 - val_accuracy: 0.2672\n",
            "Epoch 996/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6835 - accuracy: 0.3421 - val_loss: 1.6227 - val_accuracy: 0.3017\n",
            "Epoch 997/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6906 - accuracy: 0.3222 - val_loss: 1.6239 - val_accuracy: 0.2845\n",
            "Epoch 998/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6752 - accuracy: 0.3457 - val_loss: 1.6274 - val_accuracy: 0.3103\n",
            "Epoch 999/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6882 - accuracy: 0.3457 - val_loss: 1.6152 - val_accuracy: 0.3017\n",
            "Epoch 1000/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6824 - accuracy: 0.3514 - val_loss: 1.6195 - val_accuracy: 0.3017\n",
            "Epoch 1001/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6805 - accuracy: 0.3314 - val_loss: 1.6047 - val_accuracy: 0.3017\n",
            "Epoch 1002/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6870 - accuracy: 0.3685 - val_loss: 1.6104 - val_accuracy: 0.3017\n",
            "Epoch 1003/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6667 - accuracy: 0.3699 - val_loss: 1.6306 - val_accuracy: 0.2500\n",
            "Epoch 1004/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6776 - accuracy: 0.3393 - val_loss: 1.6226 - val_accuracy: 0.3190\n",
            "Epoch 1005/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6867 - accuracy: 0.3450 - val_loss: 1.6033 - val_accuracy: 0.3190\n",
            "Epoch 1006/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.7009 - accuracy: 0.3343 - val_loss: 1.6279 - val_accuracy: 0.2759\n",
            "Epoch 1007/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6764 - accuracy: 0.3457 - val_loss: 1.6285 - val_accuracy: 0.3190\n",
            "Epoch 1008/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6780 - accuracy: 0.3378 - val_loss: 1.6337 - val_accuracy: 0.3190\n",
            "Epoch 1009/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6765 - accuracy: 0.3421 - val_loss: 1.6164 - val_accuracy: 0.3017\n",
            "Epoch 1010/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6842 - accuracy: 0.3343 - val_loss: 1.6199 - val_accuracy: 0.3103\n",
            "Epoch 1011/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6754 - accuracy: 0.3571 - val_loss: 1.6139 - val_accuracy: 0.3103\n",
            "Epoch 1012/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6866 - accuracy: 0.3592 - val_loss: 1.6121 - val_accuracy: 0.3276\n",
            "Epoch 1013/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6748 - accuracy: 0.3671 - val_loss: 1.6303 - val_accuracy: 0.3276\n",
            "Epoch 1014/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6928 - accuracy: 0.3435 - val_loss: 1.6361 - val_accuracy: 0.3017\n",
            "Epoch 1015/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6845 - accuracy: 0.3378 - val_loss: 1.6372 - val_accuracy: 0.3103\n",
            "Epoch 1016/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6830 - accuracy: 0.3421 - val_loss: 1.6294 - val_accuracy: 0.2586\n",
            "Epoch 1017/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6947 - accuracy: 0.3400 - val_loss: 1.6055 - val_accuracy: 0.2931\n",
            "Epoch 1018/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6767 - accuracy: 0.3493 - val_loss: 1.6156 - val_accuracy: 0.3276\n",
            "Epoch 1019/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6694 - accuracy: 0.3507 - val_loss: 1.6393 - val_accuracy: 0.3017\n",
            "Epoch 1020/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7008 - accuracy: 0.3464 - val_loss: 1.6303 - val_accuracy: 0.3190\n",
            "Epoch 1021/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6650 - accuracy: 0.3542 - val_loss: 1.6361 - val_accuracy: 0.3103\n",
            "Epoch 1022/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6690 - accuracy: 0.3400 - val_loss: 1.6217 - val_accuracy: 0.3017\n",
            "Epoch 1023/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6698 - accuracy: 0.3414 - val_loss: 1.6246 - val_accuracy: 0.3362\n",
            "Epoch 1024/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6922 - accuracy: 0.3457 - val_loss: 1.6340 - val_accuracy: 0.2931\n",
            "Epoch 1025/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6716 - accuracy: 0.3457 - val_loss: 1.6190 - val_accuracy: 0.2931\n",
            "Epoch 1026/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6798 - accuracy: 0.3414 - val_loss: 1.6369 - val_accuracy: 0.2759\n",
            "Epoch 1027/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6737 - accuracy: 0.3542 - val_loss: 1.6366 - val_accuracy: 0.3362\n",
            "Epoch 1028/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6860 - accuracy: 0.3421 - val_loss: 1.6404 - val_accuracy: 0.2931\n",
            "Epoch 1029/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6581 - accuracy: 0.3421 - val_loss: 1.6336 - val_accuracy: 0.3362\n",
            "Epoch 1030/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6779 - accuracy: 0.3329 - val_loss: 1.6298 - val_accuracy: 0.3190\n",
            "Epoch 1031/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6705 - accuracy: 0.3450 - val_loss: 1.6271 - val_accuracy: 0.3362\n",
            "Epoch 1032/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6677 - accuracy: 0.3493 - val_loss: 1.6400 - val_accuracy: 0.3017\n",
            "Epoch 1033/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6746 - accuracy: 0.3528 - val_loss: 1.6278 - val_accuracy: 0.2845\n",
            "Epoch 1034/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6700 - accuracy: 0.3500 - val_loss: 1.6238 - val_accuracy: 0.2931\n",
            "Epoch 1035/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6711 - accuracy: 0.3471 - val_loss: 1.6325 - val_accuracy: 0.3017\n",
            "Epoch 1036/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6908 - accuracy: 0.3571 - val_loss: 1.6245 - val_accuracy: 0.3190\n",
            "Epoch 1037/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6758 - accuracy: 0.3457 - val_loss: 1.6363 - val_accuracy: 0.2931\n",
            "Epoch 1038/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6971 - accuracy: 0.3393 - val_loss: 1.6314 - val_accuracy: 0.3103\n",
            "Epoch 1039/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6779 - accuracy: 0.3507 - val_loss: 1.6347 - val_accuracy: 0.3103\n",
            "Epoch 1040/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6704 - accuracy: 0.3528 - val_loss: 1.6325 - val_accuracy: 0.3103\n",
            "Epoch 1041/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6788 - accuracy: 0.3635 - val_loss: 1.6157 - val_accuracy: 0.2931\n",
            "Epoch 1042/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6872 - accuracy: 0.3364 - val_loss: 1.6214 - val_accuracy: 0.2845\n",
            "Epoch 1043/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6928 - accuracy: 0.3457 - val_loss: 1.6096 - val_accuracy: 0.3017\n",
            "Epoch 1044/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6605 - accuracy: 0.3478 - val_loss: 1.6280 - val_accuracy: 0.3190\n",
            "Epoch 1045/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6795 - accuracy: 0.3435 - val_loss: 1.6155 - val_accuracy: 0.3017\n",
            "Epoch 1046/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6789 - accuracy: 0.3550 - val_loss: 1.6170 - val_accuracy: 0.3448\n",
            "Epoch 1047/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6742 - accuracy: 0.3400 - val_loss: 1.6142 - val_accuracy: 0.3103\n",
            "Epoch 1048/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6892 - accuracy: 0.3407 - val_loss: 1.6092 - val_accuracy: 0.2931\n",
            "Epoch 1049/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6601 - accuracy: 0.3550 - val_loss: 1.6216 - val_accuracy: 0.3103\n",
            "Epoch 1050/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6668 - accuracy: 0.3628 - val_loss: 1.6431 - val_accuracy: 0.2759\n",
            "Epoch 1051/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6823 - accuracy: 0.3386 - val_loss: 1.6148 - val_accuracy: 0.2931\n",
            "Epoch 1052/1200\n",
            "44/44 [==============================] - 0s 5ms/step - loss: 1.6724 - accuracy: 0.3478 - val_loss: 1.6164 - val_accuracy: 0.2931\n",
            "Epoch 1053/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6875 - accuracy: 0.3421 - val_loss: 1.6362 - val_accuracy: 0.3017\n",
            "Epoch 1054/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6655 - accuracy: 0.3564 - val_loss: 1.6109 - val_accuracy: 0.2931\n",
            "Epoch 1055/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6651 - accuracy: 0.3500 - val_loss: 1.6173 - val_accuracy: 0.2759\n",
            "Epoch 1056/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6677 - accuracy: 0.3550 - val_loss: 1.6266 - val_accuracy: 0.2931\n",
            "Epoch 1057/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6546 - accuracy: 0.3571 - val_loss: 1.6098 - val_accuracy: 0.2931\n",
            "Epoch 1058/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6754 - accuracy: 0.3500 - val_loss: 1.6126 - val_accuracy: 0.3534\n",
            "Epoch 1059/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6735 - accuracy: 0.3592 - val_loss: 1.6065 - val_accuracy: 0.3190\n",
            "Epoch 1060/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6633 - accuracy: 0.3678 - val_loss: 1.6018 - val_accuracy: 0.2931\n",
            "Epoch 1061/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6579 - accuracy: 0.3542 - val_loss: 1.6224 - val_accuracy: 0.3534\n",
            "Epoch 1062/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6778 - accuracy: 0.3435 - val_loss: 1.6180 - val_accuracy: 0.3362\n",
            "Epoch 1063/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6645 - accuracy: 0.3414 - val_loss: 1.6206 - val_accuracy: 0.3276\n",
            "Epoch 1064/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6721 - accuracy: 0.3471 - val_loss: 1.6269 - val_accuracy: 0.3276\n",
            "Epoch 1065/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6834 - accuracy: 0.3443 - val_loss: 1.6282 - val_accuracy: 0.3448\n",
            "Epoch 1066/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6659 - accuracy: 0.3564 - val_loss: 1.6396 - val_accuracy: 0.2845\n",
            "Epoch 1067/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.7033 - accuracy: 0.3343 - val_loss: 1.6379 - val_accuracy: 0.3190\n",
            "Epoch 1068/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6689 - accuracy: 0.3649 - val_loss: 1.6180 - val_accuracy: 0.3276\n",
            "Epoch 1069/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6549 - accuracy: 0.3321 - val_loss: 1.6319 - val_accuracy: 0.3190\n",
            "Epoch 1070/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6615 - accuracy: 0.3642 - val_loss: 1.6336 - val_accuracy: 0.3017\n",
            "Epoch 1071/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6678 - accuracy: 0.3493 - val_loss: 1.6168 - val_accuracy: 0.3017\n",
            "Epoch 1072/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6942 - accuracy: 0.3286 - val_loss: 1.6151 - val_accuracy: 0.3103\n",
            "Epoch 1073/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6942 - accuracy: 0.3478 - val_loss: 1.6279 - val_accuracy: 0.3190\n",
            "Epoch 1074/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6570 - accuracy: 0.3493 - val_loss: 1.6319 - val_accuracy: 0.3362\n",
            "Epoch 1075/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6742 - accuracy: 0.3336 - val_loss: 1.6298 - val_accuracy: 0.3190\n",
            "Epoch 1076/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6856 - accuracy: 0.3272 - val_loss: 1.6256 - val_accuracy: 0.3362\n",
            "Epoch 1077/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6863 - accuracy: 0.3336 - val_loss: 1.6161 - val_accuracy: 0.3017\n",
            "Epoch 1078/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6733 - accuracy: 0.3471 - val_loss: 1.6175 - val_accuracy: 0.3103\n",
            "Epoch 1079/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6650 - accuracy: 0.3407 - val_loss: 1.6173 - val_accuracy: 0.3276\n",
            "Epoch 1080/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6660 - accuracy: 0.3378 - val_loss: 1.6236 - val_accuracy: 0.2845\n",
            "Epoch 1081/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6529 - accuracy: 0.3656 - val_loss: 1.6276 - val_accuracy: 0.2931\n",
            "Epoch 1082/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6622 - accuracy: 0.3485 - val_loss: 1.6269 - val_accuracy: 0.2845\n",
            "Epoch 1083/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6446 - accuracy: 0.3564 - val_loss: 1.6273 - val_accuracy: 0.3448\n",
            "Epoch 1084/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6752 - accuracy: 0.3571 - val_loss: 1.6293 - val_accuracy: 0.2931\n",
            "Epoch 1085/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6640 - accuracy: 0.3607 - val_loss: 1.6198 - val_accuracy: 0.3276\n",
            "Epoch 1086/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6498 - accuracy: 0.3735 - val_loss: 1.6222 - val_accuracy: 0.3190\n",
            "Epoch 1087/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6638 - accuracy: 0.3357 - val_loss: 1.6292 - val_accuracy: 0.3017\n",
            "Epoch 1088/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6655 - accuracy: 0.3521 - val_loss: 1.6155 - val_accuracy: 0.2931\n",
            "Epoch 1089/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6829 - accuracy: 0.3329 - val_loss: 1.6120 - val_accuracy: 0.3017\n",
            "Epoch 1090/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6676 - accuracy: 0.3428 - val_loss: 1.6157 - val_accuracy: 0.2672\n",
            "Epoch 1091/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6681 - accuracy: 0.3578 - val_loss: 1.6194 - val_accuracy: 0.3276\n",
            "Epoch 1092/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6756 - accuracy: 0.3464 - val_loss: 1.6308 - val_accuracy: 0.2931\n",
            "Epoch 1093/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6465 - accuracy: 0.3407 - val_loss: 1.6177 - val_accuracy: 0.2931\n",
            "Epoch 1094/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6593 - accuracy: 0.3542 - val_loss: 1.6134 - val_accuracy: 0.3276\n",
            "Epoch 1095/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6711 - accuracy: 0.3478 - val_loss: 1.6257 - val_accuracy: 0.3017\n",
            "Epoch 1096/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6644 - accuracy: 0.3435 - val_loss: 1.6216 - val_accuracy: 0.3190\n",
            "Epoch 1097/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6683 - accuracy: 0.3585 - val_loss: 1.6477 - val_accuracy: 0.2586\n",
            "Epoch 1098/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6744 - accuracy: 0.3357 - val_loss: 1.6309 - val_accuracy: 0.2586\n",
            "Epoch 1099/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6655 - accuracy: 0.3528 - val_loss: 1.6123 - val_accuracy: 0.3103\n",
            "Epoch 1100/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6347 - accuracy: 0.3578 - val_loss: 1.6118 - val_accuracy: 0.3103\n",
            "Epoch 1101/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6531 - accuracy: 0.3806 - val_loss: 1.6084 - val_accuracy: 0.3276\n",
            "Epoch 1102/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6611 - accuracy: 0.3478 - val_loss: 1.6234 - val_accuracy: 0.3276\n",
            "Epoch 1103/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6698 - accuracy: 0.3735 - val_loss: 1.6202 - val_accuracy: 0.2931\n",
            "Epoch 1104/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7020 - accuracy: 0.3378 - val_loss: 1.6172 - val_accuracy: 0.2931\n",
            "Epoch 1105/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6632 - accuracy: 0.3500 - val_loss: 1.6213 - val_accuracy: 0.3103\n",
            "Epoch 1106/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6649 - accuracy: 0.3592 - val_loss: 1.6183 - val_accuracy: 0.3017\n",
            "Epoch 1107/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6620 - accuracy: 0.3656 - val_loss: 1.6151 - val_accuracy: 0.2845\n",
            "Epoch 1108/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6700 - accuracy: 0.3528 - val_loss: 1.6170 - val_accuracy: 0.3103\n",
            "Epoch 1109/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6468 - accuracy: 0.3535 - val_loss: 1.6248 - val_accuracy: 0.3103\n",
            "Epoch 1110/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6493 - accuracy: 0.3699 - val_loss: 1.6189 - val_accuracy: 0.3190\n",
            "Epoch 1111/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6547 - accuracy: 0.3514 - val_loss: 1.6228 - val_accuracy: 0.2931\n",
            "Epoch 1112/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6352 - accuracy: 0.3564 - val_loss: 1.6184 - val_accuracy: 0.2759\n",
            "Epoch 1113/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6719 - accuracy: 0.3485 - val_loss: 1.6221 - val_accuracy: 0.2672\n",
            "Epoch 1114/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6834 - accuracy: 0.3243 - val_loss: 1.6312 - val_accuracy: 0.2931\n",
            "Epoch 1115/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6690 - accuracy: 0.3428 - val_loss: 1.6092 - val_accuracy: 0.2845\n",
            "Epoch 1116/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6744 - accuracy: 0.3514 - val_loss: 1.6193 - val_accuracy: 0.3017\n",
            "Epoch 1117/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6912 - accuracy: 0.3514 - val_loss: 1.6279 - val_accuracy: 0.3103\n",
            "Epoch 1118/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6494 - accuracy: 0.3557 - val_loss: 1.6168 - val_accuracy: 0.2845\n",
            "Epoch 1119/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6616 - accuracy: 0.3592 - val_loss: 1.6501 - val_accuracy: 0.2500\n",
            "Epoch 1120/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6733 - accuracy: 0.3371 - val_loss: 1.6108 - val_accuracy: 0.3190\n",
            "Epoch 1121/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6598 - accuracy: 0.3592 - val_loss: 1.6195 - val_accuracy: 0.2845\n",
            "Epoch 1122/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6707 - accuracy: 0.3550 - val_loss: 1.6246 - val_accuracy: 0.2845\n",
            "Epoch 1123/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6886 - accuracy: 0.3314 - val_loss: 1.6143 - val_accuracy: 0.2845\n",
            "Epoch 1124/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6794 - accuracy: 0.3571 - val_loss: 1.6532 - val_accuracy: 0.2586\n",
            "Epoch 1125/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6622 - accuracy: 0.3428 - val_loss: 1.6203 - val_accuracy: 0.3103\n",
            "Epoch 1126/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6533 - accuracy: 0.3664 - val_loss: 1.6426 - val_accuracy: 0.3276\n",
            "Epoch 1127/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6471 - accuracy: 0.3635 - val_loss: 1.6305 - val_accuracy: 0.2931\n",
            "Epoch 1128/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6498 - accuracy: 0.3407 - val_loss: 1.6371 - val_accuracy: 0.3103\n",
            "Epoch 1129/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6420 - accuracy: 0.3457 - val_loss: 1.6518 - val_accuracy: 0.2586\n",
            "Epoch 1130/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6323 - accuracy: 0.3493 - val_loss: 1.6351 - val_accuracy: 0.2845\n",
            "Epoch 1131/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6510 - accuracy: 0.3578 - val_loss: 1.6270 - val_accuracy: 0.3017\n",
            "Epoch 1132/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6605 - accuracy: 0.3493 - val_loss: 1.6346 - val_accuracy: 0.2845\n",
            "Epoch 1133/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6517 - accuracy: 0.3485 - val_loss: 1.6326 - val_accuracy: 0.2931\n",
            "Epoch 1134/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6755 - accuracy: 0.3671 - val_loss: 1.6503 - val_accuracy: 0.2586\n",
            "Epoch 1135/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6605 - accuracy: 0.3478 - val_loss: 1.6397 - val_accuracy: 0.2931\n",
            "Epoch 1136/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6674 - accuracy: 0.3279 - val_loss: 1.6458 - val_accuracy: 0.2586\n",
            "Epoch 1137/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6656 - accuracy: 0.3450 - val_loss: 1.6187 - val_accuracy: 0.2759\n",
            "Epoch 1138/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6661 - accuracy: 0.3514 - val_loss: 1.6234 - val_accuracy: 0.2931\n",
            "Epoch 1139/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6409 - accuracy: 0.3528 - val_loss: 1.6234 - val_accuracy: 0.3276\n",
            "Epoch 1140/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6604 - accuracy: 0.3521 - val_loss: 1.6356 - val_accuracy: 0.2845\n",
            "Epoch 1141/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6264 - accuracy: 0.3927 - val_loss: 1.6416 - val_accuracy: 0.2586\n",
            "Epoch 1142/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6597 - accuracy: 0.3514 - val_loss: 1.6270 - val_accuracy: 0.2759\n",
            "Epoch 1143/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6268 - accuracy: 0.3443 - val_loss: 1.6459 - val_accuracy: 0.3017\n",
            "Epoch 1144/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6625 - accuracy: 0.3493 - val_loss: 1.6539 - val_accuracy: 0.2931\n",
            "Epoch 1145/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6598 - accuracy: 0.3571 - val_loss: 1.6433 - val_accuracy: 0.2414\n",
            "Epoch 1146/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6637 - accuracy: 0.3314 - val_loss: 1.6438 - val_accuracy: 0.2759\n",
            "Epoch 1147/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6561 - accuracy: 0.3535 - val_loss: 1.6489 - val_accuracy: 0.2414\n",
            "Epoch 1148/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6554 - accuracy: 0.3485 - val_loss: 1.6367 - val_accuracy: 0.3103\n",
            "Epoch 1149/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6493 - accuracy: 0.3692 - val_loss: 1.6442 - val_accuracy: 0.2672\n",
            "Epoch 1150/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.3329 - val_loss: 1.6253 - val_accuracy: 0.3017\n",
            "Epoch 1151/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6508 - accuracy: 0.3514 - val_loss: 1.6362 - val_accuracy: 0.3017\n",
            "Epoch 1152/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6735 - accuracy: 0.3628 - val_loss: 1.6353 - val_accuracy: 0.2931\n",
            "Epoch 1153/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6617 - accuracy: 0.3485 - val_loss: 1.6344 - val_accuracy: 0.3362\n",
            "Epoch 1154/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6588 - accuracy: 0.3550 - val_loss: 1.6333 - val_accuracy: 0.2931\n",
            "Epoch 1155/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6275 - accuracy: 0.3742 - val_loss: 1.6167 - val_accuracy: 0.2845\n",
            "Epoch 1156/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6717 - accuracy: 0.3428 - val_loss: 1.6116 - val_accuracy: 0.3017\n",
            "Epoch 1157/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6479 - accuracy: 0.3671 - val_loss: 1.6181 - val_accuracy: 0.3190\n",
            "Epoch 1158/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6321 - accuracy: 0.3628 - val_loss: 1.6102 - val_accuracy: 0.2672\n",
            "Epoch 1159/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6295 - accuracy: 0.3678 - val_loss: 1.5940 - val_accuracy: 0.2759\n",
            "Epoch 1160/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6512 - accuracy: 0.3571 - val_loss: 1.6083 - val_accuracy: 0.2759\n",
            "Epoch 1161/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6524 - accuracy: 0.3628 - val_loss: 1.6243 - val_accuracy: 0.2931\n",
            "Epoch 1162/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6469 - accuracy: 0.3678 - val_loss: 1.6372 - val_accuracy: 0.2586\n",
            "Epoch 1163/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6649 - accuracy: 0.3364 - val_loss: 1.6324 - val_accuracy: 0.2931\n",
            "Epoch 1164/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6344 - accuracy: 0.3621 - val_loss: 1.6269 - val_accuracy: 0.3276\n",
            "Epoch 1165/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6772 - accuracy: 0.3414 - val_loss: 1.6276 - val_accuracy: 0.2931\n",
            "Epoch 1166/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6724 - accuracy: 0.3500 - val_loss: 1.6148 - val_accuracy: 0.3103\n",
            "Epoch 1167/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6282 - accuracy: 0.3571 - val_loss: 1.6230 - val_accuracy: 0.3190\n",
            "Epoch 1168/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6527 - accuracy: 0.3542 - val_loss: 1.6223 - val_accuracy: 0.3190\n",
            "Epoch 1169/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6436 - accuracy: 0.3749 - val_loss: 1.6317 - val_accuracy: 0.3103\n",
            "Epoch 1170/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6582 - accuracy: 0.3564 - val_loss: 1.6085 - val_accuracy: 0.2759\n",
            "Epoch 1171/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.7194 - accuracy: 0.3378 - val_loss: 1.6154 - val_accuracy: 0.3362\n",
            "Epoch 1172/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6739 - accuracy: 0.3450 - val_loss: 1.6362 - val_accuracy: 0.2759\n",
            "Epoch 1173/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6671 - accuracy: 0.3421 - val_loss: 1.6287 - val_accuracy: 0.3276\n",
            "Epoch 1174/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6255 - accuracy: 0.3557 - val_loss: 1.6208 - val_accuracy: 0.3362\n",
            "Epoch 1175/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6440 - accuracy: 0.3842 - val_loss: 1.6142 - val_accuracy: 0.3103\n",
            "Epoch 1176/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6303 - accuracy: 0.3564 - val_loss: 1.6088 - val_accuracy: 0.3103\n",
            "Epoch 1177/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6579 - accuracy: 0.3557 - val_loss: 1.6207 - val_accuracy: 0.3103\n",
            "Epoch 1178/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6305 - accuracy: 0.3756 - val_loss: 1.6265 - val_accuracy: 0.2845\n",
            "Epoch 1179/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6345 - accuracy: 0.3521 - val_loss: 1.6223 - val_accuracy: 0.3017\n",
            "Epoch 1180/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6649 - accuracy: 0.3507 - val_loss: 1.6272 - val_accuracy: 0.3103\n",
            "Epoch 1181/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6455 - accuracy: 0.3685 - val_loss: 1.6211 - val_accuracy: 0.3017\n",
            "Epoch 1182/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6393 - accuracy: 0.3635 - val_loss: 1.6270 - val_accuracy: 0.3276\n",
            "Epoch 1183/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6634 - accuracy: 0.3592 - val_loss: 1.6169 - val_accuracy: 0.3190\n",
            "Epoch 1184/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6510 - accuracy: 0.3692 - val_loss: 1.6315 - val_accuracy: 0.3103\n",
            "Epoch 1185/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6312 - accuracy: 0.3514 - val_loss: 1.6216 - val_accuracy: 0.3190\n",
            "Epoch 1186/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6523 - accuracy: 0.3649 - val_loss: 1.6359 - val_accuracy: 0.3362\n",
            "Epoch 1187/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6483 - accuracy: 0.3599 - val_loss: 1.6227 - val_accuracy: 0.3448\n",
            "Epoch 1188/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6610 - accuracy: 0.3628 - val_loss: 1.6241 - val_accuracy: 0.2759\n",
            "Epoch 1189/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6295 - accuracy: 0.3607 - val_loss: 1.6157 - val_accuracy: 0.3017\n",
            "Epoch 1190/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6444 - accuracy: 0.3671 - val_loss: 1.6333 - val_accuracy: 0.2931\n",
            "Epoch 1191/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6404 - accuracy: 0.3649 - val_loss: 1.6163 - val_accuracy: 0.3190\n",
            "Epoch 1192/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6410 - accuracy: 0.3770 - val_loss: 1.6375 - val_accuracy: 0.3190\n",
            "Epoch 1193/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6619 - accuracy: 0.3514 - val_loss: 1.6503 - val_accuracy: 0.3276\n",
            "Epoch 1194/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6624 - accuracy: 0.3607 - val_loss: 1.6273 - val_accuracy: 0.3190\n",
            "Epoch 1195/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6281 - accuracy: 0.3735 - val_loss: 1.6184 - val_accuracy: 0.3103\n",
            "Epoch 1196/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6443 - accuracy: 0.3678 - val_loss: 1.6219 - val_accuracy: 0.3017\n",
            "Epoch 1197/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6392 - accuracy: 0.3699 - val_loss: 1.6222 - val_accuracy: 0.2759\n",
            "Epoch 1198/1200\n",
            "44/44 [==============================] - 0s 4ms/step - loss: 1.6272 - accuracy: 0.3656 - val_loss: 1.6232 - val_accuracy: 0.3276\n",
            "Epoch 1199/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6282 - accuracy: 0.3450 - val_loss: 1.6365 - val_accuracy: 0.3103\n",
            "Epoch 1200/1200\n",
            "44/44 [==============================] - 0s 3ms/step - loss: 1.6569 - accuracy: 0.3535 - val_loss: 1.6281 - val_accuracy: 0.2845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(win_pred.history).plot(figsize = (8,5))\n",
        "# plt.figure(figsize=(10,5))\n",
        "plt.rcParams.update({'font.size': 15})\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.grid(True)\n",
        "plt.savefig('/content/drive/MyDrive/Colab Notebooks/IPL Score_Analysis/Plots/nn_winner_pred_byball.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ZHqfQoR6h8Ez",
        "outputId": "bbccaa35-2634-4964-d516-cad60a360c63"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2test = y2test.ravel()"
      ],
      "metadata": {
        "id": "D0pbKBIkh8Hz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(tnewt)\n",
        "class_pred = np.argmax(predictions, axis=1)\n",
        "class_pred\n",
        "# sample = pd.DataFrame(predictions,columns=['Predict'])\n",
        "# sample['Actual']=y2test\n",
        "# sample.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmpur7iMh8No",
        "outputId": "32aa031f-c693-4718-b4a7-6ed3531ba224"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11,  5,  6,  8,  5,  5,  9,  9, 13, 13,  8,  8, 13, 13, 11, 11, 12,\n",
              "        6,  8,  5,  5,  5, 11, 12,  5,  5, 11, 11, 13, 13,  5,  5,  5,  8,\n",
              "       11, 11,  5, 13,  5,  5,  9,  7,  6, 11,  9, 11, 11, 12, 11,  5,  5,\n",
              "       13, 13,  5,  5,  9,  9,  5,  5,  5, 13,  9, 11,  5,  5,  5, 13,  5,\n",
              "        8, 12, 12,  5,  5,  8, 13,  5, 11,  5,  6, 12,  5,  5,  9,  9, 13,\n",
              "       13, 11, 11,  5,  5,  9, 11,  5,  6,  5, 13, 11, 12,  9,  9,  5, 12,\n",
              "        5,  5, 12,  6, 11, 12, 13, 13,  5,  5, 12, 13, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# proba = predictions.round(2)\n",
        "# proba"
      ],
      "metadata": {
        "id": "71RbvJRTh8d3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.DataFrame(class_pred,columns=['Predict'])\n",
        "sample['Actual']=y2test\n",
        "# sample.head()"
      ],
      "metadata": {
        "id": "7ZdTNw9e8e1G"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frames = [id_test, sample]\n",
        "# final = pd.concat(frames, axis = 1)\n",
        "# # final.head()\n",
        "# ar1 = final['id'].unique()\n",
        "# winner = pd.DataFrame()\n",
        "# for items in ar1:\n",
        "#   # print(items)\n",
        "#   try2 = final[final.id == items]\n",
        "#   # try2.drop(columns = 'id', inplace = True)\n",
        "#   hapi = try2.drop(columns = ['id']).reset_index(drop=True)\n",
        "#   result = (hapi.sum())/hapi.shape[0]\n",
        "#   # print(result)\n",
        "#   res = result.values.reshape(1,2)\n",
        "#   # print(res)\n",
        "#   winner = winner.append(pd.DataFrame(res))\n",
        "  \n",
        "# winner.rename(columns = {0: 'Predict',\n",
        "#                           1: 'Actual'\n",
        "#                           }, inplace = True)\n",
        "# winner.reset_index(drop = True)\n",
        "\n",
        "# winner['diff'] = abs(winner['Actual'] - winner['Predict'])\n",
        "# to = winner.shape[0]\n",
        "# print( ((winner[(winner['diff'])<1].shape[0])/to)*100 )"
      ],
      "metadata": {
        "id": "ZFyAgIJS8e4a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final.to_csv('final.csv')"
      ],
      "metadata": {
        "id": "HsYSrSywBF5p"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(xs)\n",
        "class_pred = np.argmax(test_pred, axis=1)\n",
        "sample = pd.DataFrame(class_pred,columns=['Predict'])\n",
        "yt2 = yt2.ravel()\n",
        "sample['Actual']=yt2"
      ],
      "metadata": {
        "id": "4hpyNSk88fBD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [tt_2021, sample]\n",
        "final = pd.concat(frames, axis = 1)\n",
        "# final.head()\n",
        "ar1 = final['id'].unique()\n",
        "winner = pd.DataFrame()\n",
        "for items in ar1:\n",
        "  # print(items)\n",
        "  try2 = final[final.id == items]\n",
        "  # try2.drop(columns = 'id', inplace = True)\n",
        "  hapi = try2.drop(columns = ['id']).reset_index(drop=True)\n",
        "  result = (hapi.sum())/hapi.shape[0]\n",
        "  # print(result)\n",
        "  res = result.values.reshape(1,2)\n",
        "  # print(res)\n",
        "  winner = winner.append(pd.DataFrame(res))\n",
        "  \n",
        "winner.rename(columns = {0: 'Predict',\n",
        "                          1: 'Actual'\n",
        "                          }, inplace = True)\n",
        "winner.reset_index(drop = True)\n",
        "\n",
        "winner['diff'] = abs(winner['Actual'] - winner['Predict'])\n",
        "to = winner.shape[0]\n",
        "print( ((winner[(winner['diff'])<1].shape[0])/to)*100 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCZubWCAq6Lz",
        "outputId": "61611029-0595-4ac0-e8cf-f4a0885f4db2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "winner.shape"
      ],
      "metadata": {
        "id": "2JJu_Ev1HyN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca9b10a-6b85-48c4-f21c-efe14aee5fa8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ovc3QrKuHyTb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y-HigrgXHVVz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A0CF3r8NHVY1"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}